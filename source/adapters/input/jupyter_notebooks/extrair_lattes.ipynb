{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<center><center><img src=\"https://raw.githubusercontent.com/makaires77/fioce/master/assets/logo_fioce.png\" \n",
    "style=\"height:150px\" alt=\"Logo_Unifor\"></center></center>\n",
    "\n",
    "## <center>Analisar a Produção Acadêmica Institucional da Fiocruz Ceará para<br /> alinhar conforme terminologia adotada no CNPq e orientar para impactos para a sociedade</center>\n",
    "\n",
    "    João Hermínio da Silva       - Fiocruz Ceará\n",
    "    Carlos Vasconcelos Guimarães – Fiocruz Ceará\n",
    "    Antonio Marcos Aires Barbosa – Fiocruz Ceará\n",
    "\n",
    "**Introdução**\n",
    "\n",
    "A Vice-Presidência de Pesquisa e Coleções Biológicas da Fiocruz (VPPCB/Fiocruz) solicita especificar as áreas do conhecimento de acordo com os critérios do CNPq. Mediante dados coletados sobre a produção científica da Fiocruz a em seis bases de dados (WoS, Scopus, PubMed, Lilacs, Arca via OasisBr e Currfculo Lattes), visamos neste trabalho classiicar a produção acadêmica da Fiocruz segundo os termos de classificação usados pelo CNPq. Esta identificação servirá de base para uma reorganização das áreas e linhas de pesquisa de todas as unidades da Fiocruz.\n",
    "\n",
    "**Objetivo geral:**\n",
    "\n",
    "    Alinhar as áreas da produção científica/acadêmica constante nas publicações da Fiocruz Ceará com as definições/nomenclatura do CNPq para alinhar a pesquisa desenvolvida pela Fiocruz com áreas já definidas pelo CNPq, em até quatro níveis diferentes de detalhamento.\n",
    "\n",
    "**Objetivos Específicos**\n",
    "\n",
    "    1. Fazer análise de similaridade entre títulos, resumos das publicações constantes das planilhas fornecidas pela VPEIC com as definições do CNPq para classificar cada publciação nas áreas do CNPq mais correlatas aos dados de cada publicação, visando contribuir para redefinição das áreas de pesquisa institucional tornando-as mais alinhadas ao CNPq;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Escopo e Premissas para o Levantamento de dados\n",
    "\n",
    "**Universo para extração de dados:**\n",
    "- Currículos Lattes dos servidores da Fiocruz Ceará, com nível de doutorado.\n",
    "\n",
    "**Período de análise:** \n",
    "- A partir da data de ingresso (início de atuação na Fiocruz Ceará), até Outubro/2023.\n",
    "    \n",
    "**Extração computacional dos dados:**\n",
    "- ScriptDadosCurriculo: Publicações (artigos completos em peródicos) de cada um dos indivíduos da amostra.\n",
    "\n",
    "**Dados a ser analizados:**\n",
    "- CoordenaçãoPesquisa: Lista de Nomes de Servidores, com as respectivas datas de entrada de cada um dos servidores na Fiocruz Ceará (ou data de ingresso na Fiocruz, pelo menos)\n",
    "- VPEIC/Observatório: Planilha com lista de artigos publicados pela Fiocruz Ceará no período 2008 a 2023;\n",
    "- VPEIC/Observatório: Planilha com lista de artigos publicados pela Fiocruz sem identificação da unidade que produziu o publicação;\n",
    "- Diretório dos Grupos de Pesquisa CNPq/GdP: Tabela de Áreas do Conhecimento, segmentada em: Grandes Áreas, Áreas  \n",
    "\n",
    "### Níveis de classificação das informações a serem preenchidas\n",
    "\n",
    "A patir de análises nos títulos, resumos e palavras-chave dos artigos, serão aplicadas as orientações da VPPCB sucintamente citadas a seguir para alinhar com os conceitos do CNPq e escolher a área e subáreas em ate três níveis.\n",
    "\n",
    "    - N00: Grande Área (Área principal do conhecimento principal)\n",
    "    - N01: Área\n",
    "    - N02: Subárea\n",
    "    - N03: Especialidade\n",
    "\n",
    "*Observações:* \n",
    "\n",
    "Sobre a área de conhecimento: Caso a produção científica não esteja contemplada em nenhuma das áreas de conhecimento do CNPq, por favor, preencher na coluna disponível com ate 4 níveis, separando os níveis por \";\"\n",
    "\n",
    "As planilhas ao final das colunas tem espaço reservado para algo não editável da planilha precise ser corrigido.\n",
    "\n",
    "### Regras de associação à Fiocruz Ceará\n",
    "- Considerar apenas produção de servidores\n",
    "- Considerar a partir da data de ingresso na Fiocruz Ceará (Dados do RH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><b>PREPARAR AMBIENTE DE DESENVOLVIMENTO E EXECUÇÃO</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importação dos módulos de trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração e teste do ambiente local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}  # Dictionary to store the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sh-tsang.medium.com/tutorial-cuda-cudnn-anaconda-jupyter-pytorch-installation-in-windows-10-96b2a2f0ac57\n",
    "# DEFINIÇÃO DAS FUNÇÕES:\n",
    "def try_amb():\n",
    "    ## Visualizar versões dos principais componentes\n",
    "    import os\n",
    "    import pip\n",
    "    import sys\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "    # !pip3 install shutup\n",
    "    # import shutup; shutup.please()   \n",
    "    pyVer      = sys.version\n",
    "    pipVer     = pip.__version__\n",
    "    print('\\nVERSÕES DAS PRINCIPAIS BIBLIOTECAS INSTALADAS NO ENVIROMENT')\n",
    "    print('Interpretador em uso:', sys.executable)\n",
    "    print('    Ambiente ativado:',os.environ['CONDA_DEFAULT_ENV'])\n",
    "    print('     Python: '+pyVer, '\\n        Pip:', pipVer,'\\n'\n",
    "         )\n",
    "    !nvcc -V\n",
    "\n",
    "def get_cpu_info_windows():\n",
    "    import subprocess\n",
    "\n",
    "    try:\n",
    "        return subprocess.check_output(\"wmic cpu get Name\", shell=True).decode('utf-8').split('\\n')[1].strip()\n",
    "    except:\n",
    "        return \"Informação não disponível\"\n",
    "\n",
    "def get_cpu_info_unix():\n",
    "    import subprocess\n",
    "    try:\n",
    "        return subprocess.check_output(\"lscpu\", shell=True).decode('utf-8')\n",
    "    except:\n",
    "        try:\n",
    "            return subprocess.check_output(\"sysctl -n machdep.cpu.brand_string\", shell=True).decode('utf-8').strip()\n",
    "        except:\n",
    "            return \"Informação não disponível\"\n",
    "        \n",
    "def try_cpu():\n",
    "    import psutil\n",
    "    import platform\n",
    "\n",
    "    # Métricas da CPU\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    cpu_count_logical = psutil.cpu_count(logical=True)\n",
    "    cpu_count_physical = psutil.cpu_count(logical=False)\n",
    "    cpu_freq = psutil.cpu_freq()\n",
    "    cpu_times_percent = psutil.cpu_times_percent(interval=1)\n",
    "\n",
    "    # Informação específica do modelo do processador\n",
    "    if platform.system() == \"Windows\":\n",
    "        cpu_model = get_cpu_info_windows()\n",
    "    else:\n",
    "        cpu_model = get_cpu_info_unix()\n",
    "\n",
    "    # Informações adicionais sobre o Processador\n",
    "    cpu_brand = platform.processor()\n",
    "    cpu_architecture = platform.architecture()[0]\n",
    "    cpu_machine_type = platform.machine()\n",
    "    \n",
    "    # Métricas da Memória RAM\n",
    "    ram = psutil.virtual_memory()\n",
    "    total_ram = ram.total / (1024 ** 3)  # Em GB\n",
    "    used_ram = ram.used / (1024 ** 3)  # Em GB\n",
    "    \n",
    "    # Métricas do Espaço em Disco\n",
    "    disk = psutil.disk_usage('/')\n",
    "    total_disk = disk.total / (1024 ** 3)  # Em GB\n",
    "    used_disk = disk.used / (1024 ** 3)  # Em GB\n",
    "    free_disk = (total_disk - used_disk)\n",
    "    used_disk_percent = (used_disk / total_disk) * 100\n",
    "    free_disk_percent = (1 - (used_disk / total_disk)) * 100\n",
    "\n",
    "    # Exibição das Métricas\n",
    "    print(f\"\\nMarca do Processador: {cpu_brand}\")\n",
    "    print(f\"Modelo do Processador: {cpu_model}\")\n",
    "    print(f\"Frequência da CPU: {cpu_freq.current} MHz\")\n",
    "    # print(f\"Tipo de Máquina: {cpu_machine_type}\")\n",
    "    print(f\"Arquitetura do Processador: {cpu_architecture}\")\n",
    "    print(f\"Número de CPUs físicas: {cpu_count_physical}\")\n",
    "    print(f\"Número de CPUs lógicas: {cpu_count_logical}\")\n",
    "    print(f\"Uso atual CPU: {cpu_percent}%\")\n",
    "    print(f\"Tempos de CPU: user={cpu_times_percent.user}%, system={cpu_times_percent.system}%, idle={cpu_times_percent.idle}%\")\n",
    "    print(f\"\\nTotal de RAM: {total_ram:>5.2f} GB\")\n",
    "    print(f\"Usado em RAM: {used_ram:>5.2f} GB\")\n",
    "    print(f\"Espaço Total em disco: {total_disk:>7.2f} GB\")\n",
    "    print(f\"Espaço em disco usado: {used_disk:>7.2f} GB {used_disk_percent:>4.1f}%\")\n",
    "    print(f\"Espaço em disco livre: {free_disk:>7.2f} GB {free_disk_percent:>4.1f}%\")\n",
    "\n",
    "def try_gpu():\n",
    "    print('\\nVERSÕES DO PYTORCH E GPU DISPONÍVEIS')\n",
    "    try:\n",
    "        import torch\n",
    "        print('    PyTorch:',torch.__version__)\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print('Dispositivo:',device)\n",
    "        print('Disponível :',device,torch.cuda.is_available(),' | Inicializado:',torch.cuda.is_initialized(),'| Capacidade:',torch.cuda.get_device_capability(device=None))\n",
    "        print('Nome GPU   :',torch.cuda.get_device_name(0),'         | Quantidade:',torch.cuda.device_count(),'\\n')\n",
    "    except Exception as e:\n",
    "        print('Erro ao configurar a GPU:',e,'\\n')\n",
    "\n",
    "def try_browser(chromedriver_path):\n",
    "    print('\\nVERSÕES O BROWSER E DO CHROMEDRIVER INSTALADAS')\n",
    "    import os\n",
    "    from selenium import webdriver\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "    try:\n",
    "        driver_path = chromedriver_path+'/chromedriver.exe'\n",
    "        service = Service(driver_path)\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        str1 = driver.capabilities['browserVersion']\n",
    "        str2 = driver.capabilities['chrome']['chromedriverVersion'].split(' ')[0]\n",
    "        print(f'     Versão do browser: {str1}')\n",
    "        print(f'Versão do chromedriver: {str2}')\n",
    "        driver.quit()\n",
    "\n",
    "        if str1[0:3] != str2[0:3]: \n",
    "            print(\"Versões incompatíveis, atualizar chromedriver!\")\n",
    "            print('  Baixar versão atualizada do Chromedriver em:')\n",
    "            print('  https://googlechromelabs.github.io/chrome-for-testing/#stable')\n",
    "            print('     Ex. Versão 116 PARA WINDOWS:')\n",
    "            print('\t    https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/win64/chromedriver-win64.zip')\n",
    "    except Exception as e:\n",
    "        print('Erro ao testar versões:')\n",
    "        print(f'  {e}')\n",
    "\n",
    "def detect_error(html_text):\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    result_list = soup.find('div', {'class': 'resultado'}).find('ol').find_all('li')\n",
    "    for result in result_list:\n",
    "        if 'Stale file handle' in result.text:\n",
    "            raise Exception('Stale File Handle Detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_directory(prompt_message):\n",
    "    \"\"\"\n",
    "    Opens a file dialog to allow the user to select a directory.\n",
    "    Returns the path of the selected directory.\n",
    "    \"\"\"\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main Tk window\n",
    "    print(prompt_message)\n",
    "    folder_selected = filedialog.askdirectory()\n",
    "    \n",
    "    if folder_selected:\n",
    "        print(f\"You have selected the folder: {folder_selected}\")\n",
    "        return folder_selected\n",
    "    else:\n",
    "        print(\"No folder was selected.\")\n",
    "        return None\n",
    "\n",
    "def configure_environment():\n",
    "    \"\"\"\n",
    "    Allows the user to specify the directory of Chromedriver and the data storage folder.\n",
    "    Returns a dictionary containing paths for both.\n",
    "    \"\"\"\n",
    "    chromedriver_path = select_directory(\"Please select the Chromedriver folder:\")\n",
    "    data_storage_path = select_directory(\"Please select the data storage folder:\")\n",
    "    \n",
    "    if chromedriver_path and data_storage_path:\n",
    "        config = {\n",
    "            \"Chromedriver_Path\": chromedriver_path,\n",
    "            \"Data_Storage_Path\": data_storage_path\n",
    "        }\n",
    "        return config\n",
    "    else:\n",
    "        print(\"Configuration incomplete. Both paths are required.\")\n",
    "        return None\n",
    "\n",
    "def select_directory_jupyter(prompt_message):\n",
    "    \"\"\"\n",
    "    Creates an interactive directory selector in Jupyter Notebook.\n",
    "    \"\"\"\n",
    "    print(prompt_message)\n",
    "    \n",
    "    folder_selector = widgets.Text(\n",
    "        description='Directory:',\n",
    "        value=os.getcwd(),  # Default value is the current working directory\n",
    "        layout=widgets.Layout(width='90%')\n",
    "    )\n",
    "    \n",
    "    def on_submit(change):\n",
    "        folder_selected = change['new']\n",
    "        \n",
    "        if os.path.isdir(folder_selected):\n",
    "            print(f\"You have selected the folder: {folder_selected}\")\n",
    "        else:\n",
    "            print(\"Invalid folder. Please try again.\")\n",
    "    \n",
    "    folder_selector.on_submit(on_submit)\n",
    "    display(folder_selector)\n",
    "    \n",
    "\n",
    "def on_submit_chromedriver(change):\n",
    "    folder_selected = change.new\n",
    "    if os.path.isdir(folder_selected):\n",
    "        print(f\"You have selected the Chromedriver folder: {folder_selected}\")\n",
    "        config[\"Chromedriver_Path\"] = folder_selected\n",
    "\n",
    "def on_submit_data_storage(change):\n",
    "    folder_selected = change.new\n",
    "    if os.path.isdir(folder_selected):\n",
    "        print(f\"You have selected the data storage folder: {folder_selected}\")\n",
    "        config[\"Data_Storage_Path\"] = folder_selected\n",
    "    else:\n",
    "        print(\"Invalid folder for data storage. Please try again.\")\n",
    "\n",
    "## Ambiente Linux (Laptop)\n",
    "# /home/marcos/fioce/chromedriver\n",
    "# /home/marcos/kgfioce\n",
    "\n",
    "## Ambiente Fiocruz Eusébio (Windows)\n",
    "# c:\\Users\\marcos.aires\\fioce\\chromedriver\n",
    "# c:\\kgfioce\\\n",
    "\n",
    "## Ambiente Home (Windows)\n",
    "# c:\\Users\\marco\\fioce\\chromedriver\n",
    "# c:\\kgfioce\\\n",
    "\n",
    "def find_chromedriver_path():\n",
    "    \"\"\"\n",
    "    Search for the existing Chromedriver directory among the predefined paths.\n",
    "    \"\"\"\n",
    "    possible_paths = [\n",
    "        '/home/marcos/fioce/chromedriver',\n",
    "        'c:\\\\Users\\\\marcos.aires\\\\fioce\\\\chromedriver',\n",
    "        'c:\\\\Users\\\\marco\\\\fioce\\\\chromedriver'\n",
    "    ]\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None  # Return None if no path is found\n",
    "\n",
    "def find_datafolder():\n",
    "    \"\"\"\n",
    "    Search for the existing Data folder directory among the predefined paths.\n",
    "    \"\"\"\n",
    "    possible_paths = [\n",
    "        '/home/marcos/kgfioce',\n",
    "        'c:\\\\kgfioce\\\\',\n",
    "    ]\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None  # Return None if no path is found\n",
    "\n",
    "def configure_environment_jupyter():\n",
    "    \"\"\"\n",
    "    Specify directory of Chromedriver and the data storage folder in Jupyter Notebook.\n",
    "    \"\"\"\n",
    "    detected_chromedriver = find_chromedriver_path()  # Automatically find the chromedriver path\n",
    "    initial_chromedriver_value = detected_chromedriver if detected_chromedriver else os.getcwd()\n",
    "    if initial_chromedriver_value:\n",
    "        chromedriver_selector = widgets.Text(\n",
    "            description='Chromedriver:',\n",
    "            value=initial_chromedriver_value,\n",
    "            layout=widgets.Layout(width='90%')\n",
    "        )\n",
    "        print(f\"Detected the Chromedriver folder: {initial_chromedriver_value}\")\n",
    "        config[\"Chromedriver_Path\"] = initial_chromedriver_value        \n",
    "    else:\n",
    "        chromedriver_selector = widgets.Text(\n",
    "            description='Chromedriver:',\n",
    "            value=os.getcwd(),\n",
    "            layout=widgets.Layout(width='90%')\n",
    "        )\n",
    "        chromedriver_selector.continuous_update = False\n",
    "        chromedriver_selector.observe(on_submit_chromedriver, names='value')\n",
    "        print(\"Please select the Chromedriver folder:\")\n",
    "        display(chromedriver_selector)        \n",
    "\n",
    "    detected_datafolder = find_datafolder()  # Automatically find the chromedriver path\n",
    "    initial_datafolder = detected_datafolder if detected_datafolder else os.getcwd()\n",
    "    if initial_datafolder:\n",
    "        data_storage_selector = widgets.Text(\n",
    "            description='Chromedriver:',\n",
    "            value=initial_datafolder,\n",
    "            layout=widgets.Layout(width='90%')\n",
    "        )\n",
    "        print(f\"Detected the data storage folder: {initial_datafolder}\")\n",
    "        config[\"Data_Storage_Path\"] = initial_datafolder \n",
    "    else:\n",
    "        data_storage_selector = widgets.Text(\n",
    "            description='Data Storage:',\n",
    "            value=os.getcwd(),\n",
    "            layout=widgets.Layout(width='90%')\n",
    "        )\n",
    "        data_storage_selector.continuous_update = False\n",
    "        data_storage_selector.observe(on_submit_data_storage, names='value')\n",
    "        print(\"Please select the data storage folder:\")\n",
    "        display(data_storage_selector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução das funções de teste do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected the Chromedriver folder: c:\\Users\\marco\\fioce\\chromedriver\n",
      "Detected the data storage folder: c:\\kgfioce\\\n"
     ]
    }
   ],
   "source": [
    "configure_environment_jupyter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver_path = config.get(\"Chromedriver_Path\", \"Default_Value\")\n",
    "data_storage_path = config.get(\"Data_Storage_Path\", \"Default_Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VERSÕES O BROWSER E DO CHROMEDRIVER INSTALADAS\n",
      "     Versão do browser: 117.0.5938.150\n",
      "Versão do chromedriver: 117.0.5938.88\n"
     ]
    }
   ],
   "source": [
    "try_browser(chromedriver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VERSÕES DAS PRINCIPAIS BIBLIOTECAS INSTALADAS NO ENVIROMENT\n",
      "Interpretador em uso: c:\\Users\\marco\\.conda\\envs\\beakerx\\python.exe\n",
      "    Ambiente ativado: beakerx\n",
      "     Python: 3.11.2 | packaged by Anaconda, Inc. | (main, Mar 27 2023, 23:35:04) [MSC v.1916 64 bit (AMD64)] \n",
      "        Pip: 23.2.1 \n",
      "\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Jul_11_03:10:21_Pacific_Daylight_Time_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.128\n",
      "Build cuda_12.2.r12.2/compiler.33053471_0\n"
     ]
    }
   ],
   "source": [
    "try_amb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VERSÕES DO PYTORCH E GPU DISPONÍVEIS\n",
      "    PyTorch: 2.0.1+cu118\n",
      "Dispositivo: cuda\n",
      "Disponível : cuda True  | Inicializado: False | Capacidade: (7, 5)\n",
      "Nome GPU   : NVIDIA GeForce RTX 2060          | Quantidade: 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Marca do Processador: AMD64 Family 25 Model 33 Stepping 0, AuthenticAMD\n",
      "Modelo do Processador: AMD Ryzen 7 5800X 8-Core Processor\n",
      "Frequência da CPU: 3801.0 MHz\n",
      "Arquitetura do Processador: 64bit\n",
      "Número de CPUs físicas: 8\n",
      "Número de CPUs lógicas: 16\n",
      "Uso atual CPU: 9.0%\n",
      "Tempos de CPU: user=2.7%, system=1.8%, idle=95.3%\n",
      "\n",
      "Total de RAM: 63.94 GB\n",
      "Usado em RAM: 28.75 GB\n",
      "Espaço Total em disco:  465.15 GB\n",
      "Espaço em disco usado:  446.56 GB 96.0%\n",
      "Espaço em disco livre:   18.59 GB  4.0%\n"
     ]
    }
   ],
   "source": [
    "try_cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importar pacotes necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python.exe -m pip install --upgrade pip\n",
    "# !pip install selenium --upgrade\n",
    "\n",
    "%matplotlib inline\n",
    "import time\n",
    "t00=time.time()\n",
    "\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os, csv, sys, pip, time, string, re\n",
    "import warnings, traceback\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from string import Formatter\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "## Configurar exibição dos dataframes do pandas na tela\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('colheader_justify', 'left')\n",
    "pd.set_option('display.max_rows', 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Renderização de imagem para exibição dentro da linha do dataframe\n",
    "def path_to_image_html(path):\n",
    "\n",
    "    return '<img src=\"'+ path + '\" style=max-height:124px;\"/>'\n",
    "\n",
    "def show_im():\n",
    "    CSS = \"\"\"\n",
    "    .output {\n",
    "        flex-direction: row;\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    HTML('<style>{}</style>'.format(CSS))\n",
    "    \n",
    "def foto():\n",
    "    '''Aplica filtro no campo com o link para a foto do autor do Dataframe de identificação extraído do currículo Lattes e renderiza a foto em HTML a partir deste link\n",
    "    Autor: Marcos Aires Fev.2022\n",
    "    '''\n",
    "    campo='Link Foto:'\n",
    "    images_df       = df_identificacao[df_identificacao['ROTULOS'] == campo]  # filter by sport input, must be soccer or basketball for this use case\n",
    "    image_grid      = df_identificacao['CONTEUDOS']\n",
    "    image_grid_html = HTML(df_identificacao[:1].to_html(escape=False,formatters=dict(conteudos=path_to_image_html)))\n",
    "    display(image_grid_html)\n",
    "    show_im()\n",
    "\n",
    "def tempo(start, end):\n",
    "    t=end-start\n",
    "\n",
    "    tempo = timedelta(\n",
    "        weeks   = t//(3600*24*7),\n",
    "        days    = t//(3600*24),\n",
    "        seconds = t,\n",
    "        minutes = t//(60),\n",
    "        hours   = t//(3600),\n",
    "        microseconds=t//1000000,\n",
    "        )\n",
    "    fmt='{H:2}:{M:02}:{S:02}'\n",
    "    return strfdelta(tempo)\n",
    "\n",
    "\n",
    "def horas(segundos): \n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(segundos)) \n",
    "\n",
    "\n",
    "def dias_horas_minutos(td):\n",
    "    x = (td.days, td.seconds//3600, (td.seconds//60)%60, td.seconds)\n",
    "    return x #(days, hrs, mins, seconds)\n",
    "\n",
    "\n",
    "def strfdelta(tdelta, fmt='{H:02}h {M:02}m {S:02}s', inputtype='timedelta'):\n",
    "    \"\"\"Convert a datetime.timedelta object or a regular number to a custom-formatted string, \n",
    "    just like the stftime() method does for datetime.datetime objects.\n",
    "\n",
    "    The fmt argument allows custom formatting to be specified.  Fields can \n",
    "    include seconds, minutes, hours, days, and weeks.  Each field is optional.\n",
    "\n",
    "    Some examples:\n",
    "        '{D:02}d {H:02}h {M:02}m {S:02}s' --> '05d 08h 04m 02s' (default)\n",
    "        '{W}w {D}d {H}:{M:02}:{S:02}'     --> '4w 5d 8:04:02'\n",
    "        '{D:2}d {H:2}:{M:02}:{S:02}'      --> ' 5d  8:04:02'\n",
    "        '{H}h {S}s'                       --> '72h 800s'\n",
    "\n",
    "    The inputtype argument allows tdelta to be a regular number instead of the  \n",
    "    default, which is a datetime.timedelta object.  Valid inputtype strings: \n",
    "        's', 'seconds', \n",
    "        'm', 'minutes', \n",
    "        'h', 'hours', \n",
    "        'd', 'days', \n",
    "        'w', 'weeks'\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert tdelta to integer seconds.\n",
    "    if inputtype == 'timedelta':\n",
    "        remainder = int(tdelta.total_seconds())\n",
    "    elif inputtype in ['s', 'seconds']:\n",
    "        remainder = int(tdelta)\n",
    "    elif inputtype in ['m', 'minutes']:\n",
    "        remainder = int(tdelta)*60\n",
    "    elif inputtype in ['h', 'hours']:\n",
    "        remainder = int(tdelta)*3600\n",
    "    elif inputtype in ['d', 'days']:\n",
    "        remainder = int(tdelta)*86400\n",
    "    elif inputtype in ['w', 'weeks']:\n",
    "        remainder = int(tdelta)*604800\n",
    "\n",
    "    f = Formatter()\n",
    "    desired_fields = [field_tuple[1] for field_tuple in f.parse(fmt)]\n",
    "    possible_fields = ('W', 'D', 'H', 'M', 'S')\n",
    "    constants = {'W': 604800, 'D': 86400, 'H': 3600, 'M': 60, 'S': 1}\n",
    "    values = {}\n",
    "    \n",
    "    for field in possible_fields:\n",
    "        if field in desired_fields and field in constants:\n",
    "            values[field], remainder = divmod(remainder, constants[field])\n",
    "    \n",
    "    return f.format(fmt, **values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_pastas(caminho):\n",
    "    import sys\n",
    "\n",
    "    print(f'Pasta armazenagem local {caminho}\\n')\n",
    "    \n",
    "    if os.path.isdir(caminho) is False:\n",
    "        os.mkdir(caminho)\n",
    "        if os.path.isdir(caminho+'/xml_zip'):\n",
    "            print ('Pasta para os arquivo xml já existe!')\n",
    "        else:\n",
    "            os.mkdir(caminho+'/xml_zip')\n",
    "            print ('Pasta para arquivo xml criada com sucesso!')\n",
    "\n",
    "        if os.path.isdir(caminho+'/csv'):\n",
    "            print ('Pasta para os arquivo CSV já existe!')\n",
    "        else:\n",
    "            os.mkdir(caminho+'/csv')\n",
    "            print ('Pasta para arquivo CSV criada com sucesso!')\n",
    "\n",
    "        if os.path.isdir(caminho+'/json'):\n",
    "            print ('Pasta para os arquivo JSON já existe!')\n",
    "        else:\n",
    "            os.mkdir(caminho+'/json')\n",
    "            print ('Pasta para JSON criada com sucesso!')\n",
    "\n",
    "        if os.path.isdir(caminho+'/fig'):\n",
    "            print ('Pasta para figuras já existe!')\n",
    "        else:\n",
    "            os.mkdir(caminho+'/fig')\n",
    "            print ('Pasta para JSON criada com sucesso!')\n",
    "    else:\n",
    "        if os.path.isdir(caminho+'/xml_zip'):\n",
    "            print ('Pasta para os xml já existe!')\n",
    "        else:\n",
    "            os.mkdir(caminho+'/xml_zip')\n",
    "            print ('Pasta para xml criada com sucesso!')\n",
    "\n",
    "        if os.path.isdir(caminho+'/csv'):\n",
    "            print ('Pasta para os CSV já existe!')\n",
    "        else:\n",
    "            os.mkdir(caminho+'/csv')\n",
    "            print ('Pasta para CSV criada com sucesso!')\n",
    "\n",
    "        if os.path.isdir(caminho+'/json'):\n",
    "            print ('Pasta para os JSON já existe!')\n",
    "        else:\n",
    "            os.mkdir(caminho+'/json')\n",
    "            print ('Pasta para JSON criada com sucesso!')\n",
    "\n",
    "        if os.path.isdir(caminho+'/fig'):\n",
    "            print ('Pasta para figuras já existe!')\n",
    "        else:\n",
    "            os.mkdir(caminho+'/fig')\n",
    "            print ('Pasta para figuras criada com sucesso!')\n",
    "\n",
    "        if os.path.isdir(caminho+'/output'):\n",
    "            print ('Pasta para saídas já existe!')\n",
    "        else:\n",
    "            os.mkdir(caminho+'/output')\n",
    "            print ('Pasta para saídas criada com sucesso!')            \n",
    "\n",
    "    pathzip  = caminho+'/xml_zip/'\n",
    "    pathcsv  = caminho+'/csv/'\n",
    "    pathjson = caminho+'/json/'\n",
    "    pathfig  = caminho+'/fig/'\n",
    "    pathaux  = caminho+'/'\n",
    "    pathout  = caminho+'/output/'\n",
    "\n",
    "    print('\\nCaminho da pasta raiz', pathaux)\n",
    "    print('Caminho arquivos  XML', pathzip)\n",
    "    print('Caminho arquivos JSON', pathjson)\n",
    "    print('Caminho arquivos  CSV', pathcsv)\n",
    "    print('Caminho para  figuras', pathfig)\n",
    "    print('Pasta arquivos saídas', pathout)\n",
    "    \n",
    "    return pathzip, pathcsv, pathjson, pathfig, pathaux, pathout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Localização das pastas e dados de origem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta armazenagem local c:\\kgfioce\\\n",
      "\n",
      "Pasta para os xml já existe!\n",
      "Pasta para os CSV já existe!\n",
      "Pasta para os JSON já existe!\n",
      "Pasta para figuras já existe!\n",
      "Pasta para saídas já existe!\n",
      "\n",
      "Caminho da pasta raiz c:\\kgfioce\\/\n",
      "Caminho arquivos  XML c:\\kgfioce\\/xml_zip/\n",
      "Caminho arquivos JSON c:\\kgfioce\\/json/\n",
      "Caminho arquivos  CSV c:\\kgfioce\\/csv/\n",
      "Caminho para  figuras c:\\kgfioce\\/fig/\n",
      "Pasta arquivos saídas c:\\kgfioce\\/output/\n",
      "\n",
      "T01 Importação e Preparação das pastas de trabalho: 00h 00m 02s\n"
     ]
    }
   ],
   "source": [
    "#pastaraiz = 'kgfioce'\n",
    "programa  = 'FiocruzCE'\n",
    "\n",
    "nome_ppos_graduação = 'CIÊNCIAS DA SAÚDE'\n",
    "\n",
    "pathzip, pathcsv, pathjson, pathfig, pathaux, pathout = preparar_pastas(data_storage_path)\n",
    "\n",
    "t01 = time.time()\n",
    "print('\\nT01 Importação e Preparação das pastas de trabalho:', tempo(t00,t01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <center><b>IMPLEMENTAR SCRIPTS DE EXTRAÇÃO</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de extração e organização de dados de docentes em lote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- path_to_image_html(path)\n",
    "- show_im()\n",
    "- foto()\n",
    "- retry(func, expected_ex_type=Exception, limit=0, wait_ms=50, wait_increase_ratio=2, logger=None, on_exhaust=\"throw\")\n",
    "- achar_busca(browser, delay)\n",
    "- definir_filtros(browser, delay, assunto=False, todosniveis=False)\n",
    "- acessar_busca(browser, delay)\n",
    "- preencher_busca(browser, delay, NOME)\n",
    "- paginar(browser)\n",
    "- restante(lista_nomes, df_dados)\n",
    "- extrair_emlote(lista_nomes, assunto=False, todosniveis=False)\n",
    "- procurar_vinculos(NOME, instituicao, unidade, termo, browser, delay, limite)\n",
    "- extrair_lista_discentes(lista_nomes, instituicao='Fiocruz', unidade='Fiocruz Ceará', termo='Ministério da Saúde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções assessórias para extrair dados dos currículo, sem download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- retry()\n",
    "- detect_error(html_text)\n",
    "- conectar_busca()\n",
    "- preencher_busca(browser, delay, NOME)\n",
    "- achar_busca(browser, delay)\n",
    "- paginar(browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonte: https://github.com/davidohana/python-retry-func/blob/master/retry.py\n",
    "# davidohana/python-retry-func is licensed under the Apache License 2.0\n",
    "\n",
    "delay=10\n",
    "\n",
    "def retry(func,\n",
    "          expected_ex_type=Exception,\n",
    "          limit=0,\n",
    "          wait_ms=100,\n",
    "          wait_increase_ratio=2,\n",
    "          logger=None,\n",
    "          on_exhaust=\"throw\"\n",
    "          ):\n",
    "    \"\"\"\n",
    "    Retry a function invocation until no exception occurs\n",
    "    :param func: function to invoke\n",
    "    :param expected_ex_type: retry only if exception is subclass of this type\n",
    "    :param limit: maximum number of invocation attempts, 0 for unlimited attempts.\n",
    "    :param wait_ms: initial wait time after each attempt in milliseconds.\n",
    "    :param wait_increase_ratio: increase wait period by multiplying this value after each attempt.\n",
    "    :param logger: if not None, retry attempts will be logged to this logging.logger\n",
    "    :param on_exhaust: return value when retry attempts exhausted. Default is \"throw\" which will rethrow the exception\n",
    "                 of the last attempt.\n",
    "    :return: result of first successful invocation\n",
    "    :raises: last invocation exception if attempts exhausted or exception is not an instance of ex_type\n",
    "    \"\"\"\n",
    "\n",
    "    attempt = 1\n",
    "    while True:\n",
    "        try:\n",
    "            return func()\n",
    "        except Exception as ex:\n",
    "            if not isinstance(ex, expected_ex_type):\n",
    "                raise ex\n",
    "\n",
    "            if logger:\n",
    "                logger.error(\"Failed execution attempt #%d\", attempt, exc_info=ex)\n",
    "\n",
    "            # check if attempts exhausted\n",
    "            if 0 < limit <= attempt:\n",
    "                if logger:\n",
    "                    logger.warning(\"Attempt limit (%d) reached\", limit)\n",
    "                if on_exhaust == \"throw\":\n",
    "                    raise ex\n",
    "                return on_exhaust\n",
    "\n",
    "            # prepare for next attempt\n",
    "            attempt += 1\n",
    "            if logger:\n",
    "                logger.info(\"Waiting %d ms before attempt #%d\", wait_ms, attempt)\n",
    "            time.sleep(wait_ms / 1000)\n",
    "            wait_ms *= wait_increase_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, TimeoutException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys    \n",
    "from selenium.webdriver.common.by import By\n",
    "import traceback\n",
    "import time\n",
    "\n",
    "def detect_error(html_text):\n",
    "    if \"Stale file handle\" in html_text:\n",
    "        raise Exception(\"Stale file handle detected.\")\n",
    "\n",
    "def conectar_busca():    \n",
    "    ## https://www.selenium.dev/documentation/pt-br/webdriver/browser_manipulation/\n",
    "    print(f'Conectando com o servidor do CNPq...')\n",
    "    # print(f'Iniciada extração de {len(lista_nomes)} currículos')\n",
    "    t0=time.time()\n",
    "    options   = Options()\n",
    "    # options.add_argument(\"--headless\")\n",
    "    \n",
    "    chromedriver_path = config.get(\"Chromedriver_Path\", \"Default_Value\")\n",
    "    driver_path = chromedriver_path+'/chromedriver.exe'\n",
    "    service = Service(driver_path)\n",
    "    browser = webdriver.Chrome(service=service)    \n",
    "    \n",
    "    url_buscaespecialista = 'http://buscatextual.cnpq.br/buscatextual/busca.do?buscarDoutores=true&buscarDemais=false&textoBusca='\n",
    "    browser.get(url_buscaespecialista) # acessa a url de busca do CNPQ   \n",
    "    browser.set_window_position(-20, -10)\n",
    "    browser.set_window_size(170, 1896)\n",
    "    browser.mouse = webdriver.ActionChains(browser)\n",
    "    # url        = browser.command_executor._url #\"http://127.0.0.1:60622/hub\"\n",
    "    # session_id = browser.session_id            #'4e167f26-dc1d-4f51-a207-f761eaf73c31'\n",
    "    # t1 = time.time()\n",
    "    # tcon = tempo(t0,t1)\n",
    "    # print(f'{tcon} para conectar ao servidor do CNPq')\n",
    "    # print('Conectado com sucesso em:', url, session_id)   \n",
    "    time.sleep(0.00001)\n",
    "    # return browser, url, session_id\n",
    "    return browser\n",
    "    \n",
    "def preencher_busca(browser, delay, NOME):\n",
    "    \"\"\"\n",
    "    Função para passar o nome para campo de busca\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nome = lambda: browser.find_element(By.CSS_SELECTOR, (\"#textoBusca\"))\n",
    "        nome().send_keys(Keys.CONTROL + \"a\")\n",
    "        nome().send_keys(NOME)\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        seletorcss = 'div.layout-cell-12:nth-child(8) > div:nth-child(1) > div:nth-child(1) > a:nth-child(1)'\n",
    "        WebDriverWait(browser, delay).until(EC.element_to_be_clickable((By.CSS_SELECTOR, seletorcss))).click()\n",
    "\n",
    "        # seletorcss = \"#botaoBuscaFiltros\"\n",
    "        # WebDriverWait(browser, delay).until(EC.element_to_be_clickable((By.CSS_SELECTOR, seletorcss)))\n",
    "\n",
    "        # Retrieve the HTML content to check for error\n",
    "        html_content = browser.page_source\n",
    "        detect_error(html_content)\n",
    "\n",
    "    except Exception as e:\n",
    "        traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "        print('Erro ao preencher nome no campo de busca, pausando por 1 segundo')\n",
    "        print(e)\n",
    "        \n",
    "        # Check if the error is 'Stale file handle'\n",
    "        if \"Stale file handle\" in str(e):\n",
    "            print(\"Detectado erro 'Stale file handle'. Voltando...\")\n",
    "            time.sleep(2)  # Pause for 2 seconds before clicking the back button\n",
    "            browser.execute_script(\"window.history.go(-1)\")  # Execute JavaScript to navigate back\n",
    "            \n",
    "        time.sleep(1.5)\n",
    "    \n",
    "def achar_busca(browser, delay):\n",
    "    '''\n",
    "    Função para clicar no botão Buscar Currículo\n",
    "    '''\n",
    "    \n",
    "    delay=10\n",
    "    try:\n",
    "        limite=5\n",
    "        xpath_nome = \"/html/body/form/div/div[4]/div/div/div/div[3]/div/div[3]/ol/li/b\"\n",
    "        retry(WebDriverWait(browser, delay).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, xpath_nome))),\n",
    "            #    expected_ex_type=ZeroDivisionError, \n",
    "               wait_ms=20,\n",
    "               limit=limite, \n",
    "            #    logger=logger, \n",
    "               on_exhaust=(f'Problema ao acessar ao servidor do CNpQ função definir_filtros(). {limite} tentativas sem sucesso.'))   \n",
    "\n",
    "        link_nome  = browser.find_element(By.XPATH, xpath_nome)\n",
    "        # ActionChains(browser).move_to_element(link_nome).perform()\n",
    "        \n",
    "        # Avaliar 'Stale file handle'\n",
    "        if link_nome.text == None:\n",
    "            xpath_nome = '/html/body/form/div/div[4]/div/div/div/div[3]/div/div[3]/ol/li'\n",
    "            \n",
    "            print('Sem resposta do servidor, tentando novamente...')\n",
    "            retry(WebDriverWait(browser, delay).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, xpath_nome))),\n",
    "            #    expected_ex_type=ZeroDivisionError, \n",
    "               wait_ms=200,\n",
    "               limit=limite, \n",
    "            #    logger=logger, \n",
    "               on_exhaust=(f'Problema ao acessar ao servidor do CNpQ função definir_filtros(). {limite} tentativas sem sucesso.'))   \n",
    "\n",
    "        return link_nome\n",
    "\n",
    "    except TimeoutException as t:\n",
    "        print(f'Erro de conexão durante achar_busca(). Reiniciando a função dentro de 2 segundos...')\n",
    "        time.sleep(2)\n",
    "\n",
    "def paginar(browser):\n",
    "    try:\n",
    "        css_paginacao=\"div.paginacao:nth-child(2)\"  #seletorcss=\"div.paginacao:nth-child(4) > a:nth-child(2)\"\n",
    "        WebDriverWait(browser, delay).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, css_paginacao)))\n",
    "        paginacao = browser.find_element(By.CSS_SELECTOR, css_paginacao)\n",
    "        paginas=paginacao.text.split(' ')\n",
    "        remover=['','anterior','...']\n",
    "        numpaginas = [x for x in paginas if x not in remover]\n",
    "        # print('NumPáginas interno:',numpaginas)\n",
    "    except Exception as e:\n",
    "        print('Erro ao utilizar função paginar():', e)\n",
    "    return numpaginas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementar funções para extrair dados do Lattes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS.: Para efetuar instalações em ambientes com SSL você pode precisar adicionar pelo menos dois parâmetros:\n",
    "\n",
    "    Parâmetro 1 :--trusted-host pypi.org\n",
    "    Parâmetro 2 :--trusted-host files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyjarowinkler --trusted-host pypi.org --trusted-host files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\fioce\\chromedriver\n",
      "c:\\kgfioce\\\n"
     ]
    }
   ],
   "source": [
    "print(config.get(\"Chromedriver_Path\", \"Default_Value\"))\n",
    "print(config.get(\"Data_Storage_Path\", \"Default_Value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procurar_vinculos(NOME, instituicao, unidade, termo, browser, delay, limite):\n",
    "    from selenium.common import exceptions\n",
    "    from pyjarowinkler.distance import get_jaro_distance\n",
    "    ignored_exceptions=(NoSuchElementException,StaleElementReferenceException,)\n",
    "    ## Receber a quantidade de opções ao ler elementos de resultados\n",
    "    duvidas   = []\n",
    "    force_break_loop = False\n",
    "    try:\n",
    "        css_resultados = \".resultado\"\n",
    "        WebDriverWait(browser, delay).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, css_resultados)))\n",
    "        resultados = browser.find_elements(By.CSS_SELECTOR, css_resultados)       \n",
    "        ## Ler quantidade de resultados apresentados pela busca de nome\n",
    "        # try:\n",
    "        #     css_qteresultados = \".tit_form > b:nth-child(1)\"\n",
    "        #     WebDriverWait(browser, delay).until(\n",
    "        #         EC.presence_of_element_located((By.CSS_SELECTOR, css_qteresultados)))                       \n",
    "        #     soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "        #     div_element = soup.find('div', {'class': 'tit_form'})\n",
    "        #     match = re.search(r'<b>(\\d+)</b>', str(div_element))\n",
    "        #     if match:\n",
    "        #         qte_resultados = int(match.group(1))\n",
    "        #         if qte_resultados >1:\n",
    "        #             print(f'{qte_resultados} resultados para {NOME}')\n",
    "        #     else:\n",
    "        #         raise Exception\n",
    "        # except Exception as e:\n",
    "        #     print('Erro ao ler a quantidade de resultados:')\n",
    "        #     print(e)\n",
    "        #     return np.NaN, NOME, np.NaN, e, browser\n",
    "        try:\n",
    "            css_qteresultados = \".tit_form > b:nth-child(1)\"\n",
    "            WebDriverWait(browser, delay).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, css_qteresultados)))\n",
    "\n",
    "            soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "            # Check for 'Stale file handle' in HTML content\n",
    "            if 'Stale file handle' in soup.get_text():\n",
    "                raise Exception(\"Erro 'Stale file handle' na resposta HTML do servidor CNPq.\")\n",
    "\n",
    "            div_element = soup.find('div', {'class': 'tit_form'})\n",
    "            match = re.search(r'<b>(\\d+)</b>', str(div_element))\n",
    "            if match:\n",
    "                qte_resultados = int(match.group(1))\n",
    "                if qte_resultados > 1:\n",
    "                    print(f'{qte_resultados} resultados para {NOME}')\n",
    "            else:\n",
    "                raise Exception(\"Não foi possível achar uma quantidade de resultados com procurar_vinculos.\")\n",
    "        except Exception as e:\n",
    "            print('Erro ao ler a quantidade de resultados:')\n",
    "            print(e)\n",
    "            return np.NaN, NOME, np.NaN, e, browser        \n",
    "        \n",
    "        ## Escolher função a partir da quantidade de resultados da lista apresentada na busca\n",
    "        ## Ao achar clica no elemento elm_vinculo com link do nome para abrir o currículo\n",
    "        numpaginas = paginar(browser)\n",
    "        if numpaginas == [] and qte_resultados==1:\n",
    "            # capturar link para o primeiro nome resultado da busca\n",
    "            try:\n",
    "                css_linknome = \".resultado > ol:nth-child(1) > li:nth-child(1) > b:nth-child(1) > a:nth-child(1)\"\n",
    "                WebDriverWait(browser, delay).until(EC.presence_of_element_located((By.CSS_SELECTOR, css_linknome)))            \n",
    "                elm_vinculo  = browser.find_element(By.CSS_SELECTOR, css_linknome)\n",
    "                nome_vinculo = elm_vinculo.text\n",
    "            except Exception as e:\n",
    "                print('Erro ao encontrar o primeiro resultado da lista de nomes:',e)\n",
    "                return np.NaN, NOME, np.NaN, e, browser\n",
    "            # print('Clicar no nome único:', nome_vinculo)\n",
    "            try:\n",
    "                retry(ActionChains(browser).click(elm_vinculo).perform(),\n",
    "                       wait_ms=20,\n",
    "                       limit=limite,\n",
    "                       on_exhaust=(f'Problema ao clicar no link do nome. {limite} tentativas sem sucesso.'))   \n",
    "            except Exception as e:\n",
    "                print('Erro ao clicar no único nome encontrado anteriormente',e)\n",
    "                return np.NaN, NOME, np.NaN, e, browser\n",
    "        \n",
    "        ## Quantidade de resultados até 10 currículos, acessados sem paginação\n",
    "        else:\n",
    "            print(f'{qte_resultados} currículos de homônimos em potencial...')\n",
    "            numpaginas = paginar(browser)\n",
    "            numpaginas.append('próximo')\n",
    "            iteracoes=0\n",
    "            ## iterar em cada página de resultados\n",
    "            pagin = qte_resultados//10+1\n",
    "            for i in range(pagin+1):\n",
    "                # print(i,'/',pagin)\n",
    "                iteracoes+=1\n",
    "                try:\n",
    "                    numpaginas = paginar(browser)\n",
    "                    print(f'Iteração: {iteracoes}. Páginas sendo lidas: {numpaginas}')\n",
    "                    css_resultados = \".resultado\"\n",
    "                    WebDriverWait(browser, delay).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, css_resultados)))\n",
    "                    resultados = browser.find_elements(By.CSS_SELECTOR, css_resultados)\n",
    "                except Exception as e:\n",
    "                    print('Erro ao paginar:',e)\n",
    "                ## iterar em cada resultado\n",
    "                for n,i in enumerate(resultados):\n",
    "                    linhas = i.text.split('\\n\\n')\n",
    "                    # print(linhas)\n",
    "                    if 'Stale file handle' in str(linhas):\n",
    "                        return np.NaN, NOME, np.NaN, 'Stale file handle', browser\n",
    "                    for m,linha in enumerate(linhas):\n",
    "                        # print(f'\\nOrdem da linha: {m+1}, de total de linhas {len(linhas)}')\n",
    "                        # print('Conteúdo da linha:',linha.lower())\n",
    "                        print(linha)\n",
    "                        try:\n",
    "                            if instituicao.lower() in linha.lower() or unidade.lower() in linha.lower() or termo.lower() in linha.lower():\n",
    "                                # print('Vínculo encontrado!')\n",
    "                                count=m\n",
    "                                # print(' NOME:', NOME, type(NOME))\n",
    "                                # test = linhas[count].split('\\n')[0]\n",
    "                                # print('TESTE:',test, type(test))\n",
    "                                while get_jaro_distance(linhas[count].split('\\n')[0], str(NOME)) < 0.75:\n",
    "                                    count-=1\n",
    "                                print('Identificado vínculo com o interesse de análise no resultado:', m+1)\n",
    "                                nome_vinculo = linhas[count].strip()\n",
    "                                print(f'    Achado: {nome_vinculo}')\n",
    "                                try:\n",
    "                                    css_vinculo = f\".resultado > ol:nth-child(1) > li:nth-child({m+1}) > b:nth-child(1) > a:nth-child(1)\"\n",
    "                                    # print('\\nCSS_SELECTOR usado:', css_vinculo)\n",
    "                                    css_alvo = '.resultado > ol:nth-child(1) > li:nth-child(7) > b:nth-child(1) > a:nth-child(1)'\n",
    "                                    WebDriverWait(browser, delay).until(EC.presence_of_element_located((By.CSS_SELECTOR, css_vinculo)))            \n",
    "                                    elm_vinculo  = browser.find_element(By.CSS_SELECTOR, css_vinculo)\n",
    "                                    nome_vinculo = elm_vinculo.text\n",
    "                                    # print('Elemento retornado:',nome_vinculo)\n",
    "                                    retry(ActionChains(browser).click(elm_vinculo).perform(),\n",
    "                                        wait_ms=100,\n",
    "                                        limit=limite,\n",
    "                                        on_exhaust=(f'Problema ao clicar no link do nome. {limite} tentativas sem sucesso.'))            \n",
    "                                except Exception as e:\n",
    "                                    print('Erro ao achar o link do nome com múltiplos resultados')\n",
    "                                    return np.NaN, NOME, np.NaN, e, browser\n",
    "                                force_break_loop = True\n",
    "                                break\n",
    "                        except Exception as e2:\n",
    "                            traceback_str = ''.join(traceback.format_tb(e2.__traceback__))\n",
    "                            print('Erro ao procurar vínculo com currículos achados')    \n",
    "                            print(e2,traceback_str)\n",
    "                        ## Caso percorra todos elementos da lista e não encontre vínculo adiciona à dúvidas quanto ao nome\n",
    "                        if m==(qte_resultados):\n",
    "                            print(f'Não encontrada nenhuma referência à {instituicao} ou ao {unidade} ou ao termo {termo}')\n",
    "                            duvidas.append(NOME)\n",
    "                            # clear_output(wait=True)\n",
    "                            # browser.quit()\n",
    "                            continue\n",
    "                    if force_break_loop:\n",
    "                        break\n",
    "                try:\n",
    "                    prox = browser.find_element(By.PARTIAL_LINK_TEXT, 'próximo')\n",
    "                    prox.click()\n",
    "                except:\n",
    "                    continue\n",
    "        try:\n",
    "            elm_vinculo.text\n",
    "            # print(f'Nomes: {NOME} | {elm_vinculo.text}')\n",
    "        except:\n",
    "            return np.NaN, NOME, np.NaN, 'Vínculo não encontrado', browser\n",
    "    except Exception as err:\n",
    "        print('Erro ao sair da função procurar_vinculos()')\n",
    "        print('Conteúdo do erro:',err)\n",
    "        return np.NaN, NOME, np.NaN, err, browser\n",
    "    return elm_vinculo, np.NaN, np.NaN, np.NaN, browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def garantir_checkbox_marcado(browser, css_selector):\n",
    "    try:\n",
    "        checkbox = browser.find_element(By.CSS_SELECTOR, css_selector)\n",
    "        \n",
    "        if not checkbox.is_selected():\n",
    "            checkbox.click()\n",
    "            print(\"Checkbox buscar todos níveis de formação marcado.\")\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        print(f\"Checkbox com o seletor {css_selector} não encontrado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao tentar marcar o checkbox: {e}\")\n",
    "\n",
    "def garantir_checkbox_desmarcado(browser, css_selector):\n",
    "    try:\n",
    "        checkbox = browser.find_element(By.CSS_SELECTOR, css_selector)\n",
    "        \n",
    "        if checkbox.is_selected():\n",
    "            checkbox.click()\n",
    "            print(\"Checkbox desmarcado.\")\n",
    "        else:\n",
    "            print(\"Checkbox já estava desmarcado.\")\n",
    "    \n",
    "    except NoSuchElementException:\n",
    "        print(f\"Checkbox com o seletor {css_selector} não encontrado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao tentar desmarcar o checkbox: {e}\")\n",
    "\n",
    "def definir_filtros(browser, delay, mestres, assunto):\n",
    "    '''\n",
    "    Clica nos check-boxes para definir os filtros de buscas\n",
    "    Para buscar por Assuntos usar parâmetro True, caso omitido fará busca por Nome por default\n",
    "    '''\n",
    "    from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException, TimeoutException\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.common.by import By\n",
    "    import traceback   \n",
    "    \n",
    "    ## Aguardar carregar e clicar em checkbox de Assunto\n",
    "    try:\n",
    "        if mestres:\n",
    "            limite=2\n",
    "            ## Aguardar opção dropdown ser carregada e clicar em sua checkbox\n",
    "            css_buscar_demais = '#buscarDemais'\n",
    "            garantir_checkbox_marcado(browser, css_buscar_demais)\n",
    "        # css_estrangeiros  = '#buscarEstrangeiros'\n",
    "\n",
    "        if assunto == True:\n",
    "            ## Implementar número de retentativas para casos de conexão muito instável\n",
    "            limite=5\n",
    "            retry(WebDriverWait(browser, delay).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"#buscaAssunto\"))).click(),\n",
    "                #    expected_ex_type=ZeroDivisionError, \n",
    "                   wait_ms=200,\n",
    "                   limit=limite, \n",
    "                #    logger=logger, \n",
    "                   on_exhaust=(f'Problema ao acessar ao servidor do CNpQ função definir_filtros(). {limite} tentativas sem sucesso.'))   \n",
    "        \n",
    "            ## Aguardar opção Atuação Profissional ser carregada e clicar em sua checkbox\n",
    "            xpath_atuacaoprofissional = \".//*[contains(text(), 'Atuação profissional')]\"\n",
    "            WebDriverWait(browser, delay).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, xpath_atuacaoprofissional))).click()\n",
    "\n",
    "            ## Aguardar opção Ciências da Saúde ser carregada e clicar em sua checkbox\n",
    "            xpath_cienciassaude = \".//*[contains(text(), 'Ciências da Saúde')]\"\n",
    "            WebDriverWait(browser, delay).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, xpath_cienciassaude))).click()\n",
    "            #browser.find_element_by_xpath(xpath_cienciassaude).click()        \n",
    "\n",
    "            ## Aguardar opção Enfermagem ser carregada e clicar em sua checkbox\n",
    "            xpath_enfermagem    = \".//*[contains(text(), 'Enfermagem')]\"\n",
    "            WebDriverWait(browser, delay).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, xpath_enfermagem))).click()\n",
    "            #browser.find_element_by_xpath(xpath_enfermagem).click()\n",
    "            aplicar_link  = browser.find_element(By.LINK_TEXT, 'Aplicar')\n",
    "            aplicar_link.click()\n",
    "   \n",
    "    except Exception as e:\n",
    "        print(f'Erro na função definir_filtros()')\n",
    "        print(e)\n",
    "        # traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "        # print(e, traceback_str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nova_consulta(browser):\n",
    "    try:\n",
    "        btn_filtros = WebDriverWait(browser, delay).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//*[@id='botaoBuscaFiltros']\")))\n",
    "        btn_filtros.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Erro ao reiniciar consulta')\n",
    "        traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "        print(e,traceback_str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_dados(lista_nomes, mestres=True, assunto=False):\n",
    "    '''Extrai as informações brutas de publicações (artigos e livros) de cada currículo da Plataforma Lattes do CNPQ\n",
    "     Recebe: Uma lista de nomes a ser buscada na base do currículo Lattes\n",
    "    Utiliza: Funções: definir_filtros(), montar_dfcolab_linhas()\n",
    "    Retorna: Três dataframes: df_identificacao com dados da identificação; \n",
    "                              df_dados com dados de todas produções; e \n",
    "                              df_colabartigos com dados das colaborações em artigos\n",
    "    Autor: Marcos Aires (Jan 2022)\n",
    "    '''\n",
    "    import time\n",
    "    from datetime import date\n",
    "    t0=time.time()\n",
    "    \n",
    "    instituicao = 'Fundação Oswaldo Cruz'\n",
    "    unidade     = 'Fiocruz Ceará'\n",
    "    termo       = 'Ministerio da Saude'\n",
    "\n",
    "    browser=conectar_busca()\n",
    "    browser.set_window_position(-20, -10)\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    producao_bibliografica_div = soup.find('div', {'id': 'artigos-completos'})\n",
    "    size    = browser.get_window_size()\n",
    "    width1  = size.get(\"width\")\n",
    "    height1 = size.get(\"height\")\n",
    "    browser.set_window_size(170, 1896)\n",
    "    browser.mouse = webdriver.ActionChains(browser)\n",
    "    delay   = 20  # seconds \n",
    "    limite  = 5\n",
    "    \n",
    "    df_dados          = pd.DataFrame()   \n",
    "    rotulos           = []\n",
    "    conteudos         = []\n",
    "    curriculos        = []\n",
    "    falhas            = []\n",
    "    duvidas           = []\n",
    "    sucesso           = []\n",
    "    tipo_erro         = []\n",
    "\n",
    "    # df_parcial = pd.DataFrame({     \n",
    "    #         'NOMES': pd.Series(sucesso),\n",
    "    #         'ROTULOS': pd.Series(rotulos),\n",
    "    #         'CONTEUDOS': pd.Series(conteudos),                    \n",
    "    #     })\n",
    "\n",
    "    t1=time.time()\n",
    "    print(tempo(t0,t1), 'Tempo de conexão ao servidor do CNPq')\n",
    "    time.sleep(0.00001)\n",
    "            \n",
    "    count=0\n",
    "    for NOME in lista_nomes:\n",
    "        try:\n",
    "            # Definir filtros para busca de nomes\n",
    "            if mestres:\n",
    "                css_buscar_demais = '#buscarDemais'\n",
    "                garantir_checkbox_marcado(browser, css_buscar_demais)\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            if assunto:\n",
    "                css_buscar_demais = '#buscaAssunto'\n",
    "                garantir_checkbox_marcado(browser, css_buscar_demais)\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            print('-'*90)\n",
    "            count+=1\n",
    "            t2       = time.time()\n",
    "            tdec     = np.round(t2-t0,2)\n",
    "            restante = len(lista_nomes)-count\n",
    "            print(f'Extraindo currículo {count}/{len(lista_nomes)}. Resta {restante}. Decorrido:{horas(tdec)}. Previsão de término em {horas(np.round(tdec/count,0)*(restante+1))}')\n",
    "            preencher_busca(browser, delay, NOME)\n",
    "            window_before  = browser.current_window_handle\n",
    "            \n",
    "            # t2a = time.time()\n",
    "            elemento_achado, nome_falha, duvida, erro, browser = procurar_vinculos(NOME, instituicao, unidade, termo, browser, delay, limite)\n",
    "\n",
    "            if str(elemento_achado) == 'nan':\n",
    "                print('Vínculo não encontrado, passando ao próximo nome...')\n",
    "                falhas.append(nome_falha)\n",
    "                duvidas.append(duvida)\n",
    "                tipo_erro.append(erro)\n",
    "                # print(nome_falha)\n",
    "                # print(erro)\n",
    "                # clear_output(wait=True)\n",
    "                raise Exception\n",
    "\n",
    "            print('Vínculo encontrado no currículo de nome:',elemento_achado.text)\n",
    "\n",
    "            # t2b = time.time()\n",
    "            # print(f'{tempo(t2a,t2b)} para achar e escolher o currículo com vínculo: ')\n",
    "\n",
    "            ## Clicar no botão abrir currículo e mudar de aba\n",
    "            try:\n",
    "                ## Aguarda, encontra, clica em buscar nome\n",
    "                link_nome    = achar_busca(browser, delay)\n",
    "                nome_buscado = []\n",
    "                nome_achado  = []\n",
    "                nome_buscado.append(NOME)\n",
    "                \n",
    "                if link_nome.text == None:\n",
    "                    xpath_nome = '/html/body/form/div/div[4]/div/div/div/div[3]/div/div[3]/ol/li'\n",
    "                    # 'Stale file handle'\n",
    "                    print('Ainda sem resposta do servidor, tentando novamente...')\n",
    "                    retry(WebDriverWait(browser, delay).until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, xpath_nome))),\n",
    "                    #    expected_ex_type=ZeroDivisionError, \n",
    "                    wait_ms=200,\n",
    "                    limit=limite, \n",
    "                    #    logger=logger, \n",
    "                    on_exhaust=(f'Problema ao acessar ao servidor do CNpQ função definir_filtros(). {limite} tentativas sem sucesso.'))\n",
    "                try:\n",
    "                    ActionChains(browser).click(link_nome).perform()\n",
    "                    nome_achado.append(link_nome.text)\n",
    "                except:\n",
    "                    print(f'Currículo não encontrado para: {NOME}.')\n",
    "                    return\n",
    "                \n",
    "                retry(WebDriverWait(browser, delay).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, \"#idbtnabrircurriculo\"))),\n",
    "                    #    expected_ex_type=ZeroDivisionError, \n",
    "                    wait_ms=200,\n",
    "                    limit=limite, \n",
    "                    #    logger=logger, \n",
    "                    on_exhaust=(f'Problema ao acessar ao servidor do CNpQ função definir_filtros(). {limite} tentativas sem sucesso.'))   \n",
    "                \n",
    "                btn_abrir_curriculo = WebDriverWait(browser, delay).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, \"#idbtnabrircurriculo\")))\n",
    "                time.sleep(0.2)\n",
    "                ActionChains(browser).click(btn_abrir_curriculo).perform()\n",
    "\n",
    "                ## Gerenciamento das janelas abertas no browser\n",
    "                WebDriverWait(browser, delay).until(EC.number_of_windows_to_be(2))\n",
    "                window_after = browser.window_handles\n",
    "                new_window   = [x for x in window_after if x != window_before][0]\n",
    "                browser.switch_to.window(new_window)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print('Erro',e)\n",
    "                print('Tentando nova requisição ao servidor')\n",
    "                time.sleep(1)\n",
    "                btn_abrir_curriculo = WebDriverWait(browser, delay).until(\n",
    "                    EC.presence_of_element_located((By.CSS_SELECTOR, \"#idbtnabrircurriculo\")))\n",
    "                ActionChains(browser).click(btn_abrir_curriculo).perform()\n",
    "                WebDriverWait(browser, delay).until(EC.number_of_windows_to_be(2))\n",
    "\n",
    "                ## Gerenciamento das janelas abertas no browser\n",
    "                window_after = browser.window_handles\n",
    "                new_window   = [x for x in window_after if x != window_before][0]\n",
    "                browser.switch_to.window(new_window)\n",
    "                time.sleep(1)\n",
    "\n",
    "            t3=time.time()\n",
    "\n",
    "            ## O objeto elementos_id abaixo é uma lista de elementos onde as informações de identificação estão contidas\n",
    "            # acessado através do marcador xpath='//div[@class=\"infpessoa\"]' no HTML para extrair de cada pesquisador\n",
    "            time.sleep(1)\n",
    "            xpath='//div[@class=\"infpessoa\"]'\n",
    "            WebDriverWait(browser, delay).until(\n",
    "                    EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "            elementos_id = browser.find_elements(By.XPATH, xpath)\n",
    "\n",
    "            # Fazer com que a primeira informação para cada pesquisador seja o caminho para sua foto e dados de identificação\n",
    "            try:\n",
    "                css_selector='.foto'\n",
    "                link_foto=WebDriverWait(browser, delay).until(\n",
    "                    EC.visibility_of_element_located((By.CSS_SELECTOR, \".foto\"))).get_attribute(\"src\")\n",
    "                rotulos.append('Link Foto:')\n",
    "                conteudos.append(link_foto)\n",
    "                curriculos.append(NOME)            \n",
    "\n",
    "            except Exception as e:\n",
    "                traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "                print('  !!Erro ao extrair imagem do currículo:',e,'\\n', traceback_str)\n",
    "\n",
    "            for i in range(len(elementos_id)):\n",
    "                dados = elementos_id[i].text.split('\\n')\n",
    "                for i in range(len(dados)):\n",
    "                    if i==0:\n",
    "                        rotulos.append('Nome completo:')\n",
    "                        conteudos.append(dados[i])\n",
    "                        curriculos.append(NOME)\n",
    "                    elif 'Bolsista' in dados[i]:\n",
    "                        rotulos.append('Bolsista CNPq:')\n",
    "                        conteudos.append(dados[i])\n",
    "                        curriculos.append(NOME)\n",
    "                    elif 'Endereço para acessar este CV: ' in dados[i]:\n",
    "                        rotulos.append('Link Currículo:')\n",
    "                        conteudos.append(dados[i].strip('Endereço para acessar este CV: '))\n",
    "                        curriculos.append(NOME)\n",
    "                    elif 'ID Lattes: ' in dados[i]:\n",
    "                        rotulos.append('ID Lattes:')\n",
    "                        conteudos.append(dados[i].strip('ID Lattes: '))\n",
    "                        curriculos.append(NOME)\n",
    "                    elif 'Última atualização do currículo em ' in dados[i]:\n",
    "                        rotulos.append('Data atualização:')\n",
    "                        conteudos.append(dados[i].strip('Última atualização do currículo em '))\n",
    "                        curriculos.append(NOME)\n",
    "                        dt_atualizacao = dados[i].strip('Última atualização do currículo em ')\n",
    "                        dtt = datetime.strptime(dt_atualizacao, '%d/%m/%Y').date()\n",
    "                        defasagem = (date.today()-dtt).days\n",
    "            try: \n",
    "                df_temp =pd.DataFrame({\n",
    "                    'CURRICULO': pd.Series(curriculos),\n",
    "                    'ROTULOS': pd.Series(rotulos),\n",
    "                    'CONTEUDOS': pd.Series(conteudos),\n",
    "                        })\n",
    "                filtro    = 'Link Foto:'\n",
    "                fotos     = df_temp[(df_temp.ROTULOS == filtro)]['CONTEUDOS']\n",
    "                x         = fotos[-1:].index[0]\n",
    "                df_temp.drop(columns=['ROTULOS'], inplace=True)\n",
    "\n",
    "                try:\n",
    "                    foto = HTML(df_temp[x:x+1].to_html(escape=False, formatters=dict(CONTEUDOS=path_to_image_html)))\n",
    "                    display(foto)\n",
    "                    print(f'Atualizado em {dt_atualizacao} há {defasagem:>2} dias | {NOME}')    \n",
    "\n",
    "                except TimeoutException as t:\n",
    "                    print('Demora na conexão com servidor, carregamento da foto cancelado')\n",
    "                    traceback_str = ''.join(traceback.format_tb(t.__traceback__))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print('Erro ao extrair a foto do pesquisador')\n",
    "                traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "                print(e,traceback_str)\n",
    "\n",
    "            t4=time.time()\n",
    "            \n",
    "            try:\n",
    "                ## O objeto ELEMENTOS abaixo é uma lista de elementos onde as informações estão contidas\n",
    "                time.sleep(2)\n",
    "                # A forma antiga .find_elements_by_xpath( deve ser substituída por .find_elements(By.XPATH,\n",
    "                elementos = browser.find_elements(By.XPATH, '//div[@class=\"title-wrapper\"]')\n",
    "\n",
    "                # print('Len Cotainers 01:')\n",
    "                # pprint(elementos)\n",
    "                # for i in elementos:\n",
    "                #     print(i.text)\n",
    "\n",
    "                ## Extração das demais sessões que se organizam em pares rótulo/conteúdo\n",
    "\n",
    "                for i in range(len(elementos)):\n",
    "                    # print(len(elementos))\n",
    "                    sessao=elementos[i].text.split('\\n')[0]\n",
    "                    # print(sessao)\n",
    "                    sessoes=['Formação acadêmica/titulação',\n",
    "                            'Pós-doutorado',\n",
    "                            'Formação Complementar',\n",
    "                            'Linhas de pesquisa',\n",
    "                            'Projetos de pesquisa',\n",
    "                            'Projetos de desenvolvimento',\n",
    "                            'Membro de corpo editorial',\n",
    "                            'Membro de comitê de assessoramento',\n",
    "                            'Revisor de periódico',\n",
    "                            'Áreas de atuação',\n",
    "                            'Prêmios e títulos',\n",
    "                            'Idiomas',\n",
    "                            'Educação e Popularização de C & T',\n",
    "                            'Outras informações relevantes',\n",
    "                            ]\n",
    "\n",
    "                    ## Seção Orientações\n",
    "                    if sessao == 'Orientações':                \n",
    "                        rotulos_subsecoes=[\n",
    "                            'Orientações e supervisões em andamento',\n",
    "                            'Orientações e supervisões concluídas',\n",
    "                        ]\n",
    "\n",
    "                        rotulos_tipo =[\n",
    "                            'Dissertação de mestrado',\n",
    "                            'Tese de doutorado',\n",
    "                            'Supervisão de pós-doutorado',\n",
    "                            'Dissertação de mestrado',\n",
    "                            'Trabalho de conclusão de curso de graduação',\n",
    "                            'Tese de doutorado',\n",
    "                            'Supervisão de pós-doutorado',\n",
    "                            'Iniciação científica',\n",
    "                            'Orientações de outra natureza',\n",
    "                        ]                 \n",
    "                        \n",
    "                        ## Montagem dos dados a partir da extração da seção específica dos containers:\n",
    "                        for i in range(len(elementos)):\n",
    "                            if i != 0:\n",
    "                                secao=elementos[i].text.split('\\n')[0]\n",
    "\n",
    "                                ## Filtra para receber dados somente da seção produção, monta cada linha de dados com a quebra de linha\n",
    "                                if secao == 'Orientações':\n",
    "                                    dados=elementos[i].text.split('\\n')[1:]\n",
    "\n",
    "                        ## Montar a lista de números de linha com os respectivos dados de interesse e dividir em rótulos e conteúdos\n",
    "                        linhas_subsecoes=[]\n",
    "                        linhas_tipos=[]\n",
    "                        linhas_dados=[]\n",
    "                        for i in range(len(dados)):\n",
    "                            for rotulo in rotulos_subsecoes:\n",
    "                                if rotulo in dados[i] and i not in linhas_subsecoes:\n",
    "                                    linhas_subsecoes.append(i)\n",
    "\n",
    "                            for rotulo in rotulos_tipo:\n",
    "                                if rotulo in dados[i] and 'Citações:' not in dados[i] and 'Citações no' not in dados[i] and i not in linhas_tipos:\n",
    "                                    linhas_tipos.append(i)\n",
    "\n",
    "                            if i not in linhas_subsecoes and i not in linhas_tipos and \"Citações no\" not in dados[i] and dados[i] !='':\n",
    "                                linhas_dados.append(dados[i])\n",
    "\n",
    "                        ultima_linha=max(range(len(dados)))\n",
    "                        # print('Última linha:',ultima_linha)\n",
    "                        # print('DadoÚltLinha:',dados[ultima_linha])\n",
    "                        linhas_tipos.append(ultima_linha)\n",
    "\n",
    "                        # print(f'QteTotalLinhas:{len(dados)}, QteDados:{len(linhas_dados)}, QteRotulosCitações:{len(linhas_citacoes)}, QteCitações:{len(linhas_qtecitacoes)}, QteRotulosSubseção:{len(linhas_subsecoes)}, QteRotulosTipos:{len(linhas_tipos)}, QteRotulosRetirar:{len(linhas_retirar)}')\n",
    "\n",
    "                        ## Da lista de espacos monta os pares ordenados de rótulo/conteúdo\n",
    "                        limites_conteudos=[]\n",
    "                        lst_i=linhas_tipos[::1]\n",
    "                        lst_j=linhas_tipos[1::1]\n",
    "                        # print(len(lst_i),lst_i)\n",
    "                        # print(len(lst_j),lst_j)\n",
    "\n",
    "                        for i, j in zip(lst_i,lst_j):\n",
    "                            limites_conteudos.append((i,j))\n",
    "\n",
    "                        # print('LimitesConteúdo:',len(limites_conteudos),limites_conteudos)\n",
    "\n",
    "                        ## Para cada par ordenado separar em colunas de rótulos e coluna de conteúdos\n",
    "                        for i in range(len(limites_conteudos)):\n",
    "                            par=limites_conteudos[i]\n",
    "                            if i<(len(limites_conteudos)-1):\n",
    "                                try:\n",
    "                                    rotulos.append('Orientação '+dados[par[0]])\n",
    "                                    # print('Linhas:', par[0]+1,par[1])\n",
    "                                    conteudos.append(dados[par[0]+1:par[1]])\n",
    "                                    curriculos.append(NOME)\n",
    "                                except:\n",
    "                                    print('Erro ao montar pares ordenados de rótulo/conteúdo')\n",
    "                                    pass\n",
    "                            else:\n",
    "                                try:\n",
    "                                    rotulos.append('Orientação '+dados[par[0]])\n",
    "                                    # print('Linhas:', par[0]+1,par[1])\n",
    "                                    conteudos.append(dados[par[0]+1:par[1]+1])\n",
    "                                    curriculos.append(NOME)\n",
    "                                except:\n",
    "                                    print('Erro ao montar pares ordenados de rótulo/conteúdo')\n",
    "                                    pass\n",
    "\n",
    "                        # Montar dataframe com colunas de rótulos e conteúdos\n",
    "                        # df_orientacoes=pd.DataFrame(zip(rotulos,conteudos), columns=['rotulos','conteudos'])                    \n",
    "                    \n",
    "                    if sessao == 'Identificação':\n",
    "                        dados = elementos[i].text.split('\\n')[1:]\n",
    "                        for i, j in zip(dados[::2], dados[1::2]):\n",
    "                            curriculos.append(NOME)\n",
    "                            rotulos.append(i)\n",
    "                            if i != 'Nome em citações bibliográficas':\n",
    "                                conteudos.append(j)\n",
    "                            else:\n",
    "                                conteudos.append(j.split(';'))\n",
    "                        # print(f'{len(rotulos):>3} Linhas extraídas seção {sessao}...')\n",
    "                    \n",
    "                    ## Seção Produções\n",
    "                    if sessao == 'Produções':\n",
    "                        rotulos_retirar=[\n",
    "                            'Ordenar por', \n",
    "                            'Ordem Cronológica',\n",
    "                            'Número de citações Web of science',\n",
    "                            'Número de citações Scopus',\n",
    "                            'Numero de citações Scielo',\n",
    "                            'Primeiro autor',\n",
    "                            'Impacto JCR',\n",
    "                            'Ordem de Importância',\n",
    "                        ]\n",
    "\n",
    "                        rotulos_citacoes =  [\n",
    "                            'Web of Science',\n",
    "                            'Total de trabalhos',\n",
    "                            'Total de citações',\n",
    "                            'Fator H',\n",
    "                            'SciELO',\n",
    "                            'Total de trabalhos',\n",
    "                            'Total de citações',\n",
    "                            'SCOPUS',\n",
    "                            'Total de trabalhos',\n",
    "                            'Total de citações',\n",
    "                            'Outras',\n",
    "                            'Total de trabalhos',                        \n",
    "                        ]\n",
    "\n",
    "                        rotulos_subsecoes=[\n",
    "                            'Produção bibliográfica',\n",
    "                            'Produção técnica',\n",
    "                            'Demais tipos de produção técnica',\n",
    "                        ]\n",
    "\n",
    "                        rotulos_tipo =[\n",
    "                            'Citações',\n",
    "                            'Artigos completos publicados em periódicos',\n",
    "                            'Livros publicados/organizados ou edições',\n",
    "                            'Capítulos de livros publicados',\n",
    "                            'Textos em jornais de notícias/revistas',\n",
    "                            'Trabalhos completos publicados em anais de congressos',\n",
    "                            'Resumos expandidos publicados em anais de congressos',\n",
    "                            'Resumos publicados em anais de congressos',\n",
    "                            'Resumos publicados em anais de congressos (artigos)',\n",
    "                            'Artigos aceitos para publicação',\n",
    "                            'Apresentações de Trabalho',\n",
    "                            'Outras produções bibliográficas',\n",
    "                            'Assessoria e consultoria',\n",
    "                            'Programas de computador sem registro',\n",
    "                            'Trabalhos técnicos',\n",
    "                            'Entrevistas, mesas redondas, programas e comentários na mídia',\n",
    "                            'Demais tipos de produção técnica',\n",
    "                        ]\n",
    "\n",
    "                        rotulos_qte_citacoes =[\n",
    "                            'Citações:',\n",
    "                        ]\n",
    "\n",
    "                        ## Montagem dos dados a partir da extração da seção específica dos containers:\n",
    "                        for i in range(len(elementos)):\n",
    "                            if i != 0:\n",
    "                                sessao=elementos[i].text.split('\\n')[0]\n",
    "\n",
    "                                ## Filtra para receber dados somente da seção produção, monta cada linha de dados com a quebra de linha\n",
    "                                if sessao == 'Produções':\n",
    "                                    dados=elementos[i].text.split('\\n')[1:]\n",
    "                                    node_name = NOME\n",
    "                                    producoes = []\n",
    "                                    json_data = {\"Node Name\": node_name, \"Properties\": {}}\n",
    "                                    ## Gerar um arquivo JSON com dados da produção bibliográfica para popular o Neo4j\n",
    "                                    try:\n",
    "                                        for artigo_div in producao_bibliografica_div.find_all('div', {'class': 'artigo-completo'}):\n",
    "                                            artigo_dict = {}\n",
    "\n",
    "                                            # Extrair os números de ordem dos artigos\n",
    "                                            ordens = artigo_div.find_all('div', {'class': 'layout-cell-pad-5 text-align-right'})\n",
    "                                            for index, ordem in enumerate(ordens):\n",
    "                                                b_tag = ordem.find('b')\n",
    "                                                # if b_tag:\n",
    "                                                #     print(b_tag.text.strip())\n",
    "                                                \n",
    "                                            try:\n",
    "                                                ano = artigo_div.find('span', {'data-tipo-ordenacao': 'ano'}).text\n",
    "                                            except:\n",
    "                                                ano = None\n",
    "                                            try:\n",
    "                                                prim_autor = artigo_div.find('span', {'data-tipo-ordenacao': 'autor'}).text\n",
    "                                            except:\n",
    "                                                prim_autor = None\n",
    "                                            try:\n",
    "                                                jcr = artigo_div.find('span', {'data-tipo-ordenacao': 'jcr'}).text\n",
    "                                            except:\n",
    "                                                jcr = None\n",
    "                                            try:\n",
    "                                                doi = artigo_div.find('a', {'class': 'icone-doi'})['href']\n",
    "                                            except:\n",
    "                                                doi = None\n",
    "                                            # try:\n",
    "                                            #     titulo = artigo_div.find('div', {'class': 'citado'}).text\n",
    "                                            # except:\n",
    "                                            #     titulo = None\n",
    "                                            dados   = artigo_div.find_all('div', {'class': 'layout-cell-pad-5'})\n",
    "                                            list    = str(dados).split(\" . \")\n",
    "                                            autores = prim_autor + list[0].split(prim_autor)[-1].replace('</a>','').replace('</b>','').replace('<b>','')\n",
    "                                            revista = list[1].split('nomePeriodico=')[1].split('tooltip=')[0].strip('\\\" ')\n",
    "                                            titulo  = list[1].split('titulo=')[1].split('&amp')[0].strip('\\\" ')\n",
    "                                            artigo_dict['ano']     = ano\n",
    "                                            artigo_dict['autores'] = autores\n",
    "                                            artigo_dict['revista'] = revista\n",
    "                                            artigo_dict['titulo']  = titulo\n",
    "                                            artigo_dict['jcr']     = jcr\n",
    "                                            artigo_dict['doi']     = doi\n",
    "                                            producoes.append(artigo_dict)\n",
    "                                            json_data[\"Properties\"]['Produções'] = producoes                                        \n",
    "                                    except AttributeError:\n",
    "                                        print('Produçao não encontrada para este currículo')\n",
    "                        \n",
    "                        ## Montar a lista de números de linha com os respectivos dados de interesse e dividir em rótulos e conteúdos\n",
    "                        linhas_citacoes=[]\n",
    "                        linhas_qtecitacoes=[]\n",
    "                        linhas_retirar=[]\n",
    "                        linhas_subsecoes=[]\n",
    "                        linhas_tipos=[]\n",
    "                        linhas_dados=[]\n",
    "                        for i in range(len(dados)):\n",
    "                            for rotulo in rotulos_citacoes:\n",
    "                                if rotulo in dados[i] and i not in linhas_citacoes:\n",
    "                                    linhas_citacoes.append(i)\n",
    "\n",
    "                            for rotulo in rotulos_qte_citacoes:\n",
    "                                if rotulo in dados[i] and i not in linhas_qtecitacoes:\n",
    "                                    linhas_qtecitacoes.append(i)\n",
    "\n",
    "                            for rotulo in rotulos_retirar:\n",
    "                                if rotulo in dados[i] and i not in linhas_retirar:\n",
    "                                    linhas_retirar.append(i)\n",
    "\n",
    "                            for rotulo in rotulos_subsecoes:\n",
    "                                if rotulo in dados[i] and i not in linhas_subsecoes:\n",
    "                                    linhas_subsecoes.append(i)\n",
    "\n",
    "                            for rotulo in rotulos_tipo:\n",
    "                                if rotulo in dados[i] and 'Citações:' not in dados[i] and 'Citações no' not in dados[i] and i not in linhas_tipos:\n",
    "                                    linhas_tipos.append(i)\n",
    "\n",
    "                            if i not in linhas_citacoes and i not in linhas_qtecitacoes and i not in linhas_retirar and i not in linhas_subsecoes and i not in linhas_tipos and \"Citações no\" not in dados[i] and dados[i] !='':\n",
    "                                linhas_dados.append(dados[i])\n",
    "\n",
    "                        ultima_linha=max(range(len(dados)))\n",
    "                        # print('Última linha:',ultima_linha)\n",
    "                        # print('DadoÚltLinha:',dados[ultima_linha])\n",
    "                        linhas_tipos.append(ultima_linha)\n",
    "\n",
    "                        # print(f'QteTotalLinhas:{len(dados)}, QteDados:{len(linhas_dados)}, QteRotulosCitações:{len(linhas_citacoes)}, QteCitações:{len(linhas_qtecitacoes)}, QteRotulosSubseção:{len(linhas_subsecoes)}, QteRotulosTipos:{len(linhas_tipos)}, QteRotulosRetirar:{len(linhas_retirar)}')\n",
    "\n",
    "                        ## Da lista de espacos monta os pares ordenados de rótulo/conteúdo\n",
    "                        limites_conteudos=[]\n",
    "                        lst_i=linhas_tipos[::1]\n",
    "                        lst_j=linhas_tipos[1::1]\n",
    "                        # print(len(lst_i),lst_i)\n",
    "                        # print(len(lst_j),lst_j)\n",
    "\n",
    "                        for i, j in zip(lst_i,lst_j):\n",
    "                            limites_conteudos.append((i,j))\n",
    "\n",
    "                        # print('LimitesConteúdo:',len(limites_conteudos),limites_conteudos)\n",
    "\n",
    "                        ## Para cada par ordenado separar em colunas de rótulos e coluna de conteúdos\n",
    "                        for i in range(len(limites_conteudos)):\n",
    "                            par=limites_conteudos[i]\n",
    "                            if i<(len(limites_conteudos)-1):\n",
    "                                try:\n",
    "                                    rotulos.append(dados[par[0]])\n",
    "                                    # print('Linhas:', par[0]+1,par[1])\n",
    "                                    conteudos.append(dados[par[0]+1:par[1]])\n",
    "                                    curriculos.append(NOME)\n",
    "                                except:\n",
    "                                    print('Erro ao montar pares ordenados de rótulo/conteúdo')\n",
    "                                    pass\n",
    "                            else:\n",
    "                                try:\n",
    "                                    rotulos.append(dados[par[0]])\n",
    "                                    # print('Linhas:', par[0]+1,par[1])\n",
    "                                    conteudos.append(dados[par[0]+1:par[1]+1])\n",
    "                                    curriculos.append(NOME)\n",
    "                                except:\n",
    "                                    print('Erro ao montar pares ordenados de rótulo/conteúdo')\n",
    "                                    pass        \n",
    "                        \n",
    "                    ## Seções de organização simples em rótulos e conteúdos\n",
    "                    elif sessao in sessoes:\n",
    "                        subtitulo = elementos[i].text.split('\\n')[0]\n",
    "                        dados = elementos[i].text.split('\\n')[1:]\n",
    "                        indices=[]\n",
    "                        for i in range(len(dados)):\n",
    "                            numbers = re.findall('[0-9]+', dados[i])\n",
    "                            hifen = re.findall('-', dados[i])\n",
    "                            if len(numbers) == 2 and len(hifen) == 1:\n",
    "                                indices.append(i)\n",
    "                                periodo = f' {numbers[0]}{hifen[0]}{numbers[1]}'\n",
    "                                rotulos.append(subtitulo+\" \"+periodo)\n",
    "                            else:\n",
    "                                pass                    \n",
    "                        \n",
    "                        finais=[]\n",
    "                        for i in indices[1::1]: # slice: a partir do elemento 1 até o final da lista, contanto de 1 em 1\n",
    "                            finais.append(i-1)\n",
    "                        finais.append(len(dados))\n",
    "\n",
    "                        for ini, fim in zip(indices, finais):\n",
    "                            conteudos.append(dados[ini+1:fim])\n",
    "                            curriculos.append(NOME)\n",
    "                \n",
    "                ## Fechar janela do currículo\n",
    "                browser.close()            \n",
    "                \n",
    "                ## Gerenciamento das janelas abertas no browser\n",
    "                todas_janelas = browser.window_handles\n",
    "                browser.switch_to.window(todas_janelas[0])\n",
    "\n",
    "                ## Fechar a janela pop-up\n",
    "                close_popup = WebDriverWait(browser, delay).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, \"//*[@id='idbtnfechar']\")))\n",
    "                close_popup.click()\n",
    "                \n",
    "                ## Nova Consulta\n",
    "                try:\n",
    "                    btn_novaconsulta = WebDriverWait(browser, delay).until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, \"//*[@id='botaoBuscaFiltros']\")))\n",
    "                    btn_novaconsulta.click()\n",
    "                    time.sleep(1)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print('Erro ao reiniciar consulta')\n",
    "                    traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "                    print(e,traceback_str) \n",
    "                \n",
    "                t5=time.time()\n",
    "                # print(f' {tempo(t0,t5)} | Tempo de Acesso |  Identificação |   Dados Brutos | Subtotal Tempo | Acumulado')\n",
    "                # print(f'  Decorrido  |   {tempo(t2,t3)}   |  {tempo(t3,t4)}   |  {tempo(t4,t5)}   |  {tempo(t2,t5)}   | {len(conteudos)} seções')\n",
    "                \n",
    "                sucesso.append(NOME)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print('Erro ao montar dataframe dados de artigos')\n",
    "                traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "                print(e,traceback_str)    \n",
    "                browser.quit()\n",
    "                \n",
    "                return np.NaN, np.NaN, np.NaN\n",
    "        except:\n",
    "            print(f'Currículo não encontrado: {NOME}')\n",
    "            browser.back()\n",
    "            pass\n",
    "\n",
    "    df_dados =pd.DataFrame({\n",
    "        'CURRICULO': pd.Series(curriculos),\n",
    "        'ROTULOS': pd.Series(rotulos),\n",
    "        'CONTEUDOS': pd.Series(conteudos),\n",
    "            })\n",
    "    \n",
    "    t6=time.time()\n",
    "    print('='*95)\n",
    "    # print(f' {len(sucesso)} currículos extraídos com sucesso')\n",
    "    print(f' Tempo total para extrair {len(conteudos)} seções dos currículos: {tempo(t0,t6)}')\n",
    "    # print('='*95)\n",
    "    browser.quit()\n",
    "    \n",
    "    return df_dados, sucesso, json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_teste = ['Carlos Jose Araujo Pinheiro', 'Claudia Stutz Zubieta','Antonio Marcos Aires Barbosa']\n",
    "# df_secoes_teste, sucesso_teste, json_data = extrair_dados(lista_teste, mestres=True, assunto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_lista_discentes(lista_nomes, instituicao='Fiocruz', unidade='Ceará', termo='Fundação Oswaldo Cruz'):\n",
    "    from pyjarowinkler.distance import get_jaro_distance\n",
    "    from IPython.display import clear_output\n",
    "    import numpy as np\n",
    "    import time\n",
    "\n",
    "    delay=15\n",
    "    rotulos=[]\n",
    "    conteudos=[]\n",
    "    tipo_erro=[]\n",
    "    falhas=[]\n",
    "    duvidas=[]\n",
    "    sucessos=[]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    browser = conectar_busca()\n",
    "    t1 = time.time()\n",
    "    \n",
    "    for k,NOME in enumerate(lista_nomes):\n",
    "        resta=len(lista_nomes)-(k+1)\n",
    "        tdec=time.time()-t1\n",
    "        tmed=tdec/(k+1)\n",
    "        trest=tmed*resta\n",
    "        print(f'{k+1}/{len(lista_nomes)}, restando {len(lista_nomes)-int(k+1)}. Decorrido: {horas(time.time()-t1)}. Previsão tempo para término: {horas(trest)}')\n",
    "        t2 = time.time()\n",
    "        limite=5\n",
    "\n",
    "        ## Definir filtros para busca de nomes\n",
    "        definir_filtros(browser, delay, assunto=False, todosniveis=True) # filtros customizados para todos níveis\n",
    "    \n",
    "        ## Colar a query desejada e guardar a janela corrente\n",
    "        preencher_busca(browser, delay, NOME)      \n",
    "        window_before  = browser.current_window_handle\n",
    "        \n",
    "        t2a = time.time()\n",
    "        elemento_achado, nome_falha, duvida, erro, browser = procurar_vinculos(NOME, instituicao, unidade, termo, browser, delay, limite)\n",
    "        # print('Elemento encontrado:',elemento_achado)\n",
    "        # print(nome_falha)\n",
    "        # print(tipo_erro)\n",
    "        \n",
    "        if str(elemento_achado) == 'nan':\n",
    "            print('Vínculo não encontrado passando ao próximo nome...')\n",
    "            falhas.append(nome_falha)\n",
    "            duvidas.append(duvida)\n",
    "            tipo_erro.append(erro)\n",
    "            clear_output(wait=True)\n",
    "            continue\n",
    "            \n",
    "        t2b = time.time()\n",
    "        print(f'{tempo(t2a,t2b)} para achar e escolher o currículo com vínculo: ')\n",
    "    \n",
    "        try:\n",
    "            print('Aguardando abertura da janela de currículo...')\n",
    "            ## Clicar no botão abrir currículo\n",
    "            cssselector_btn = \"#idbtnabrircurriculo\"\n",
    "            waitbtn = WebDriverWait(browser, delay).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, cssselector_btn)))\n",
    "            time.sleep(0.5)\n",
    "            elemento_btn = browser.find_element(By.CSS_SELECTOR, cssselector_btn)             \n",
    "            texto_botao  = elemento_btn.text\n",
    "            # print('Clicando no botão:', texto_botao)\n",
    "            retry(elemento_btn.click(),\n",
    "                   wait_ms=20,\n",
    "                   limit=limite, \n",
    "                   on_exhaust=(f'Problema clicar em {texto_botao}, {limite} tentativas sem sucesso.'))\n",
    "            \n",
    "            ## Gerenciamento das janelas abertas no browser e mudar de aba\n",
    "            WebDriverWait(browser, delay).until(EC.number_of_windows_to_be(2))\n",
    "            window_after = browser.window_handles\n",
    "            new_window   = [x for x in window_after if x != window_before][0]\n",
    "            browser.switch_to.window(new_window)\n",
    "            time.sleep(2) # tempo para garantir mudança de aba em conexão lenta\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('Erro na função extrair_lista_discentes(), ao clicar no botão para abrir o currículo')\n",
    "            print(e)\n",
    "            falhas.append(NOME)\n",
    "            duvidas.append(np.NaN)\n",
    "            tipo_erro.append(e)            \n",
    "            continue\n",
    "        \n",
    "        ## Extrair dados e salvar em dataframe\n",
    "        print('Iniciando a captura dos dados do currículo...')\n",
    "        time.sleep(0.5)\n",
    "        t3 = time.time()\n",
    "        css_dadoscentral = \".main-content > div:nth-child(1)\"\n",
    "        \n",
    "        ## O objeto elementos_id abaixo é uma lista de elementos onde as informações de identificação estão contidas\n",
    "        ## acessado através do marcador xpath='//div[@class=\"infpessoa\"]' no HTML para extrair de cada pesquisador\n",
    "        xpath='//div[@class=\"infpessoa\"]'\n",
    "        WebDriverWait(browser, delay).until(\n",
    "                EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "        elementos_id = browser.find_elements(By.XPATH, xpath)\n",
    "\n",
    "        ## primeira informação para cada pesquisador seja o caminho para sua foto e dados de identificação\n",
    "        try:\n",
    "            css_selector='.foto'\n",
    "            link_foto=WebDriverWait(browser, delay).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, \".foto\"))).get_attribute(\"src\")\n",
    "            rotulos.append('Link Foto:')\n",
    "            conteudos.append(link_foto)            \n",
    "\n",
    "        except Exception as e:\n",
    "            traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "            print('  !!Erro ao extrair imagem do currículo:',e,'\\n', traceback_str)\n",
    "            falhas.append(NOME)\n",
    "            duvidas.append(np.NaN)\n",
    "            tipo_erro.append(e)              \n",
    "            continue\n",
    "        \n",
    "        for i in range(len(elementos_id)):\n",
    "            dados = elementos_id[i].text.split('\\n')\n",
    "            for i in range(len(dados)):\n",
    "                if i==0:\n",
    "                    rotulos.append('Nome completo:')\n",
    "                    conteudos.append(dados[i])\n",
    "                elif 'Bolsista' in dados[i]:\n",
    "                    rotulos.append('Bolsista CNPq:')\n",
    "                    conteudos.append(dados[i])\n",
    "                elif 'Endereço para acessar este CV: ' in dados[i]:\n",
    "                    rotulos.append('Link Currículo:')\n",
    "                    conteudos.append(dados[i].strip('Endereço para acessar este CV: '))\n",
    "                elif 'ID Lattes: ' in dados[i]:\n",
    "                    rotulos.append('ID Lattes:')\n",
    "                    conteudos.append(dados[i].strip('ID Lattes: '))\n",
    "                    print('  ID_LATTES:',dados[i].strip('ID Lattes: '))\n",
    "                elif 'Última atualização do currículo em ' in dados[i]:\n",
    "                    rotulos.append('Data atualização:')\n",
    "                    conteudos.append(dados[i].strip('Última atualização do currículo em '))\n",
    "                    print('ATUALIZAÇÃO:',dados[i].strip('Última atualização do currículo em '))\n",
    "        try: \n",
    "            df_temp =pd.DataFrame({\n",
    "                'ROTULOS': pd.Series(rotulos),\n",
    "                'CONTEUDOS': pd.Series(conteudos),\n",
    "                    })\n",
    "            filtro    = 'Link Foto:'\n",
    "            fotos     = df_temp[(df_temp.ROTULOS == filtro)]['CONTEUDOS']\n",
    "            x         = fotos[-1:].index[0]\n",
    "            df_temp.drop(columns=['ROTULOS'], inplace=True)\n",
    "\n",
    "            try:\n",
    "                foto = HTML(df_temp[x:x+1].to_html(escape=False, formatters=dict(CONTEUDOS=path_to_image_html)))\n",
    "                display(foto)\n",
    "\n",
    "            except TimeoutException as t:\n",
    "                print('Demora na conexão com servidor, carregamento da foto cancelado')\n",
    "                print(t)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Erro ao extrair a foto do pesquisador')\n",
    "            print(e)\n",
    "            falhas.append(NOME)\n",
    "            duvidas.append(np.NaN)\n",
    "            tipo_erro.append(e)              \n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            css_resumo = \".resumo\"\n",
    "            resumo = browser.find_elements(By.CSS_SELECTOR, css_resumo)\n",
    "            for i in resumo:\n",
    "                print(i.text)\n",
    "                rotulos.append('Resumo:')\n",
    "                conteudos.append(i.text) \n",
    "        except Exception as e:\n",
    "            print('Erro ao extrair o resumo:', e)\n",
    "            falhas.append(NOME)\n",
    "            duvidas.append(np.NaN)\n",
    "            tipo_erro.append(e)              \n",
    "            continue\n",
    "        \n",
    "        t4=time.time() \n",
    "        print('Dados de cabeçalho carregados...', tempo(t3,t4))\n",
    "            \n",
    "        ## Extração de dados de produções e orientações\n",
    "        try:\n",
    "            ## O objeto ELEMENTOS abaixo é uma lista de elementos onde as informações estão contidas\n",
    "            time.sleep(2)\n",
    "            elementos = browser.find_elements(By.XPATH, '//div[@class=\"title-wrapper\"]')\n",
    "            # print('Len Cotainers 01:')\n",
    "            # pprint(elementos)\n",
    "            # for i in elementos:\n",
    "            #     print(i.text)\n",
    "        \n",
    "            ## Extração das demais sessões que se organizam em pares rótulo/conteúdo\n",
    "            for i in range(len(elementos)):\n",
    "                # print(len(elementos))\n",
    "                sessao=elementos[i].text.split('\\n')[0]\n",
    "                # print(sessao)\n",
    "                sessoes=['Formação acadêmica/titulação',\n",
    "                         'Pós-doutorado',\n",
    "                         'Formação Complementar',\n",
    "                         'Linhas de pesquisa',\n",
    "                         'Projetos de pesquisa',\n",
    "                         'Projetos de desenvolvimento',\n",
    "                         'Membro de corpo editorial',\n",
    "                         'Membro de comitê de assessoramento',\n",
    "                         'Revisor de periódico',\n",
    "                         'Áreas de atuação',\n",
    "                         'Prêmios e títulos',\n",
    "                         'Idiomas',\n",
    "                         'Educação e Popularização de C & T',\n",
    "                         'Outras informações relevantes',\n",
    "                        ]\n",
    "\n",
    "                ## Seção Orientações\n",
    "                if sessao == 'Orientações':                \n",
    "                    rotulos_subsecoes=[\n",
    "                        'Orientações e supervisões em andamento',\n",
    "                        'Orientações e supervisões concluídas',\n",
    "                    ]\n",
    "        \n",
    "                    rotulos_retirar=['Orientações e supervisões concluídas ', \n",
    "                                     'Orientações e supervisões concluídas']\n",
    "\n",
    "                    rotulos_tipo =[\n",
    "                        'Dissertação de mestrado',\n",
    "                        'Tese de doutorado',\n",
    "                        'Supervisão de pós-doutorado',\n",
    "                        'Dissertação de mestrado',\n",
    "                        'Trabalho de conclusão de curso de graduação',\n",
    "                        'Tese de doutorado',\n",
    "                        'Supervisão de pós-doutorado',\n",
    "                        # 'Iniciação científica',\n",
    "                        'Orientações de outra natureza',\n",
    "                    ]                 \n",
    "\n",
    "                    ## Montagem dos dados a partir da extração da seção específica dos containers:\n",
    "                    for i in range(len(elementos)):\n",
    "                        if i != 0:\n",
    "                            secao=elementos[i].text.split('\\n')[0]\n",
    "\n",
    "                            ## Filtra para receber dados somente da seção produção, monta cada linha de dados com a quebra de linha\n",
    "                            if secao == 'Orientações':\n",
    "                                dados=elementos[i].text.split('\\n')[1:]\n",
    "        \n",
    "                    ## Montar a lista de números de linha com os respectivos dados de interesse e dividir em rótulos e conteúdos\n",
    "                    linhas_subsecoes=[]\n",
    "                    linhas_tipos=[]\n",
    "                    linhas_dados=[]\n",
    "                    for i in range(len(dados)):\n",
    "                        for rotulo in rotulos_subsecoes:\n",
    "                            if rotulo in dados[i] and i not in linhas_subsecoes:\n",
    "                                linhas_subsecoes.append(i)\n",
    "\n",
    "                        for rotulo in rotulos_tipo:\n",
    "                            if rotulo in dados[i] and 'Citações:' not in dados[i] and 'Citações no' not in dados[i] and i not in linhas_tipos:\n",
    "                                linhas_tipos.append(i)\n",
    "\n",
    "                        if i not in linhas_subsecoes and i not in linhas_tipos and \"Citações no\" not in dados[i] and dados[i] !='':\n",
    "                            linhas_dados.append(dados[i])\n",
    "\n",
    "                    ultima_linha=max(range(len(dados)))\n",
    "                    # print('Última linha:',ultima_linha)\n",
    "                    # print('DadoÚltLinha:',dados[ultima_linha])\n",
    "                    linhas_tipos.append(ultima_linha)\n",
    "                    # print(f'QteTotalLinhas:{len(dados)}, QteDados:{len(linhas_dados)}, QteRotulosCitações:{len(linhas_citacoes)}, QteCitações:{len(linhas_qtecitacoes)}, QteRotulosSubseção:{len(linhas_subsecoes)}, QteRotulosTipos:{len(linhas_tipos)}, QteRotulosRetirar:{len(linhas_retirar)}')\n",
    "\n",
    "                    ## Da lista de espacos monta os pares ordenados de rótulo/conteúdo\n",
    "                    limites_conteudos=[]\n",
    "                    lst_i=linhas_tipos[::1]\n",
    "                    lst_j=linhas_tipos[1::1]\n",
    "                    # print(len(lst_i),lst_i)\n",
    "                    # print(len(lst_j),lst_j)\n",
    "\n",
    "                    for i, j in zip(lst_i,lst_j):\n",
    "                        limites_conteudos.append((i,j))\n",
    "                    # print('LimitesConteúdo:',len(limites_conteudos),limites_conteudos)\n",
    "\n",
    "                    ## Para cada par ordenado separar em colunas de rótulos e coluna de conteúdos\n",
    "                    for i in range(len(limites_conteudos)):\n",
    "                        par=limites_conteudos[i]\n",
    "                        if i<(len(limites_conteudos)-1):\n",
    "                            try:\n",
    "                                rotulos.append('Orientação '+dados[par[0]])\n",
    "                                # print('Linhas:', par[0]+1,par[1])\n",
    "                                conteudos.append(dados[par[0]+1:par[1]])\n",
    "                            except:\n",
    "                                print('Erro ao montar pares ordenados de rótulo/conteúdo')\n",
    "                                pass\n",
    "                        else:\n",
    "                            try:\n",
    "                                rotulos.append('Orientação '+dados[par[0]])\n",
    "                                # print('Linhas:', par[0]+1,par[1])\n",
    "                                conteudos.append(dados[par[0]+1:par[1]+1])\n",
    "                            except:\n",
    "                                print('Erro ao montar pares ordenados de rótulo/conteúdo')\n",
    "                                pass\n",
    "\n",
    "                    ## Montar dataframe com colunas de rótulos e conteúdos só sobre orientações\n",
    "                    ## df_orientacoes=pd.DataFrame(zip(rotulos,conteudos), columns=['rotulos','conteudos'])                    \n",
    "\n",
    "                if sessao == 'Identificação':\n",
    "                    dados = elementos[i].text.split('\\n')[1:]\n",
    "                    for i, j in zip(dados[::2], dados[1::2]):\n",
    "                        rotulos.append(i)\n",
    "                        if i != 'Nome em citações bibliográficas':\n",
    "                            conteudos.append(j)\n",
    "                        else:\n",
    "                            conteudos.append(j.split(';'))\n",
    "                        # print(f'{len(rotulos):>3} Linhas extraídas seção {sessao}...')\n",
    "\n",
    "                ## Seção Produções\n",
    "                if sessao == 'Produções':\n",
    "                    rotulos_retirar=[\n",
    "                        'Ordenar por', \n",
    "                        'Ordem Cronológica',\n",
    "                        'Número de citações Web of science',\n",
    "                        'Número de citações Scopus',\n",
    "                        'Numero de citações Scielo',\n",
    "                        'Primeiro autor',\n",
    "                        'Impacto JCR',\n",
    "                        'Ordem de Importância',\n",
    "                    ]\n",
    "                    rotulos_citacoes =  [\n",
    "                        'Web of Science',\n",
    "                        'Total de trabalhos',\n",
    "                        'Total de citações',\n",
    "                        'Fator H',\n",
    "                        'Pinheiro, Placido R  Data',\n",
    "                        'SciELO',\n",
    "                        'Total de trabalhos',\n",
    "                        'Total de citações',\n",
    "                        'Placido Rogerio Pinheiro  Data',\n",
    "                        'SCOPUS',\n",
    "                        'Total de trabalhos',\n",
    "                        'Total de citações',\n",
    "                        'Placido Rogerio Pinheiro (Fator h-index',\n",
    "                        'Outras',\n",
    "                        'Total de trabalhos',\n",
    "                    ]\n",
    "                    rotulos_subsecoes=[\n",
    "                        'Produção bibliográfica',\n",
    "                        'Produção técnica',\n",
    "                        'Demais tipos de produção técnica',\n",
    "                    ]\n",
    "                    rotulos_tipo =[\n",
    "                        'Citações',\n",
    "                        'Artigos completos publicados em periódicos',\n",
    "                        'Livros publicados/organizados ou edições',\n",
    "                        'Capítulos de livros publicados',\n",
    "                        'Textos em jornais de notícias/revistas',\n",
    "                        'Trabalhos completos publicados em anais de congressos',\n",
    "                        'Resumos expandidos publicados em anais de congressos',\n",
    "                        'Resumos publicados em anais de congressos',\n",
    "                        'Apresentações de Trabalho',\n",
    "                        'Outras produções bibliográficas',\n",
    "                        'Assessoria e consultoria',\n",
    "                        'Programas de computador sem registro',\n",
    "                        'Trabalhos técnicos',\n",
    "                        'Entrevistas, mesas redondas, programas e comentários na mídia',\n",
    "                        'Demais tipos de produção técnica',\n",
    "                    ]\n",
    "                    rotulos_qte_citacoes =[\n",
    "                        'Citações:',\n",
    "                    ]\n",
    "\n",
    "                    ## Montagem dos dados a partir da extração da seção específica dos containers:\n",
    "                    for i in range(len(elementos)):\n",
    "                        if i != 0:\n",
    "                            sessao=elementos[i].text.split('\\n')[0]\n",
    "\n",
    "                            ## Filtra para receber dados somente da seção produção, monta cada linha de dados com a quebra de linha\n",
    "                            if sessao == 'Produções':\n",
    "                                dados=elementos[i].text.split('\\n')[1:]\n",
    "\n",
    "                    ## Montar a lista de números de linha com os respectivos dados de interesse e dividir em rótulos e conteúdos\n",
    "                    linhas_citacoes=[]\n",
    "                    linhas_qtecitacoes=[]\n",
    "                    linhas_retirar=[]\n",
    "                    linhas_subsecoes=[]\n",
    "                    linhas_tipos=[]\n",
    "                    linhas_dados=[]\n",
    "                    for i in range(len(dados)):\n",
    "                        for rotulo in rotulos_citacoes:\n",
    "                            if rotulo in dados[i] and i not in linhas_citacoes:\n",
    "                                linhas_citacoes.append(i)\n",
    "                        for rotulo in rotulos_qte_citacoes:\n",
    "                            if rotulo in dados[i] and i not in linhas_qtecitacoes:\n",
    "                                linhas_qtecitacoes.append(i)\n",
    "                        for rotulo in rotulos_retirar:\n",
    "                            if rotulo in dados[i] and i not in linhas_retirar:\n",
    "                                linhas_retirar.append(i)\n",
    "                        for rotulo in rotulos_subsecoes:\n",
    "                            if rotulo in dados[i] and i not in linhas_subsecoes:\n",
    "                                linhas_subsecoes.append(i)\n",
    "                        for rotulo in rotulos_tipo:\n",
    "                            if rotulo in dados[i] and 'Citações:' not in dados[i] and 'Citações no' not in dados[i] and i not in linhas_tipos:\n",
    "                                linhas_tipos.append(i)\n",
    "                        if i not in linhas_citacoes and i not in linhas_qtecitacoes and i not in linhas_retirar and i not in linhas_subsecoes and i not in linhas_tipos and \"Citações no\" not in dados[i] and dados[i] !='':\n",
    "                            linhas_dados.append(dados[i])\n",
    "\n",
    "                    ultima_linha=max(range(len(dados)))\n",
    "                    linhas_tipos.append(ultima_linha)\n",
    "                    # print('Última linha:',ultima_linha)\n",
    "                    # print('DadoÚltLinha:',dados[ultima_linha])\n",
    "                    # print(f'QteTotalLinhas:{len(dados)}, QteDados:{len(linhas_dados)}, QteRotulosCitações:{len(linhas_citacoes)}, QteCitações:{len(linhas_qtecitacoes)}, QteRotulosSubseção:{len(linhas_subsecoes)}, QteRotulosTipos:{len(linhas_tipos)}, QteRotulosRetirar:{len(linhas_retirar)}')\n",
    "\n",
    "                    ## Da lista de espacos monta os pares ordenados de rótulo/conteúdo\n",
    "                    limites_conteudos=[]\n",
    "                    lst_i=linhas_tipos[::1]\n",
    "                    lst_j=linhas_tipos[1::1]\n",
    "                    # print(len(lst_i),lst_i)\n",
    "                    # print(len(lst_j),lst_j)\n",
    "\n",
    "                    for i, j in zip(lst_i,lst_j):\n",
    "                        limites_conteudos.append((i,j))\n",
    "                    # print('LimitesConteúdo:',len(limites_conteudos),limites_conteudos)\n",
    "\n",
    "                    ## Para cada par ordenado separar em colunas de rótulos e coluna de conteúdos\n",
    "                    for i in range(len(limites_conteudos)):\n",
    "                        par=limites_conteudos[i]\n",
    "                        if i<(len(limites_conteudos)-1):\n",
    "                            try:\n",
    "                                rotulos.append(dados[par[0]])\n",
    "                                # print('Linhas:', par[0]+1,par[1])\n",
    "                                conteudos.append(dados[par[0]+1:par[1]])\n",
    "                            except:\n",
    "                                print('Erro ao montar pares ordenados de rótulo/conteúdo')\n",
    "                                pass\n",
    "                        else:\n",
    "                            try:\n",
    "                                rotulos.append(dados[par[0]])\n",
    "                                # print('Linhas:', par[0]+1,par[1])\n",
    "                                conteudos.append(dados[par[0]+1:par[1]+1])\n",
    "                            except:\n",
    "                                print('Erro ao montar pares ordenados de rótulo/conteúdo')\n",
    "                                pass        \n",
    "\n",
    "                ## Seções de organização simples em rótulos e conteúdos\n",
    "                elif sessao in sessoes:\n",
    "                    subtitulo = elementos[i].text.split('\\n')[0]\n",
    "                    dados = elementos[i].text.split('\\n')[1:]\n",
    "                    indices=[]\n",
    "                    for i in range(len(dados)):\n",
    "                        numbers = re.findall('[0-9]+', dados[i])\n",
    "                        hifen = re.findall('-', dados[i])\n",
    "                        if len(numbers) == 2 and len(hifen) == 1:\n",
    "                            indices.append(i)\n",
    "                            periodo = f' {numbers[0]}{hifen[0]}{numbers[1]}'\n",
    "                            rotulos.append(subtitulo+\" \"+periodo)\n",
    "                        else:\n",
    "                            pass                    \n",
    "\n",
    "                    finais=[]\n",
    "                    for i in indices[1::1]: # slice: a partir do elemento 1 até o final da lista, contanto de 1 em 1\n",
    "                        finais.append(i-1)\n",
    "                    finais.append(len(dados))\n",
    "\n",
    "                    for ini, fim in zip(indices, finais):\n",
    "                        conteudos.append(dados[ini+1:fim])\n",
    "\n",
    "            t5=time.time()                       \n",
    "            print(\"=\"*95)\n",
    "            print(f' {tempo(t0,t5)} | Tempo de Acesso |  Identificação |   Dados Brutos | Subtotal Tempo | Acumulado')\n",
    "            print(f'  Decorrido  |   {tempo(t2,t3)}   |  {tempo(t3,t4)}   |  {tempo(t4,t5)}   |  {tempo(t2,t5)}   | {len(conteudos)} seções')\n",
    "            print(\"=\"*95)\n",
    "            sucessos.append(NOME)              \n",
    "        \n",
    "        except Exception as e:\n",
    "            print('Erro ao montar dataframe dados de artigos')\n",
    "            print(e)\n",
    "            falhas.append(NOME)\n",
    "            duvidas.append(np.NaN)\n",
    "            tipo_erro.append(e)\n",
    "            continue\n",
    "\n",
    "        print(f' Tempo para extrair currículo com {len(conteudos)} seções: {tempo(t2,t5)}')\n",
    "        print('='*95)\n",
    "        \n",
    "        ## Fechar janela do currículo\n",
    "        browser.close() \n",
    "\n",
    "        ## Gerenciamento das janelas abertas no browser\n",
    "        print('Retornando para aba de busca...')\n",
    "        browser.switch_to.window(window_before)\n",
    "        # todas_janelas = browser.window_handles \n",
    "        # browser.switch_to.window(todas_janelas[0])\n",
    "\n",
    "        ## Fechar a janela pop-up\n",
    "        # print('Fechando janela pop-up do currículo')\n",
    "        css_fecharpopup = \"#idbtnfechar\"\n",
    "        fecharpopup = WebDriverWait(browser, delay).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, css_fecharpopup)))\n",
    "        fecharpopup = browser.find_element(By.CSS_SELECTOR, css_fecharpopup)\n",
    "        fecharpopup.click()\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        ## Nova Consulta\n",
    "        try:\n",
    "            # print('Retornando para página de busca...')\n",
    "            css_novaconsulta = \"#botaoBuscaFiltros\"\n",
    "            btn_novaconsulta = browser.find_element(By.CSS_SELECTOR, css_novaconsulta)             \n",
    "            retry(btn_novaconsulta.click(),\n",
    "                   wait_ms=50,\n",
    "                   limit=limite, \n",
    "                   on_exhaust=(f'Problema clicar em {css_novaconsulta}, {limite} tentativas sem sucesso.'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Erro ao reiniciar consulta')\n",
    "            traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "            print(e,traceback_str)\n",
    "            falhas.append(NOME)\n",
    "            duvidas.append(np.NaN)\n",
    "            tipo_erro.append(e)              \n",
    "            continue\n",
    "    \n",
    "    df_dados =pd.DataFrame({\n",
    "                            'ROTULOS': pd.Series(rotulos),\n",
    "                            'CONTEUDOS': pd.Series(conteudos),\n",
    "                            })\n",
    "    \n",
    "    t6=time.time()\n",
    "    print('='*95)\n",
    "    print(f' {len(sucessos)} currículos extraídos com sucesso')\n",
    "    print(f' Tempo total para extrair {len(conteudos)} seções dos currículos: {tempo(t0,t6)}')\n",
    "    print('='*95)\n",
    "    browser.quit()\n",
    "            \n",
    "    return df_dados, falhas, duvidas, tipo_erro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para dividir detalhes dos artigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padrões de expressão regular\n",
    "pattern_m01a = r' \\. '\n",
    "pattern_m01b = r' et al. '\n",
    "pattern_m01c = r' \\; '\n",
    "pattern_m01d = r'\\. '\n",
    "pattern_vol  = r' v\\. (\\d+)'\n",
    "pattern_pag  = r' p\\. (.*?),'\n",
    "pattern_ano  = r'\\d{4}\\.$'\n",
    "\n",
    "def find_positions(pattern, string):\n",
    "    return [match.start() for match in re.finditer(pattern, string)]\n",
    "\n",
    "def find_vol(input_string):\n",
    "    pattern = r\" v\\. (\\d+)\"\n",
    "    match   = re.search(pattern, input_string)\n",
    "    try:\n",
    "        volume = match.group(1)\n",
    "        return volume, match.start()\n",
    "    except:\n",
    "        return ['','']\n",
    "\n",
    "def find_pag(input_string):\n",
    "    pattern = r\" p\\. (.*?),\"\n",
    "    match   = re.search(pattern, input_string)\n",
    "    try:\n",
    "        pages = match.group(1)\n",
    "        return pages, match.start()\n",
    "    except Exception as e:\n",
    "        # print(e)\n",
    "        return ['','']\n",
    "\n",
    "def find_year(input_string):\n",
    "    pattern = r'\\d{4}\\.$'\n",
    "    match = re.search(pattern, input_string)\n",
    "    year  = match.group().strip('.')\n",
    "    return year, match.start()\n",
    "\n",
    "def find_marker_positions(input_string, markers):\n",
    "    marker_positions = {}\n",
    "    for marker in markers:\n",
    "        position = input_string.find(marker)\n",
    "        if position != -1:\n",
    "            marker_positions[position] = marker\n",
    "    return marker_positions\n",
    "\n",
    "def find_odd(input_string, marker):\n",
    "    odds_positions = []\n",
    "    \n",
    "    for order, position in enumerate([pos for pos, char in enumerate(input_string) if input_string[pos:pos+len(marker)] == marker], start=1):\n",
    "        if order % 2 != 0:\n",
    "            odds_positions.append(position)\n",
    "    \n",
    "    return odds_positions\n",
    "\n",
    "def find_even(input_string, marker):\n",
    "    evens_positions = []\n",
    "    \n",
    "    for order, position in enumerate([pos for pos, char in enumerate(input_string) if input_string[pos:pos+len(marker)] == marker], start=0):\n",
    "        if order % 2 != 0:\n",
    "            evens_positions.append(position)\n",
    "    \n",
    "    return evens_positions\n",
    "\n",
    "\n",
    "def split_string_at_positions(input_string, positions):\n",
    "    substrings = []\n",
    "    start = 0\n",
    "\n",
    "    for position in positions:\n",
    "        substrings.append(input_string[start:position])\n",
    "        start = position\n",
    "\n",
    "    substrings.append(input_string[start:])\n",
    "\n",
    "    return substrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_publication_data(input_string):\n",
    "    extracted_data = {}\n",
    "    \n",
    "    # Extract Year\n",
    "    try:\n",
    "        year, year_position = find_year(input_string)\n",
    "        extracted_data['ANO'] = year\n",
    "        input_string = input_string[:year_position]\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred while extracting the year: {e}\")\n",
    "    \n",
    "    # List of patterns in order of priority\n",
    "    priority_patterns = [pattern_m01a, pattern_m01b, pattern_m01c, pattern_m01d]\n",
    "    m1_used = None\n",
    "    p1_end = None\n",
    "\n",
    "    # Identify m1 following the hierarchical preference\n",
    "    for pattern in priority_patterns:\n",
    "        positions = find_positions(pattern, input_string)\n",
    "        if positions:\n",
    "            m1_used = pattern\n",
    "            p1_end = positions[0]\n",
    "            break\n",
    "\n",
    "    # User interaction if no m1 marker is found\n",
    "    if m1_used is None:\n",
    "        user_marker = input(\"No marker found for splitting data for m1. Please specify a marker: \")\n",
    "        positions = find_positions(user_marker, input_string)\n",
    "        if positions:\n",
    "            m1_used = user_marker\n",
    "            p1_end = positions[0]\n",
    "\n",
    "    p1 = input_string[:p1_end].strip()\n",
    "    extracted_data['LISTA_AUTORES'] = p1\n",
    "    # extracted_data['M1_USED'] = m1_used\n",
    "    \n",
    "    # Identify m2 for p2 and p3\n",
    "    p2_end_candidates = [find_vol(input_string)[1], find_pag(input_string)[1]]\n",
    "    m2_labels = ['vol', 'pag']\n",
    "    m2_used = None\n",
    "    p2_end_candidates = [pos for pos in p2_end_candidates if pos is not None and pos != '']\n",
    "    \n",
    "    if len(p2_end_candidates) == 0:\n",
    "        last_dot_space = input_string.rfind('. ')\n",
    "        if last_dot_space != -1:\n",
    "            p2_end_candidates.append(last_dot_space)\n",
    "            m2_used = '. '\n",
    "        else:\n",
    "            user_input = input(\"No suitable marker found for p2 and p3. Specify either 'vol' or 'pag': \")\n",
    "            p2_end_candidates = find_positions(user_input, input_string)\n",
    "            m2_used = user_input\n",
    "    \n",
    "    else:\n",
    "        m2_used = m2_labels[p2_end_candidates.index(min(p2_end_candidates))]\n",
    "    \n",
    "    p2_end = min(p2_end_candidates)\n",
    "    p2 = input_string[p1_end:p2_end].lstrip(m1_used).strip()\n",
    "    extracted_data['ARTIGO_REVISTA'] = p2\n",
    "    # extracted_data['M2_USED'] = m2_used\n",
    "    \n",
    "    p3_start = max(p2_end_candidates)\n",
    "    p3 = input_string[p3_start:].strip()\n",
    "    \n",
    "    volume, _ = find_vol(p3)\n",
    "    pages, _ = find_pag(p3)\n",
    "    \n",
    "    if volume != '':\n",
    "        extracted_data['VOLUME'] = volume\n",
    "    if pages != '':\n",
    "        extracted_data['PAGES'] = pages\n",
    "    \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para separar nomes de autores \n",
    "\n",
    "(Funcionando bem somente para separador ';' melhorar para ausência dele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_abreviation(substring):\n",
    "    pattern = r'(?: [a-zA-Z]\\.)|(?: [a-zA-Z] \\.)'\n",
    "    if re.search(pattern, substring):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_surname(substring):\n",
    "    return not is_abreviation(substring) and substring.endswith(', ')\n",
    "\n",
    "def compose_full_name(surname, parts, marker):\n",
    "    full_name = \"\"\n",
    "    for part in parts:\n",
    "        full_name += part + marker\n",
    "    full_name += ' '+surname\n",
    "    return full_name.strip()\n",
    "\n",
    "def split_authors(string, verbose=False):\n",
    "    authors_names = []\n",
    "    \n",
    "    m1a = \"; \"\n",
    "    m1b = \", \"\n",
    "    \n",
    "    if m1a in string and (string.count(m1a) <= string.count(m1b) or m1b not in string):\n",
    "        marker = m1a\n",
    "        authors_names = string.split(marker)\n",
    "        return [x.strip() for x in authors_names]\n",
    "    else:\n",
    "        marker = m1b\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Selected marker: \"{marker}\"')\n",
    "\n",
    "    parts_list = string.split(marker)\n",
    "    name    = \"\"\n",
    "    surname = \"\"\n",
    "    \n",
    "    for part in parts_list:\n",
    "        if is_abreviation(part):\n",
    "            classification = 'Abrev'\n",
    "            name += part + marker\n",
    "        else:\n",
    "            classification = 'Name'\n",
    "            if is_surname(part) or surname == \"\":\n",
    "                classification = 'SOBRENOME'\n",
    "                if surname:\n",
    "                    full_name = compose_full_name(surname.strip(), name.split(marker), ', ')\n",
    "                    if full_name not in authors_names:\n",
    "                        authors_names.append(full_name)\n",
    "                surname = part\n",
    "                name = part + marker\n",
    "            else:\n",
    "                name = part + marker\n",
    "        if verbose:\n",
    "            # print(f'Quantidade de m1a: {string.count(m1a)} \\nQuantidade de m1b: {string.count(m1b)}')\n",
    "            print(f'Autor: {part:40} | Forma: {classification}')\n",
    "\n",
    "        authors_names.append(part.strip(marker).strip())\n",
    "     \n",
    "    return [x.strip() for x in authors_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BARBOSA, ANTONIO MARCOS AIRES',\n",
      " 'ANTONIO MARCOS AIRES BARBOSA',\n",
      " 'BARBOSA FILHO, A. M. A.',\n",
      " 'SUZANA, B. B. A. B.']\n"
     ]
    }
   ],
   "source": [
    "# Testando a função\n",
    "input_string = 'BARBOSA, ANTONIO MARCOS AIRES ; ANTONIO MARCOS AIRES BARBOSA ; BARBOSA FILHO, A. M. A. ; SUZANA, B. B. A. B. '\n",
    "names = split_authors(input_string, 1)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected marker: \", \"\n",
      "Autor: BARBOSA                                  | Forma: SOBRENOME\n",
      "Autor: ANTONIO MARCOS AIRES                     | Forma: Name\n",
      "Autor: ANTONIO MARCOS AIRES BARBOSA             | Forma: Name\n",
      "Autor: BARBOSA FILHO                            | Forma: Name\n",
      "Autor: A. M. A.                                 | Forma: Abrev\n",
      "Autor: SUZANA                                   | Forma: Name\n",
      "Autor: B. B. A. B.                              | Forma: Abrev\n",
      "['BARBOSA',\n",
      " 'ANTONIO MARCOS AIRES',\n",
      " 'ANTONIO MARCOS AIRES BARBOSA',\n",
      " 'BARBOSA FILHO',\n",
      " 'A. M. A.',\n",
      " 'SUZANA',\n",
      " 'B. B. A. B.']\n"
     ]
    }
   ],
   "source": [
    "# Testando a função\n",
    "input_string = 'BARBOSA, ANTONIO MARCOS AIRES, ANTONIO MARCOS AIRES BARBOSA, BARBOSA FILHO, A. M. A., SUZANA, B. B. A. B.'\n",
    "names = split_authors(input_string, 1)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Antonio Marcos Aires BARBOSA'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compose_full_name('BARBOSA', 'Antonio Marcos Aires', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BARBOSA FILHO, A. M. A.',\n",
       " 'SUZANA, B. B. A. B.',\n",
       " 'ANTONIO MARCOS AIRES BARBOSA']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'BARBOSA FILHO, A. M. A. ; SUZANA, B. B. A. B. ; ANTONIO MARCOS AIRES BARBOSA '\n",
    "split_authors(string, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de montar dataframes a partir dos dados brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_string(citation, verbose=False):\n",
    "    citation = citation.replace('CitaÃ§Ãµes:','Citações:')\n",
    "    # Define potential separators in order of preference\n",
    "    separators = [r' \\. ', r' ; ', r'(?<=[^A-Z\\s])\\. ']\n",
    "    \n",
    "    for sep in separators:\n",
    "            # Split the citation using regex\n",
    "            parts = re.split(sep, citation)\n",
    "            if len(parts) > 1:\n",
    "                authors = parts[0]\n",
    "                if verbose is True:\n",
    "                    print(type(authors))\n",
    "                    print(authors)\n",
    "                remaining_info = citation.split(authors)[1].lstrip(sep)\n",
    "\n",
    "                volume_match = re.search(r'v\\. (\\d+)', remaining_info)\n",
    "                volume = volume_match.group(1) if volume_match and volume_match is not None else ''\n",
    "                if volume_match:\n",
    "                    start_position = volume_match.start()\n",
    "                    title_journal = remaining_info[:start_position-2].strip()\n",
    "                    try:\n",
    "                        journal = title_journal.split('. ')[1]\n",
    "                    except:\n",
    "                        journal = ''\n",
    "                else:\n",
    "                    start_position = len(citation)\n",
    "                    title_journal = remaining_info[:start_position].strip()\n",
    "                    journal = ''\n",
    "                pages_match = re.search(r'p\\. ([\\d\\-]+)', remaining_info)\n",
    "                pages = pages_match.group(1) if pages_match and pages_match is not None else ''\n",
    "\n",
    "                year_match = re.search(r'(\\d{4}\\.)', remaining_info)\n",
    "                year = year_match.group(1).strip('.') if year_match else ''\n",
    "\n",
    "                title   = title_journal.split('. ')[0]\n",
    "                \n",
    "                if type(parts[0]) is str:\n",
    "                    authors = split_authors(parts[0], verbose=False)\n",
    "                else:\n",
    "                    authors = [authors]\n",
    "\n",
    "                return {\n",
    "                    'authors': authors,\n",
    "                    'title': title,\n",
    "                    'journal': journal,\n",
    "                    'volume': volume,\n",
    "                    'pages': pages,\n",
    "                    'year': year\n",
    "                }\n",
    "\n",
    "    return citation, ''\n",
    "    \n",
    "\n",
    "def parse_dataframe(df):\n",
    "    # Initialize an empty list to hold the parsed data\n",
    "    parsed_data = []\n",
    "    \n",
    "    # Iterate over each row in the DataFrame\n",
    "    for idx, row in df.iterrows():\n",
    "        # Extract the 'ARTIGO' value\n",
    "        citation = row['ARTIGO']\n",
    "        \n",
    "        # Parse the citation using the previously defined 'parse_citation' function\n",
    "        parsed_citation = parse_string(citation)\n",
    "        \n",
    "        # Create a new dictionary that combines the parsed citation data with the remaining row data\n",
    "        new_row = parsed_citation.copy() if parsed_citation else {}\n",
    "        for col in ['ANO_PUB', 'STATUS', 'MATRÍCULA', 'NOME', 'ÁREA', 'CARGO', 'VÍNCULO', 'INGRESSO_FIOCE', 'NÍVEL', 'ANO_INGRESSO_FIOCE']:\n",
    "            new_row[col] = row[col]\n",
    "        \n",
    "        # Append this new row dictionary to the list of parsed data\n",
    "        parsed_data.append(new_row)\n",
    "        \n",
    "    # Convert the list of parsed data dictionaries into a new DataFrame\n",
    "    new_df = pd.DataFrame(parsed_data)\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "def find_authors_and_others(citation):\n",
    "    # Define the separator types and their priority\n",
    "    separators = [' \\. ', '; ', '. ']\n",
    "    \n",
    "    # Check for each separator in the priority order\n",
    "    for sep in separators:\n",
    "        parts = re.split(sep, citation)\n",
    "        \n",
    "        # Special case for '. ' where it might be part of an abbreviated author name\n",
    "        if sep == '. ':\n",
    "            author_parts = []\n",
    "            for i, part in enumerate(parts):\n",
    "                # If the previous part ends with an uppercase letter followed by a space, it is likely an author's abbreviated initial\n",
    "                if i > 0 and (parts[i-1][-1].isupper() and parts[i-1][-2] == ' '):\n",
    "                    author_parts.append(part)\n",
    "                else:\n",
    "                    # Once we encounter a part that doesn't meet the condition, we break and consider the authors' list complete\n",
    "                    break\n",
    "            \n",
    "            if author_parts:\n",
    "                authors = f\"{sep}\".join(parts[:len(author_parts) + 1])\n",
    "                remaining_info = f\"{sep}\".join(parts[len(author_parts) + 1:])\n",
    "                return authors, remaining_info\n",
    "        \n",
    "        else:\n",
    "            if len(parts) > 1:\n",
    "                authors = parts[0]\n",
    "                remaining_info = sep.join(parts[1:])\n",
    "                return authors, remaining_info\n",
    "                \n",
    "    return citation, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GERAR DATAFRAMES COM LISTA DE PUBLICAÇÕES DE CADA AUTOR\n",
    "def montar_publicacoes(df_secoes):\n",
    "    filtro  = 'Artigos completos publicados em periódicos'\n",
    "    artigos = df_secoes[(df_secoes.ROTULOS == filtro)]\n",
    "    print(f'Total de linhas de dados: {len(artigos)}')\n",
    "    \n",
    "    nomes   = df_secoes[df_secoes.ROTULOS=='Nome'].values\n",
    "    print(f'Total de nomes de servidores: {len(nomes)}')  \n",
    "\n",
    "    cont=[]\n",
    "    publicacoes=[]\n",
    "    l_curriculo=[]\n",
    "    l_autores=[]\n",
    "    l_titulo=[]\n",
    "    l_revista=[]\n",
    "    l_ano_pub=[]\n",
    "    l_volume=[]\n",
    "    l_paginas=[]\n",
    "    # l_primautor=[]\n",
    "    # l_ultimautor=[]\n",
    "    # l_coaut=[]\n",
    "    # l_numero=[]\n",
    "    # l_local=[]\n",
    "    # l_doi=[]\n",
    "    \n",
    "    remover =['Ordenar por','Ordem Cronológica','Número de citações Web of science','Número de citações Scopus','Numero de citações Scielo','Primeiro autor','Impacto JCR','Ordem de Importância','Livros publicados/organizados ou edições']\n",
    "    \n",
    "    for n,linha in enumerate(artigos['CONTEUDOS']):\n",
    "        linha = linha.replace('CitaÃ§Ãµes:','Citações:')\n",
    "        c=0\n",
    "        # print(type(linha))\n",
    "        for i in eval(linha):\n",
    "            if i not in remover and len(i)>15 and 'Citações:' not in i:\n",
    "                c+=1\n",
    "                cont.append(c)\n",
    "                publicacoes.append(i)\n",
    "                data = parse_string(i)\n",
    "                l_curriculo.append(nomes[n][0])\n",
    "                l_autores.append(data[\"authors\"])\n",
    "                l_titulo.append(data[\"title\"])\n",
    "                l_revista.append(data[\"journal\"])\n",
    "                l_volume.append(data[\"volume\"])\n",
    "                l_paginas.append(data[\"pages\"])\n",
    "                l_ano_pub.append(data[\"year\"])\n",
    "                #  prim_autor, ult_autor, coaut, titulo, revista, local, volume, numero, paginas, ano_publicacao, doi, problemas  = extrair_detalhes(i)\n",
    "                #  l_primautor.append(prim_autor)\n",
    "                #  l_ultimautor.append(ult_autor)\n",
    "                #  l_coaut.append(coaut)\n",
    "                #  l_numero.append(numero)\n",
    "                #  l_local.append(local)\n",
    "                #  l_doi.append(doi)\n",
    "            \n",
    "    ## Monta novo dataframe para ver primeiro e último autor separados dos demais colaboradores\n",
    "    df_artigos = pd.DataFrame({\n",
    "        'CURRICULO': pd.Series(l_curriculo),\n",
    "        'AUTORES': pd.Series(l_autores),\n",
    "        'TITULO': pd.Series(l_titulo),\n",
    "        'REVISTA': pd.Series(l_revista),\n",
    "        'ANO_PUB': pd.Series(l_ano_pub),\n",
    "        'VOLUME':pd.Series(l_volume),\n",
    "        'PAGINAS': pd.Series(l_paginas),\n",
    "        # 'PRIMEIRO_AUTOR': pd.Series(l_primautor),\n",
    "        # 'ULTIMO_AUTOR': pd.Series(l_ultimautor),\n",
    "        # 'COAUTORES': pd.Series(l_coaut),\n",
    "        # 'LOCAL': pd.Series(l_local),        \n",
    "        # 'DOI': pd.Series(l_doi),\n",
    "    })\n",
    "\n",
    "    return df_artigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GERAR DATAFRAMES COM LISTA DE PUBLICAÇÕES DE CADA AUTOR E DATAFRAME COM LISTA DE COLABORAÇÕES UMA POR LINHA\n",
    "def dividir(linha_dados):\n",
    "    '''Identifica os separadores de nomes de autores em uma string\n",
    "     Recebe: a string e entrega uma lista dividida por possíveis separadores como o ;\n",
    "    Retorna: linha de dados dividida com o separador escolhido dentro da função\n",
    "      Autor: Marcos Aires Fev.2022\n",
    "    '''\n",
    "    \n",
    "    ## encontrar padrões com regular expressions \n",
    "    qte_divisor_autores  = re.compile(r';')            #Símbolo \";\" na string\n",
    "    nome_autor_inicio    = re.compile(r'^[A-ZÀ-ú]+,')  #Uma ou mais ocorrência de letras maiúsculas no início da string\n",
    "    # nome_abreviatura     = re.compile(r'^[A-Z].')      #Uma ou mais ocorrência de letras\n",
    "     \n",
    "    ## variáveis para encontrar padrões com expressões regulares\n",
    "    div_autores     = qte_divisor_autores.findall(linha_dados)\n",
    "    nomes_autores   = nome_autor_inicio.findall(linha_dados)\n",
    "    # div_abreviatura = nome_autor_inicio.findall(linha_dados)\n",
    "\n",
    "    ## parâmetros para classificar cada linha como número de ordem, dados de autor ou citações da publicação\n",
    "    cond_pntvrg = len(div_autores)>0\n",
    "    cond_pnt    = len(nomes_autores)>0\n",
    "    # cond_abrev  = len(div_abreviatura)>0\n",
    "\n",
    "    if cond_pntvrg is True:\n",
    "        div_inicial = div_pvirg=linha_dados.split(\";\") \n",
    "    elif cond_pnt is True:\n",
    "        div_inicial = div_pvirg=linha_dados.split(\". \")\n",
    "        \n",
    "    return div_inicial\n",
    "\n",
    "\n",
    "def montar_dfcolab_linhas(df_artigos):\n",
    "    '''Aplica filtro em df_dados para montar o dataframe de dados detalhados de artigos publicados\n",
    "        Recebe: Dataframe com os artigos gerado pela função montar_df_artigos(containers).\n",
    "       Utiliza: Função extrair_detalhes()\n",
    "       Retorna: Dataframe df_colabartigos com os dados de PRIMEIRO_AUTOR, ULTIMO_AUTOR, COAUTORES, TITULO, REVISTA, ANO_PUB.\n",
    "         Autor: Marcos Aires Fev.2022\n",
    "    '''\n",
    "    \n",
    "    dados_artigo=df_artigos['dados_artigo']\n",
    "    l_primautor, l_ultimautor, l_coaut, l_titulo, l_revista, l_local, l_volume, l_numero, l_paginas, l_ano_pub, l_doi = [],[],[],[],[],[],[],[],[],[],[]\n",
    "    \n",
    "    primeiro_autor=''\n",
    "    revista=''\n",
    "    doi=''\n",
    "    local=''\n",
    "    volume=''\n",
    "    numero=''\n",
    "    paginas=''\n",
    "    ano_publicacao=''\n",
    "    \n",
    "    ## Para cada artigo no dataframe extrai os dados detalhados com uso da função de quebra da string\n",
    "    for i in dados_artigo:\n",
    "        try:\n",
    "            primeiro_autor, ultimo_autor, coautores, titulo, revista, local, volume, numero, paginas, ano_publicacao, doi, problemas = extrair_detalhes(i)\n",
    "            l_primautor.append(primeiro_autor)\n",
    "            l_ultimautor.append(ultimo_autor)\n",
    "            l_coaut.append(coautores)\n",
    "            l_titulo.append(titulo)\n",
    "            l_revista.append(revista)\n",
    "            l_local.append(local)\n",
    "            l_volume.append(volume)\n",
    "            l_numero.append(numero)\n",
    "            l_paginas.append(paginas)\n",
    "            l_ano_pub.append(ano_publicacao)\n",
    "            clear_output(wait=True)\n",
    "        except Exception as e:\n",
    "            print('Erro ao montar colaborações na função montar_dfcolab_linhas()')\n",
    "            traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "            print(e,traceback_str)\n",
    "            \n",
    "    ## Monta novo dataframe de artigos com seus dados individualizados\n",
    "    df_colabartigos = pd.DataFrame({\n",
    "        'PRIMEIRO_AUTOR': pd.Series(l_primautor),\n",
    "        'ULTIMO_AUTOR': pd.Series(l_ultimautor),\n",
    "        'COAUTORES': pd.Series(l_coaut),\n",
    "        'TITULO': pd.Series(l_titulo),\n",
    "        'REVISTA': pd.Series(l_revista),\n",
    "        'ANO_PUB': pd.Series(l_ano_pub),\n",
    "        'local': pd.Series(l_local),\n",
    "        'rev_volume':pd.Series(l_volume),\n",
    "        'rev_numero':pd.Series(l_numero),\n",
    "        'paginas': pd.Series(l_paginas),\n",
    "    })\n",
    "    \n",
    "    return df_colabartigos, problemas\n",
    "\n",
    "\n",
    "def padronizar_titulo(titulo_bruto):\n",
    "    '''Retira acentos, expressão (Org.) e espaços vazios do título da publicação\n",
    "    Autor: Marcos Aires (Fev.2022)\n",
    "    '''\n",
    "    import unicodedata\n",
    "    import re\n",
    "    string = ''.join(ch for ch in unicodedata.normalize('NFKD', titulo_bruto) if not unicodedata.combining(ch))\n",
    "    string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.','')\n",
    "    \n",
    "    titulo_padronizado = string.strip().strip('\"')\n",
    "    \n",
    "    return titulo_padronizado\n",
    "\n",
    "\n",
    "def montar_lista_autores(df_dadosgrupo, df_colunaautores):\n",
    "    ''' Cria lista com o nome padronizado para cada autor\n",
    "     Recebe: Dataframe com os dados brutos do grupo de pesquisa; Coluna de um Dataframe com nomes dos membros do grupo de pesquisa, com um nome de autor em cada linha; Lista de tuplas a trocar (origem, destino)\n",
    "    Utiliza: Funções padronizar_nome(nome), extrair_variantes(df_dadosgrupo)\n",
    "    Retorna: lista_padronizada com os nomes padronizados\n",
    "      Autor: Marco Aires (Fev.2022)\n",
    "    '''\n",
    "    \n",
    "#     lista_nomes=df_professores['PESQUISADORES']\n",
    "    lista_padronizada=[]\n",
    "    origem=[]\n",
    "    destino=[]\n",
    "    trocar=extrair_variantes(df_dadosgrupo)\n",
    "    for i,j in trocar:\n",
    "        origem.append(i)\n",
    "        destino.append(j)\n",
    "    \n",
    "    c=0\n",
    "    for autor in df_colunaautores:\n",
    "        # print(' ANTES:',autor)\n",
    "        c+=1\n",
    "        try:\n",
    "            nome_padronizado = padronizar_nome(autor.strip())\n",
    "        except:\n",
    "            nome_padronizado = autor.strip()\n",
    "            pass\n",
    "        if autor in origem:\n",
    "            for j,k in zip(origem,destino):\n",
    "                if autor.lower().strip()==j.lower().strip():\n",
    "                    l=k\n",
    "#             print(f'{c:3d}. {i:<35} ==> {j:<35} ==> {k}')\n",
    "            lista_padronizada.append(l)\n",
    "            # print('DEPOIS:',l)\n",
    "        else:\n",
    "            # print('DEPOIS:',nome_padronizado)\n",
    "            lista_padronizada.append(nome_padronizado)\n",
    "    \n",
    "    return lista_padronizada\n",
    "\n",
    "\n",
    "def montar_lista_coautores(df_dadosgrupo,df_colunacoautores):\n",
    "    '''\n",
    "    Cria lista com o nome padronizado de cada autor\n",
    "     Recebe: Coluna de um Dataframe com nomes dos membros do grupo de pesquisa, com vários nomes de autor em cada célula\n",
    "    Utiliza: Funções padronizar_nome(nome), extrair_variantes(df_dadosgrupo)\n",
    "    Retorna: Lista com os nomes padronizados\n",
    "      Autor: Marco Aires (Fev.2022)\n",
    "    '''\n",
    "    lista_coautores_padronizada=[]\n",
    "    origem=[]\n",
    "    destino=[]\n",
    "    \n",
    "    filtro1   = 'Nome'\n",
    "    lista_nomes = list(df_dadosgrupo[(df_dadosgrupo.ROTULOS == filtro1)]['CONTEUDOS'].values)\n",
    "    lista_nomes\n",
    "    \n",
    "    trocar=extrair_variantes(df_dadosgrupo)\n",
    "    for i,j in trocar:\n",
    "        origem.append(i)\n",
    "        destino.append(j)\n",
    "    \n",
    "    c=0\n",
    "    for coautores in df_colunacoautores.values:\n",
    "        c+=1\n",
    "        # print(' ANTES:',coautores)\n",
    "        lista_temp=[]\n",
    "        for coautor in coautores:\n",
    "            try:\n",
    "                nome_padronizado = padronizar_nome(coautor.strip())\n",
    "            except:\n",
    "                nome_padronizado = coautor.strip()\n",
    "            if coautor in origem or nome_padronizado in origem:             \n",
    "                for j,k in zip(origem,destino):\n",
    "                    if coautor.lower().strip()==j.lower().strip():\n",
    "                        l=k\n",
    "                lista_temp.append(l)\n",
    "            else:\n",
    "                lista_temp.append(nome_padronizado)      \n",
    "        # print('DEPOIS:',lista_temp)\n",
    "        lista_coautores_padronizada.append(lista_temp) \n",
    "    \n",
    "    return lista_coautores_padronizada\n",
    "\n",
    "\n",
    "\n",
    "## MONTAGEM E VISUALIZAÇÃO DOS DATAFRAMES QUE IRÃO GERAR OS GRAFOS\n",
    "def montar_bipartido(df):\n",
    "    '''Monta dataframes de colaboração a partir do dataframe de dados brutos df_dados extraídos de cada autor\n",
    "     Recebe: Dataframe df_dados com dados brutos de cada autor\n",
    "    Utiliza: Função parse_string(linha_conteudo)\n",
    "    Retorna: Dois dataframes um com lista de publicações separada por autoria e colaborações outro com uma linha por colaborador\n",
    "      Autor: Marcos Aires (Fev.2022)\n",
    "    '''\n",
    "    filtro='Artigos completos publicados em periódicos'\n",
    "    # df=df_dados_unico\n",
    "    dados = df[(df.ROTULOS == filtro)]\n",
    "    remover=['Ordenar por','Ordem Cronológica','Número de citações Web of science','Número de citações Scopus','Numero de citações Scielo','Primeiro autor','Impacto JCR','Ordem de Importância','Livros publicados/organizados ou edições']\n",
    "    publicacoes=[]\n",
    "    cont=[]\n",
    "    l_curriculo=[]\n",
    "    l_primautor=[]\n",
    "    l_ultimautor=[]\n",
    "    l_coaut=[]\n",
    "    l_titulo=[]\n",
    "    l_revista=[]\n",
    "    l_ano_pub=[]\n",
    "    l_local=[]\n",
    "    l_volume=[]\n",
    "    l_numero=[]\n",
    "    l_paginas=[]\n",
    "    l_doi=[]\n",
    "    l_problemas=[]\n",
    "\n",
    "    for n,j in enumerate(dados['CONTEUDOS']):\n",
    "        c=0\n",
    "        for i in j: \n",
    "            if i not in remover and len(i)>15 and 'Citações:' not in i:\n",
    "                c+=1\n",
    "                cont.append(c)\n",
    "                publicacoes.append(i)\n",
    "                data  = parse_string(i)\n",
    "                l_curriculo.append(dados['CURRICULO'].iloc[n])\n",
    "                l_autores.append(data[\"authors\"])\n",
    "                l_titulo.append(data[\"title\"])\n",
    "                l_revista.append(data[\"journal\"])\n",
    "                l_volume.append(data[\"volume\"])\n",
    "                l_paginas.append(data[\"pages\"])\n",
    "                l_ano_pub.append(data[\"year\"])\n",
    "                #  l_primautor.append(prim_autor)\n",
    "                #  l_ultimautor.append(ult_autor)\n",
    "                #  l_coaut.append(coaut)\n",
    "                #  l_numero.append(numero)\n",
    "                #  l_local.append(local)\n",
    "                #  l_doi.append(doi)\n",
    "\n",
    "    ## Monta novo dataframe para ver primeiro e último autor separados dos demais colaboradores\n",
    "    df_colabartigos = pd.DataFrame({\n",
    "        'CURRICULO': pd.Series(l_curriculo),\n",
    "        'AUTORES': pd.Series(l_autores),\n",
    "        'PRIMEIRO_AUTOR': pd.Series(l_primautor),\n",
    "        'ULTIMO_AUTOR': pd.Series(l_ultimautor),\n",
    "        'COAUTORES': pd.Series(l_coaut),\n",
    "        'TITULO': pd.Series(l_titulo),\n",
    "        'REVISTA': pd.Series(l_revista),\n",
    "        'ANO_PUB': pd.Series(l_ano_pub),\n",
    "    })\n",
    "\n",
    "\n",
    "    ## Monta novo dataframe para ver uma linha por cada colaborador na autoria \n",
    "    l_autores =[]\n",
    "    l_titulos =[]\n",
    "    l_anos    =[]\n",
    "    l_tipos   =[]\n",
    "\n",
    "    for i in range(len(df_colabartigos['TITULO'])):\n",
    "        l_anos.append(df_colabartigos['ANO_PUB'][i])\n",
    "        l_titulos.append(df_colabartigos['TITULO'][i])\n",
    "        l_autores.append(df_colabartigos['PRIMEIRO_AUTOR'][i])\n",
    "        l_tipos.append('primeiro_autor')\n",
    "\n",
    "        for j in df_colabartigos['COAUTORES'][i]:\n",
    "            l_anos.append(df_colabartigos['ANO_PUB'][i])\n",
    "            l_titulos.append(df_colabartigos['TITULO'][i])\n",
    "            try:\n",
    "                j=padronizar_nome(j.strip())\n",
    "            except:\n",
    "                pass\n",
    "            l_autores.append(j)\n",
    "            l_tipos.append('colaborador')\n",
    "\n",
    "    for k in range(len(df_colabartigos['TITULO'])):\n",
    "        if df_colabartigos['ULTIMO_AUTOR'][k] != '':\n",
    "            ultimo=df_colabartigos['ULTIMO_AUTOR'][k]\n",
    "            try:\n",
    "                ultimo=padronizar_nome(ultimo)\n",
    "            except:\n",
    "                pass\n",
    "            l_anos.append(df_colabartigos['ANO_PUB'][k])\n",
    "            l_titulos.append(df_colabartigos['TITULO'][k])\n",
    "            l_autores.append(ultimo)\n",
    "            l_tipos.append('ultimo_autor')\n",
    "\n",
    "    df_bipartido = pd.DataFrame({\n",
    "        'ANO_PUB': pd.Series(l_anos),\n",
    "        'TITULO': pd.Series(l_titulos),\n",
    "        'AUTORES': pd.Series(l_autores),\n",
    "        'TIPO': pd.Series(l_tipos)\n",
    "    })\n",
    "\n",
    "    df_bipartido.sort_values([\"ANO_PUB\", \"TITULO\"],\n",
    "                               axis = 0, \n",
    "                               ascending = True,\n",
    "                               inplace = True,\n",
    "                               na_position = \"first\")\n",
    "\n",
    "    df_bipartido.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # filtro='Supervisão de pós-doutorado'\n",
    "    # filtro='Monografia de conclusão de curso de aperfeiçoamento/especialização'\n",
    "    # filtro='Trabalho de conclusão de curso de graduação'\n",
    "    # filtro='Iniciação científica'\n",
    "    # filtro='Orientações de outra natureza'\n",
    "    \n",
    "    \n",
    "    filtro='Orientação Dissertação de mestrado'\n",
    "    dados = df[(df.ROTULOS == filtro)]\n",
    "    remover=['Ordenar por','Ordem Cronológica','Número de citações Web of science','Número de citações Scopus','Numero de citações Scielo','Primeiro autor','Impacto JCR','Ordem de Importância','Livros publicados/organizados ou edições']   \n",
    "    orientacoes_mestrado=[]\n",
    "    # remover=[]\n",
    "    cont=[]\n",
    "    for j in dados['CONTEUDOS']:\n",
    "        c=0\n",
    "        for i in j: \n",
    "            if i not in remover and len(i)>15 and 'Citações:' not in i:\n",
    "                c+=1\n",
    "                cont.append(c)\n",
    "                orientacoes_mestrado.append(i)   \n",
    "                \n",
    "    orientandos=[]\n",
    "    trabalhos_orientados=[]\n",
    "    ano_orientacao=[]\n",
    "    instituicoes_orientacao=[]\n",
    "    papeis_orientacao=[]\n",
    "\n",
    "    for j in orientacoes_mestrado:\n",
    "        i = j.split('. ')\n",
    "        orientando=i[0]\n",
    "        trabalho=i[1]\n",
    "        ano=i[2]\n",
    "        terceiro_dado=i[3]\n",
    "        # print(terceiro_dado)\n",
    "        if len(terceiro_dado) > 5:\n",
    "            instituicao=i[3]\n",
    "            papel=i[4].split(': ')[0]\n",
    "        else:\n",
    "            instituicao=i[4]\n",
    "            papel=i[5].split(': ')[0]\n",
    "\n",
    "        orientandos.append(orientando.title().strip())\n",
    "        trabalhos_orientados.append(trabalho)\n",
    "        ano_orientacao.append(ano)\n",
    "        instituicoes_orientacao.append(instituicao)\n",
    "        papeis_orientacao.append(papel)  \n",
    "    \n",
    "    df_orientacoes_mestrado = pd.DataFrame({\n",
    "        'ANO_CONCLUSÃO': pd.Series(ano_orientacao),\n",
    "        'TÍTULO': pd.Series(trabalhos_orientados),\n",
    "        'ORIENTADOS': pd.Series(orientandos),\n",
    "        'PAPEL_ORIENTAÇÃO': pd.Series(papeis_orientacao),\n",
    "        'INSTITUIÇÃO': pd.Series(instituicoes_orientacao),\n",
    "    })\n",
    "\n",
    "\n",
    "    filtro='Orientação Tese de doutorado'\n",
    "    dados = df[(df.ROTULOS == filtro)]\n",
    "    remover=['Ordenar por','Ordem Cronológica','Número de citações Web of science','Número de citações Scopus','Numero de citações Scielo','Primeiro autor','Impacto JCR','Ordem de Importância','Livros publicados/organizados ou edições']   \n",
    "    orientacoes_doutorado=[]\n",
    "    # remover=[]\n",
    "    cont=[]\n",
    "    for j in dados['CONTEUDOS']:\n",
    "        c=0\n",
    "        for i in j: \n",
    "            if i not in remover and len(i)>15:\n",
    "                c+=1\n",
    "                cont.append(c)\n",
    "                orientacoes_doutorado.append(i)   \n",
    "                \n",
    "    orientandos=[]\n",
    "    trabalhos_orientados=[]\n",
    "    ano_orientacao=[]\n",
    "    instituicoes_orientacao=[]\n",
    "    papeis_orientacao=[]\n",
    "\n",
    "    for j in orientacoes_doutorado:\n",
    "        i = j.split('. ')\n",
    "        orientando=i[0]\n",
    "        trabalho=i[1]\n",
    "        ano=i[2]\n",
    "        terceiro_dado=i[3]\n",
    "        # print(terceiro_dado)\n",
    "        if len(terceiro_dado) > 5:\n",
    "            instituicao=i[3]\n",
    "            papel=i[4].split(': ')[0]\n",
    "        else:\n",
    "            instituicao=i[4]\n",
    "            papel=i[5].split(': ')[0]\n",
    "\n",
    "        orientandos.append(orientando.title().strip())\n",
    "        trabalhos_orientados.append(trabalho)\n",
    "        ano_orientacao.append(ano)\n",
    "        instituicoes_orientacao.append(instituicao)\n",
    "        papeis_orientacao.append(papel)  \n",
    "    \n",
    "    df_orientacoes_doutorado = pd.DataFrame({\n",
    "        'ANO_CONCLUSÃO': pd.Series(ano_orientacao),\n",
    "        'TÍTULO': pd.Series(trabalhos_orientados),\n",
    "        'ORIENTADOS': pd.Series(orientandos),\n",
    "        'PAPEL_ORIENTAÇÃO': pd.Series(papeis_orientacao),\n",
    "        'INSTITUIÇÃO': pd.Series(instituicoes_orientacao),\n",
    "    })\n",
    "    \n",
    "    return df_colabartigos, df_bipartido, df_orientacoes_mestrado, df_orientacoes_doutorado\n",
    "\n",
    "\n",
    "def visualizar_bipartido(df_dados):\n",
    "    '''Renderiza, no notebook ou em uma página HTML, a visualização do grafo de todas as colaborações a partir do dataframe de dados bipartidos\n",
    "     Recebe: Dataframe com uma linha para relacionamento, ou seja, uma linha para cada autor do artigo repetindo o mesmo artigo para quantos coautores houver.\n",
    "    Utiliza: Módulo network da biblioteca pyvis\n",
    "    Retorna: Visualização em HTML do grafo\n",
    "    Autor: Marcos Aires (Mar.2022)\n",
    "    '''\n",
    "    from pyvis.network import Network\n",
    "\n",
    "    origem =[]\n",
    "    destino=[]\n",
    "    pesos=[]\n",
    "    titulo=[]\n",
    "    ano=[]\n",
    "    peso=[]\n",
    "\n",
    "    for i in range(len(df_dados['AUTORES_PADRONIZADOS'])):\n",
    "        origem.append(df_dados['AUTORES_PADRONIZADOS'][i].title())\n",
    "        destino.append(df_dados['TITULO'][i].title())\n",
    "        titulo.append(df_dados['TITULO'][i])\n",
    "        ano.append(df_dados['ANO_PUB'][i])\n",
    "        peso.append(1)\n",
    "\n",
    "    df_bipartido = pd.DataFrame({\n",
    "                            'AUTOR': pd.Series(origem),\n",
    "                            'TITULO': pd.Series(titulo),\n",
    "                            'ANO_PUB': pd.Series(ano),\n",
    "                            'PESO': pd.Series(peso),\n",
    "                           }) \n",
    "\n",
    "    colab_artigos = Network(height='750px', \n",
    "                    width='100%', \n",
    "                    bgcolor='#222222', \n",
    "                    font_color='white',\n",
    "                    # fontsize=24,\n",
    "                    notebook=True,\n",
    "                           )\n",
    "\n",
    "    # modelo de física para conformação da rede\n",
    "    colab_artigos.barnes_hut()\n",
    "\n",
    "    ## Adicionando subgrafo referente ao componente principal com as colaborações\n",
    "    sources = df_bipartido['AUTOR']\n",
    "    targets = df_bipartido['TITULO']\n",
    "    weights = df_bipartido['PESO']\n",
    "    ano_pub = df_bipartido['ANO_PUB']\n",
    "\n",
    "    edge_data = zip(sources, targets, weights)\n",
    "\n",
    "    for e in edge_data:\n",
    "        src = e[0]\n",
    "        dst = e[1]\n",
    "        w   = e[2]\n",
    "\n",
    "        colab_artigos.add_node(src, src, title=src)\n",
    "        colab_artigos.add_node(dst, dst, title=dst)\n",
    "        colab_artigos.add_edge(src, dst, value=w)\n",
    "\n",
    "\n",
    "    neighbor_map = colab_artigos.get_adj_list()\n",
    "\n",
    "    # add neighbor data to node hover data\n",
    "    for node in colab_artigos.nodes:\n",
    "        node['title'] += ' COLABOROU_COM:<br>' + '<br>'.join(neighbor_map[node['id']])\n",
    "        node['value'] = len(neighbor_map[node['id']])\n",
    "\n",
    "    colab_artigos.show_buttons(filter_=['physics'])\n",
    "    # colab_artigos.show('coautorias.html')\n",
    "    \n",
    "    return colab_artigos.show('coautorias.html')\n",
    "\n",
    "\n",
    "def montar_adj(df_dadoscolab):\n",
    "    '''Monta uma lista de colaborações, tomando o primeiro autor como origem e colaboradores como destino\n",
    "    Recebe: DataFrame com dados detalhados dos artigos\n",
    "    Retorna: DataFrame com lista de aresta de colaborações\n",
    "    Autor: Marcos Aires Fev.2022\n",
    "    '''\n",
    "    origem=[]\n",
    "    destinos=[]\n",
    "    lista_destinos=[]\n",
    "    lista_titulos=[]\n",
    "    lista_anos=[]\n",
    "\n",
    "    for i in range(len(df_dadoscolab['PRIMEIRO_AUTOR'])):\n",
    "        lista_anos.append(df_dadoscolab['ANO_PUB'][i])\n",
    "        lista_titulos.append(df_dadoscolab['TITULO'][i])\n",
    "        origem.append(df_dadoscolab['PRIMEIRO_AUTOR'][i])\n",
    "\n",
    "        \n",
    "    for i in range(len(df_dadoscolab['COAUTORES'])):\n",
    "        l1=df_dadoscolab['COAUTORES'][i]\n",
    "        l2=[df_dadoscolab['ULTIMO_AUTOR'][i]]\n",
    "        destino=l1+l2\n",
    "        lista_destinos.append(destino)\n",
    "\n",
    "    df_adj = pd.DataFrame({\n",
    "                            'ANO_PUB': pd.Series(lista_anos),\n",
    "                            'TITULO': pd.Series(lista_titulos),\n",
    "                            'PRIMEIRO_AUTOR': pd.Series(origem),\n",
    "                            'COAUTORES': pd.Series(lista_destinos),\n",
    "                           }) \n",
    "\n",
    "    return df_adj\n",
    "\n",
    "\n",
    "def montar_adj_primult(df_dados):\n",
    "    '''Monta uma lista de colaborações, tomando o primeiro autor como origem e ultimo autor como destino\n",
    "    Recebe: DataFrame com dados detalhados dos artigos\n",
    "    Retorna: DataFrame com lista de aresta de colaborações\n",
    "    Autor: Marcos Aires Fev.2022\n",
    "    '''\n",
    "    origem=[]\n",
    "    destinos=[]\n",
    "    lista_destinos=[]\n",
    "    lista_titulos=[]\n",
    "    lista_anos=[]\n",
    "\n",
    "    for i in range(len(df_dados['PRIMEIRO_AUTOR'])):\n",
    "        origem.append(df_dados['PRIMEIRO_AUTOR'][i])\n",
    "        lista_anos.append(df_dados['ANO_PUB'][i])\n",
    "        lista_titulos.append(df_dados['TITULO'][i])\n",
    "\n",
    "        \n",
    "    for j in range(len(df_dados['ULTIMO_AUTOR'])):\n",
    "        destinos.append(df_dados['ULTIMO_AUTOR'][j])\n",
    "\n",
    "    df_adj_prim_ult = pd.DataFrame({\n",
    "                            'ANO_PUB': pd.Series(lista_anos),\n",
    "                            'TITULO': pd.Series(lista_titulos),\n",
    "                            'PRIMEIRO_AUTOR': pd.Series(origem),\n",
    "                            'ULTIMO_AUTOR': pd.Series(destinos),\n",
    "                           }) \n",
    "\n",
    "    return df_adj_prim_ult\n",
    "\n",
    "\n",
    "def visualizar_colaboracoes(df_dados):\n",
    "    '''Renderiza, no notebook ou em uma página HTML, a visualização do grafo de todas as colaborações\n",
    "    Como parâmetro, recebe um dataframe de dados, onde: df_dados=montar_adj(df_dados)\n",
    "    Autor: Marcos Aires (Mar.2022)\n",
    "    '''\n",
    "    from pyvis.network import Network\n",
    "\n",
    "    origem =[]\n",
    "    destino=[]\n",
    "    pesos=[]\n",
    "    titulo=[]\n",
    "    ano=[]\n",
    "    peso=[]\n",
    "    lista_autores=[]\n",
    "\n",
    "    for i in range(len(df_dados['PRIMEIRO_AUTOR'])):\n",
    "        if i not in lista_autores:\n",
    "            lista_autores.append(df_dados['PRIMEIRO_AUTOR'][i].title())\n",
    "        \n",
    "        for j in df_dados['COAUTORES'][i]:\n",
    "            origem.append(df_dados['PRIMEIRO_AUTOR'][i].title())\n",
    "            destino.append(j.title())\n",
    "            if j not in lista_autores:\n",
    "                lista_autores.append(j.title())\n",
    "            titulo.append(df_dados['TITULO'][i])\n",
    "            ano.append(df_dados['ANO_PUB'][i])\n",
    "            peso.append(1)\n",
    "\n",
    "    df_grafo = pd.DataFrame({\n",
    "                            'PRIMEIRO_AUTOR': pd.Series(origem),\n",
    "                            'COAUTORES': pd.Series(destino),\n",
    "                            'TITULO': pd.Series(titulo),\n",
    "                            'ANO_PUB': pd.Series(ano),\n",
    "                            'PESO': pd.Series(peso),\n",
    "                           }) \n",
    "\n",
    "    colab_artigos = Network(height='750px', \n",
    "                    width='100%', \n",
    "                    bgcolor='#222222', \n",
    "                    font_color='white',\n",
    "                    # fontsize=24,\n",
    "                    notebook=True,\n",
    "                           )\n",
    "\n",
    "    # modelo de física para conformação da rede\n",
    "    colab_artigos.barnes_hut()\n",
    "\n",
    "    ## Adicionando subgrafo referente ao componente principal com as colaborações\n",
    "    sources = df_grafo['PRIMEIRO_AUTOR']\n",
    "    targets = df_grafo['COAUTORES']\n",
    "    weights = df_grafo['PESO']\n",
    "\n",
    "    titulo  = df_grafo['TITULO']\n",
    "    ano_pub = df_grafo['ANO_PUB']\n",
    "\n",
    "    edge_data = zip(sources, targets, weights)\n",
    "\n",
    "    for e in edge_data:\n",
    "        src = e[0]\n",
    "        dst = e[1]\n",
    "        w = e[2]\n",
    "\n",
    "        colab_artigos.add_node(src, src, title=src)\n",
    "        colab_artigos.add_node(dst, dst, title=dst)\n",
    "        colab_artigos.add_edge(src, dst, value=w)\n",
    "\n",
    "\n",
    "    # ## Adicionando subgrafo referente às variantes de nome em citações\n",
    "    # origem = NOME\n",
    "    # filtro = 'Nome em citações bibliográficas'\n",
    "    # variantes = df_dados[(df_dados.ROTULOS == filtro)]['CONTEUDOS'].values[0]\n",
    "\n",
    "    # origens = []\n",
    "    # pesos = []\n",
    "    # destinos = variantes\n",
    "\n",
    "    # # Atribui dados do dataset às variáveis que constroem o grafo\n",
    "    # for i in range(len(destinos)):\n",
    "    #     origens.append(origem)\n",
    "    #     pesos.append(100)\n",
    "\n",
    "    # arestas = zip(origens, destinos, pesos)\n",
    "    # for a in arestas:\n",
    "    #     src = a[0]\n",
    "    #     dst = a[1]\n",
    "    #     w = a[2]\n",
    "\n",
    "    #     colab_artigos.add_node(src, src, title=src, color = \"white\")\n",
    "    #     colab_artigos.add_node(dst, dst, title=dst)\n",
    "    #     colab_artigos.add_edge(src, dst, value=w)\n",
    "\n",
    "\n",
    "    neighbor_map = colab_artigos.get_adj_list()\n",
    "\n",
    "    # add neighbor data to node hover data\n",
    "    for node in colab_artigos.nodes:\n",
    "        node['title'] += ' COLABOROU_COM:<br>' + '<br>'.join(neighbor_map[node['id']])\n",
    "        node['value'] = len(neighbor_map[node['id']])\n",
    "\n",
    "    colab_artigos.show_buttons(filter_=['physics'])\n",
    "#     colab_artigos.show('coautorias.html')\n",
    "    \n",
    "    return colab_artigos.show('coautorias.html')\n",
    "\n",
    "\n",
    "def visualizar_colabprincipais(df_dados):\n",
    "    '''Renderiza, no notebook ou em uma página HTML, a visualização do grafo das principais colaborações.\n",
    "    Considera como principais as colaborações onde o autor é o primeiro ou o último autor.\n",
    "    Como parâmetro, recebe um dataframe de dados, onde: df_dados=montar_adj_primult(df_dados)\n",
    "    Autor: Marcos Aires (Mar.2022)\n",
    "    '''\n",
    "    from pyvis.network import Network\n",
    "\n",
    "    origem =[]\n",
    "    destino=[]\n",
    "    pesos=[]\n",
    "    titulo=[]\n",
    "    ano=[]\n",
    "    peso=[]\n",
    "    lista_autores=[]\n",
    "\n",
    "    for i in range(len(df_dados['PRIMEIRO_AUTOR'])):\n",
    "        origem.append(df_dados['PRIMEIRO_AUTOR'][i])\n",
    "        if i not in lista_autores:\n",
    "            lista_autores.append(df_dados['PRIMEIRO_AUTOR'][i])\n",
    "        \n",
    "    for j in range(len(df_dados['ULTIMO_AUTOR'])):\n",
    "        destino.append(df_dados['ULTIMO_AUTOR'][j])\n",
    "        if df_dados['ULTIMO_AUTOR'][j] not in lista_autores:\n",
    "            lista_autores.append(df_dados['ULTIMO_AUTOR'][j])\n",
    "    \n",
    "    titulo.append(df_dados['TITULO'][i])\n",
    "    ano.append(df_dados['ANO_PUB'][i])\n",
    "    peso.append(1)\n",
    "\n",
    "    df_grafo = pd.DataFrame({\n",
    "                            'PRIMEIRO_AUTOR': pd.Series(origem),\n",
    "                            'ULTIMO_AUTOR': pd.Series(destino),\n",
    "                            'TITULO': pd.Series(titulo),\n",
    "                            'ANO_PUB': pd.Series(ano),\n",
    "                            'PESO': pd.Series(peso),\n",
    "                           }) \n",
    "\n",
    "    colab_artigos = Network(height='750px', \n",
    "                    width='100%', \n",
    "                    bgcolor='#000000', \n",
    "                    font_color='white',\n",
    "                    # fontsize=24,\n",
    "                    notebook=True,\n",
    "                           )\n",
    "\n",
    "    # modelo de física para conformação da rede\n",
    "    colab_artigos.barnes_hut()\n",
    "\n",
    "    ## Adicionando subgrafo referente ao componente principal com as colaborações\n",
    "    sources = df_grafo['PRIMEIRO_AUTOR']\n",
    "    targets = df_grafo['ULTIMO_AUTOR']\n",
    "    weights = df_grafo['PESO']\n",
    "\n",
    "    titulo  = df_grafo['TITULO']\n",
    "    ano_pub = df_grafo['ANO_PUB']\n",
    "\n",
    "    edge_data = zip(sources, targets, weights)\n",
    "\n",
    "    for e in edge_data:\n",
    "        src = e[0]\n",
    "        dst = e[1]\n",
    "        w   = e[2]\n",
    "\n",
    "        colab_artigos.add_node(src, src, title=src)\n",
    "        colab_artigos.add_node(dst, dst, title=dst)\n",
    "        colab_artigos.add_edge(src, dst, value=w)\n",
    "\n",
    "\n",
    "    # ## Adicionando subgrafo referente às variantes de nome em citações\n",
    "    # origem = NOME\n",
    "    # filtro = 'Nome em citações bibliográficas'\n",
    "    # variantes = df_dados[(df_dados.ROTULOS == filtro)]['CONTEUDOS'].values[0]\n",
    "\n",
    "    # origens = []\n",
    "    # pesos = []\n",
    "    # destinos = variantes\n",
    "\n",
    "    # # Atribui dados do dataset às variáveis que constroem o grafo\n",
    "    # for i in range(len(destinos)):\n",
    "    #     origens.append(origem)\n",
    "    #     pesos.append(100)\n",
    "\n",
    "    # arestas = zip(origens, destinos, pesos)\n",
    "    # for a in arestas:\n",
    "    #     src = a[0]\n",
    "    #     dst = a[1]\n",
    "    #     w = a[2]\n",
    "\n",
    "    #     colab_artigos.add_node(src, src, title=src, color = \"white\")\n",
    "    #     colab_artigos.add_node(dst, dst, title=dst)\n",
    "    #     colab_artigos.add_edge(src, dst, value=w)\n",
    "\n",
    "\n",
    "    neighbor_map = colab_artigos.get_adj_list()\n",
    "\n",
    "    # add neighbor data to node hover data\n",
    "    for node in colab_artigos.nodes:\n",
    "        node['title'] += ' COLABOROU_COM:<br>' + '<br>'.join(neighbor_map[node['id']])\n",
    "        node['value'] = len(neighbor_map[node['id']])\n",
    "\n",
    "    colab_artigos.show_buttons(filter_=['physics'])\n",
    "    \n",
    "    return colab_artigos.show('coautorias_principais.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementar funções de Plotagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def get_initials(name):\n",
    "    return ''.join([word[0] for word in name.split()])\n",
    "\n",
    "def plotar_artigos_ano(df_artigosperiodo):\n",
    "    # Contar os valores dos anos da coluna ANO_PUB\n",
    "    count_anos = df_artigosperiodo['ANO_PUB'].value_counts().sort_index()\n",
    "\n",
    "    # Criar o gráfico de barras com plotly express\n",
    "    fig = px.bar(x=range(len(count_anos.index)), \n",
    "                 y=count_anos.values,\n",
    "                 labels={'x':'Ano de publicação', 'y':'Quantidade de artigos'},\n",
    "                 title='Quantidade de Artigos por Ano')\n",
    "\n",
    "    # Ajustar os tick labels do eixo x para mostrar os anos\n",
    "    fig.update_xaxes(tickvals=list(range(len(count_anos.index))), ticktext=count_anos.index, showgrid=False)\n",
    "\n",
    "    # Remover linhas de grade horizontal (eixo y)\n",
    "    fig.update_yaxes(showgrid=False)\n",
    "\n",
    "    # Adicionar a anotação dos valores em cada barra\n",
    "    for index, value in enumerate(count_anos.values):\n",
    "        fig.add_annotation(\n",
    "            x=index,\n",
    "            y=value + (0.05 * max(count_anos.values)),  # Ajustar esta proporção conforme necessário\n",
    "            text=str(value),\n",
    "            showarrow=False,\n",
    "            font_size=20\n",
    "        )\n",
    "\n",
    "    # Adicionar a anotação com a quantidade total de artigos no período\n",
    "    total_artigos = sum(count_anos.values)\n",
    "    fig.add_annotation(\n",
    "        x=len(count_anos.index)/2,\n",
    "        y=max(count_anos.values) + (0.15 * max(count_anos.values)),  # Ajustar esta proporção conforme necessário\n",
    "        text=f\"Total de Participação em Artigos, após entrada na Fiocruz Ceará: {total_artigos}\",\n",
    "        showarrow=False,\n",
    "        font_size=18,\n",
    "        font_color=\"blue\"\n",
    "    )\n",
    "\n",
    "    # Ajustar a altura e a largura\n",
    "    fig.update_layout(\n",
    "        width=1380,   # largura em pixels\n",
    "        height=600   # altura em pixels\n",
    "    )\n",
    "\n",
    "    # Mostrar o gráfico\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "def plotar_barras_agrupadas(df_artigosperiodo):\n",
    "    import pandas as pd\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # Contar os artigos por ano e por CURRICULO\n",
    "    grouped_data = df_artigosperiodo.groupby(['ANO_PUB', 'NOME']).size().reset_index(name='count')\n",
    "\n",
    "    # Usar paleta de cores personalizada \"VIVID\"\n",
    "    colors_vivid = ['#FF595E', '#FFCA3A', '#8AC926', '#1982FC', '#6A0572'] # Adicione mais cores se necessário\n",
    "\n",
    "    # Criar o gráfico de barras com plotly express\n",
    "    fig = px.bar(grouped_data, \n",
    "                 x='ANO_PUB',\n",
    "                 y='count',\n",
    "                 color='CURRICULO',\n",
    "                 color_discrete_sequence=colors_vivid,\n",
    "                 labels={'ANO_PUB':'Ano', 'count':'Quantidade'},\n",
    "                 title='Quantidade de Participações em Artigos por Ano e por Currículo, após entrada na Fiocruz Ceará')\n",
    "\n",
    "    # Adicionar rótulos de dados\n",
    "    for trace, color in zip(fig.data, colors_vivid):\n",
    "        for x_val, y_val in zip(trace.x, trace.y):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[x_val],\n",
    "                    y=[y_val + (0.02 * max(grouped_data['count']))], \n",
    "                    text=[str(y_val)],\n",
    "                    mode=\"text\",\n",
    "                    showlegend=False,\n",
    "                    textfont=dict(color=color)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Remover linhas de grade\n",
    "    fig.update_xaxes(showgrid=False)\n",
    "    fig.update_yaxes(showgrid=False)\n",
    "\n",
    "    # Ajustar a altura e a largura\n",
    "    fig.update_layout(\n",
    "        width=1380,   # largura em pixels\n",
    "        height=1200   # altura em pixels\n",
    "    )\n",
    "\n",
    "    # Mostrar o gráfico\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def plotar_barras_estaqueadas(df_artigosperiodo):\n",
    "    \n",
    "    df_artigosperiodo['INICIAIS'] = df_artigosperiodo['NOME'].apply(get_initials)\n",
    "    grouped_data = df_artigosperiodo.groupby(['ANO_PUB', 'INICIAIS']).size().reset_index(name='count')\n",
    "\n",
    "    # Usar a paleta \"Plotly\"\n",
    "    colors = px.colors.qualitative.Vivid\n",
    "\n",
    "    fig = px.bar(grouped_data, \n",
    "                 x='ANO_PUB',\n",
    "                 y='count',\n",
    "                #  color='CURRICULO',\n",
    "                 color='INICIAIS',\n",
    "                 barmode='group',\n",
    "                 color_discrete_sequence=colors,\n",
    "                #  labels={'ANO_PUB':'Ano', 'count':'Quantidade'},\n",
    "                 labels={'ANO_PUB':'Ano de Publicação', 'count':'Quantidade de artigos', 'INICIAIS':'Currículo'},\n",
    "                 title='Quantidade de Participação em Artigos por Ano e por Currículo, após entrada na Fiocruz Ceará')\n",
    "\n",
    "    # Adicionar rótulos de dados\n",
    "#     for trace, color in zip(fig.data, colors):\n",
    "#         for x_val, y_val in zip(trace.x, trace.y):\n",
    "#             fig.add_trace(\n",
    "#                 go.Scatter(\n",
    "#                     x=[x_val + 0.01],\n",
    "#                     y=[y_val + (0.02 * max(grouped_data['count']))], \n",
    "#                     text=[str(y_val)],\n",
    "#                     mode=\"text\",\n",
    "#                     showlegend=False,\n",
    "#                     textfont=dict(color=color)\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "    # Posicionar a legenda abaixo do gráfico\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=-0.3,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Ajustar a altura e a largura\n",
    "    fig.update_layout(\n",
    "        width=1600,   # largura em pixels\n",
    "        height=1200   # altura em pixels\n",
    "    )\n",
    "    \n",
    "    # Remover linhas de grade\n",
    "    fig.update_xaxes(showgrid=False)\n",
    "    fig.update_yaxes(showgrid=False)\n",
    "\n",
    "    # Mostrar o gráfico\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "def comparativo_curriculos(df_artigosperiodo):\n",
    "\n",
    "    df_artigosperiodo['CURRICULO_INITIALS'] = df_artigosperiodo['NOME'].apply(get_initials)\n",
    "    grouped_data = df_artigosperiodo.groupby(['ANO_PUB', 'CURRICULO_INITIALS']).size().reset_index(name='count')\n",
    "    years = sorted(grouped_data['ANO_PUB'].unique())\n",
    "\n",
    "    # Calcular a soma total para cada currículo\n",
    "    total_counts = grouped_data.groupby('CURRICULO_INITIALS')['count'].sum()\n",
    "\n",
    "    # Ordenar as iniciais dos currículos com base na soma total\n",
    "    sorted_initials = total_counts.sort_values(ascending=False).index.tolist()\n",
    "\n",
    "    # Obter a paleta \"Greens\" e normalize-a para ter uma cor para cada ano\n",
    "    palette = px.colors.sequential.Greens\n",
    "    colors = reversed([palette[i * (len(palette) - 1) // (len(years) - 1)] for i in range(len(years))])\n",
    "    colors = list(colors)  # Converta o resultado para uma lista novamente\n",
    "\n",
    "    # Criar o gráfico com as iniciais ordenadas\n",
    "    traces = []\n",
    "    for idx, year in enumerate(reversed(years)):\n",
    "        year_data = grouped_data[grouped_data['ANO_PUB'] == year]\n",
    "\n",
    "        # Preencher valores ausentes com zero\n",
    "        year_data = year_data.set_index('CURRICULO_INITIALS').reindex(sorted_initials, fill_value=0).reset_index()\n",
    "\n",
    "        # Remover entradas com valores zerados\n",
    "        # year_data = year_data[year_data['count'] > 0]\n",
    "\n",
    "        traces.append(go.Bar(\n",
    "            y=year_data['CURRICULO_INITIALS'],\n",
    "            x=year_data['count'],\n",
    "            name=str(year),\n",
    "            orientation='h',\n",
    "            marker_color=colors[idx]  # Aplique a cor aqui\n",
    "        ))\n",
    "\n",
    "    # Adicionar as traces em ordem à figura\n",
    "    fig = go.Figure(data=traces)\n",
    "\n",
    "    # Configurar o layout para ser empilhado\n",
    "    fig.update_layout(\n",
    "        barmode='stack',\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5\n",
    "        ),\n",
    "        title='Quantidade de Participações em Artigos por Currículo e Ano, após entrada na Fiocruz Ceará'\n",
    "    )\n",
    "\n",
    "    # Criar um DataFrame para a soma total por currículo\n",
    "    total_per_curriculo = grouped_data.groupby('CURRICULO_INITIALS')['count'].sum().reset_index()\n",
    "    total_per_curriculo = total_per_curriculo.set_index('CURRICULO_INITIALS').reindex(sorted_initials, fill_value=0).reset_index()\n",
    "\n",
    "    # Calcular a soma total de todos os artigos\n",
    "    total_articles = grouped_data['count'].sum()\n",
    "\n",
    "    # Adicionar a anotação no centro superior da área do gráfico com a soma total de todos os artigos\n",
    "    fig.add_annotation(\n",
    "        x=0.5,  # posição horizontal centrada\n",
    "        y=0.99,  # posição vertical logo acima do topo do gráfico\n",
    "        xref=\"paper\",  # refere-se à posição proporcional do gráfico (0 à esquerda, 1 à direita)\n",
    "        yref=\"paper\",  # refere-se à posição proporcional do gráfico (0 na parte inferior, 1 na parte superior)\n",
    "        text=f\"Total de Participação em Artigos, após entrada na Fiocruz Ceará: {total_articles}\",\n",
    "        showarrow=False,\n",
    "        font=dict(color='blue', size=20),\n",
    "        align=\"center\",\n",
    "        valign=\"top\"\n",
    "    )\n",
    "\n",
    "    # Ajustar a altura e a largura\n",
    "    fig.update_layout(\n",
    "        width=1380,   # largura em pixels\n",
    "        height=1200   # altura em pixels\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Levenshtein --trusted-host pypi.org --trusted-host files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def evolucao_anual(df_artigosperiodo, df_pessoal):\n",
    "    # Removendo duplicidades\n",
    "    # df_artigosperiodo = df_artigosperiodo.drop_duplicates(subset='TITULO')\n",
    "\n",
    "    # Para todos os anos dos dados\n",
    "    min_year = df_artigosperiodo['ANO_PUB'].min()\n",
    "    max_year = df_artigosperiodo['ANO_PUB'].max()\n",
    "    all_years = list(range(min_year, max_year + 1))\n",
    "\n",
    "    # Quantidade total de artigos por ano\n",
    "    artigos_por_ano = df_artigosperiodo.groupby('ANO_PUB').size().reindex(all_years, fill_value=0).reset_index(name='count')\n",
    "\n",
    "    # Quantidade de pesquisadores únicos que entraram a cada ano\n",
    "    pesquisadores_por_ano = df_pessoal.groupby('ANO_INGRESSO_FIOCE')['NOME'].nunique().reindex(all_years, fill_value=0).reset_index(name='unique_researchers')\n",
    "\n",
    "    # Soma cumulativa de pesquisadores ao longo dos anos\n",
    "    pesquisadores_por_ano['cumulative_researchers'] = pesquisadores_por_ano['unique_researchers'].cumsum()\n",
    "\n",
    "    # Média de artigos por pesquisador\n",
    "    pesquisadores_por_ano['avg_articles_per_researcher'] = artigos_por_ano['count'] / pesquisadores_por_ano['cumulative_researchers']\n",
    "    pesquisadores_por_ano['avg_articles_per_researcher'].replace(np.inf, 0, inplace=True)\n",
    "\n",
    "    # Calcular a proporção entre os dois eixos y\n",
    "    max_y1 = artigos_por_ano['count'].max()+10\n",
    "    max_y2 = pesquisadores_por_ano['cumulative_researchers'].max()\n",
    "    ratio = max_y1 / max_y2\n",
    "\n",
    "    # Defina um buffer de 10%\n",
    "    buffer = 0.1\n",
    "    \n",
    "    # Criando a figura com as devidas traces\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Adicionando a trace de barras para a quantidade de artigos\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=artigos_por_ano['ANO_PUB'],\n",
    "        y=artigos_por_ano['count'],\n",
    "        name='Total de Artigos',\n",
    "        text=artigos_por_ano['count'],\n",
    "        textposition='outside'\n",
    "    ))\n",
    "\n",
    "    # Adicionando a trace de linha para a soma cumulativa de pesquisadores\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pesquisadores_por_ano['ANO_INGRESSO_FIOCE'],\n",
    "        y=pesquisadores_por_ano['cumulative_researchers'],\n",
    "        yaxis='y2',\n",
    "        name='Soma Cumulativa de Pesquisadores',\n",
    "        mode='lines+markers+text',\n",
    "        text=pesquisadores_por_ano['cumulative_researchers'],\n",
    "        textposition='top center'\n",
    "    ))\n",
    "\n",
    "    # Adicionando a trace de linha tracejada para a média de artigos por pesquisador\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pesquisadores_por_ano['ANO_INGRESSO_FIOCE'],\n",
    "        y=pesquisadores_por_ano['avg_articles_per_researcher'] * ratio,\n",
    "        yaxis='y2',\n",
    "        name='Média de Artigos por Pesquisador',\n",
    "        mode='lines+text',\n",
    "        line=dict(dash='dash'),\n",
    "        text=pesquisadores_por_ano['avg_articles_per_researcher'].round(2),\n",
    "        textposition='top center'\n",
    "    ))\n",
    "\n",
    "    # Atualizando o layout do gráfico\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(\n",
    "            title='Total de Artigos',\n",
    "            range=[0, max_y1 * (1 + buffer)]\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='Soma Cumulativa de Pesquisadores e Média de Artigos por Pesquisador',\n",
    "            overlaying='y',\n",
    "            side='right',\n",
    "            range=[0, max_y2 * (1 + buffer)],\n",
    "            tickvals=list(range(0, int(max_y2 * (1 + buffer)), int(max_y2/10))),\n",
    "            ticktext=list(range(0, int(max_y2 * (1 + buffer)), int(max_y2/10)))\n",
    "        ),\n",
    "        xaxis=dict(tickvals=all_years),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            x=0.2,\n",
    "            y=0.99\n",
    "        ),\n",
    "        title='Quantidade de Participações em Artigos, Soma Cumulativa de Pesquisadores e Média de Artigos por Pesquisador por Ano',\n",
    "    )\n",
    "\n",
    "    # Remover linhas de grade\n",
    "    fig.update_xaxes(showgrid=False)\n",
    "    fig.update_yaxes(showgrid=False)\n",
    "    \n",
    "    # Ajustar a altura e a largura\n",
    "    fig.update_layout(\n",
    "        width=1380,   # largura em pixels\n",
    "        height=800   # altura em pixels\n",
    "    )\n",
    "        \n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def evolucao_sem_duplicatas(df_artigosperiodo, df_pessoal, sim_limite=0.95):\n",
    "    import Levenshtein\n",
    "\n",
    "    # Função para verificar similaridade entre strings\n",
    "    def is_similar(str1, str2, threshold):\n",
    "        similarity = (len(str1) - Levenshtein.distance(str1, str2)) / float(len(str1))\n",
    "        return similarity >= threshold\n",
    "\n",
    "    # Removendo duplicidades\n",
    "    titles = df_artigosperiodo['ARTIGO'].tolist()\n",
    "    unique_titles = []\n",
    "    for title in titles:\n",
    "        if not any(is_similar(title, utitle, sim_limite) for utitle in unique_titles):\n",
    "            unique_titles.append(title)\n",
    "    df_artigosperiodo = df_artigosperiodo[df_artigosperiodo['ARTIGO'].isin(unique_titles)]\n",
    "\n",
    "    # Remover duplicatas apenas com base no título exato\n",
    "    df_artigosperiodo = df_artigosperiodo.drop_duplicates(subset='ARTIGO')\n",
    "\n",
    "    # Para todos os anos dos dados\n",
    "    min_year  = df_artigosperiodo['ANO_PUB'].min()\n",
    "    max_year  = df_artigosperiodo['ANO_PUB'].max()\n",
    "    all_years = list(range(min_year, max_year + 1))\n",
    "\n",
    "    # Quantidade total de artigos por ano\n",
    "    artigos_por_ano = df_artigosperiodo.groupby('ANO_PUB').size().reindex(all_years, fill_value=0).reset_index(name='count')\n",
    "\n",
    "    # Quantidade de pesquisadores únicos que entraram a cada ano\n",
    "    pesquisadores_por_ano = df_pessoal.groupby('ANO_INGRESSO_FIOCE')['NOME'].nunique().reindex(all_years, fill_value=0).reset_index(name='unique_researchers')\n",
    "\n",
    "    # Soma cumulativa de pesquisadores ao longo dos anos\n",
    "    pesquisadores_por_ano['cumulative_researchers'] = pesquisadores_por_ano['unique_researchers'].cumsum()\n",
    "\n",
    "    # Média de artigos por pesquisador\n",
    "    pesquisadores_por_ano['avg_articles_per_researcher'] = artigos_por_ano['count'] / pesquisadores_por_ano['cumulative_researchers']\n",
    "    pesquisadores_por_ano['avg_articles_per_researcher'].replace(np.inf, 0, inplace=True)\n",
    "\n",
    "    # Calcular a proporção entre os dois eixos y\n",
    "    max_y1 = artigos_por_ano['count'].max()+10\n",
    "    max_y2 = pesquisadores_por_ano['cumulative_researchers'].max()\n",
    "    ratio  = max_y1 / max_y2\n",
    "\n",
    "    # Defina um buffer de 10%\n",
    "    buffer = 0.1\n",
    "    \n",
    "    # Criando a figura com as devidas traces\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Adicionando a trace de barras para a quantidade de artigos\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=artigos_por_ano['ANO_PUB'],\n",
    "        y=artigos_por_ano['count'],\n",
    "        name='Total de Artigos',\n",
    "        text=artigos_por_ano['count'],\n",
    "        textposition='outside'\n",
    "    ))\n",
    "\n",
    "    # Adicionando a trace de linha para a soma cumulativa de pesquisadores\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pesquisadores_por_ano['ANO_INGRESSO_FIOCE'],\n",
    "        y=pesquisadores_por_ano['cumulative_researchers'],\n",
    "        yaxis='y2',\n",
    "        name='Soma Cumulativa de Pesquisadores',\n",
    "        mode='lines+markers+text',\n",
    "        text=pesquisadores_por_ano['cumulative_researchers'],\n",
    "        textposition='top center'\n",
    "    ))\n",
    "\n",
    "    # Adicionando a trace de linha tracejada para a média de artigos por pesquisador\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pesquisadores_por_ano['ANO_INGRESSO_FIOCE'],\n",
    "        y=pesquisadores_por_ano['avg_articles_per_researcher'] * ratio,\n",
    "        yaxis='y2',\n",
    "        name='Média de Artigos por Pesquisador',\n",
    "        mode='lines+text',\n",
    "        line=dict(dash='dash'),\n",
    "        text=pesquisadores_por_ano['avg_articles_per_researcher'].round(2),\n",
    "        textposition='top center'\n",
    "    ))\n",
    "\n",
    "    # Atualizando o layout do gráfico\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(\n",
    "            title='Total de Artigos',\n",
    "            range=[0, max_y1 * (1 + buffer)]\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='Soma Cumulativa de Pesquisadores e Média de Artigos por Pesquisador',\n",
    "            overlaying='y',\n",
    "            side='right',\n",
    "            range=[0, max_y2 * (1 + buffer)],\n",
    "            tickvals=list(range(0, int(max_y2 * (1 + buffer)), int(max_y2/10))),\n",
    "            ticktext=list(range(0, int(max_y2 * (1 + buffer)), int(max_y2/10)))\n",
    "        ),\n",
    "        xaxis=dict(tickvals=all_years),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            x=0.2,\n",
    "            y=0.99\n",
    "        ),\n",
    "        title='Quantidade de Artigos (sem duplicatas), Soma Cumulativa de Pesquisadores e Média de Artigos por Pesquisador por Ano',\n",
    "    )\n",
    "\n",
    "    # Identificar o último ano\n",
    "    last_year = max(all_years)\n",
    "    \n",
    "    # Adicionar a barra transparente para o último ano\n",
    "    mask_last_year = artigos_por_ano['ANO_PUB'] == last_year\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=[last_year],\n",
    "        y=[artigos_por_ano[mask_last_year]['count'].iloc[0]],\n",
    "        name='Total de Artigos no Ano Atual',\n",
    "        text=str(artigos_por_ano[mask_last_year]['count'].iloc[0]),  # Convertendo para string\n",
    "        textposition='outside',\n",
    "        marker=dict(color='rgba(0,0,0,0)',  # Transparente\n",
    "                    line=dict(color='#1f77b4', width=2))  # Borda com a cor padrão e espessura de 2\n",
    "    ))\n",
    "    \n",
    "    # Remover linhas de grade\n",
    "    fig.update_xaxes(showgrid=False)\n",
    "    fig.update_yaxes(showgrid=False)\n",
    "    \n",
    "    # Ajustar a altura e a largura\n",
    "    fig.update_layout(\n",
    "        width=1380,   # largura em pixels\n",
    "        height=800   # altura em pixels\n",
    "    )\n",
    "        \n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def boxplot_media_artigos(df_artigosperiodo, df_pessoal):\n",
    "    # Removendo duplicidades\n",
    "    df_artigosperiodo = df_artigosperiodo.drop_duplicates(subset='ARTIGO')\n",
    "    df_artigosperiodo['CURRICULO_INITIALS'] = df_artigosperiodo['NOME'].apply(get_initials)\n",
    "\n",
    "    # Calculando o total de artigos por pesquisador\n",
    "    artigos_por_pesquisador = df_artigosperiodo.groupby('CURRICULO_INITIALS').size()\n",
    "\n",
    "    # Calculando a média de artigos por pesquisador\n",
    "    anos_ativos = df_artigosperiodo.groupby('CURRICULO_INITIALS')['ANO_PUB'].nunique()\n",
    "    media_artigos_por_pesquisador = artigos_por_pesquisador / anos_ativos\n",
    "\n",
    "    # Retirar possíveis infinitos\n",
    "    media_artigos_por_pesquisador.replace(np.inf, 0, inplace=True)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Box plot\n",
    "    fig.add_trace(go.Box(\n",
    "        y=media_artigos_por_pesquisador,\n",
    "        boxpoints='all',\n",
    "        jitter=0.3,\n",
    "        pointpos=0,\n",
    "        name='Média de Artigos por Pesquisador'\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Distribuição da Média de Artigos por Pesquisador',\n",
    "        yaxis_title='Média de Artigos por Pesquisador'\n",
    "    )\n",
    "\n",
    "    # Ajustar a altura e a largura\n",
    "    fig.update_layout(\n",
    "        width=1380,   # largura em pixels\n",
    "        height=800   # altura em pixels\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def evolucao_artigos(df_artigosperiodo, df_pessoal, threshold=0.8):\n",
    "    # Para todos os anos dos dados\n",
    "    min_year = df_artigosperiodo['ANO_PUB'].min()\n",
    "    max_year = df_artigosperiodo['ANO_PUB'].max()\n",
    "    all_years = list(range(min_year, max_year + 1))\n",
    "\n",
    "    # 1. Usando TF-IDF para calcular similaridade entre os títulos\n",
    "    vectorizer = TfidfVectorizer().fit_transform(df_artigosperiodo['ARTIGO'])\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_matrix = cosine_similarity(vectors)\n",
    "\n",
    "    # 2. Filtrando títulos com similaridade acima do threshold e removendo duplicatas\n",
    "    indices_to_drop = []\n",
    "    for i in range(cosine_matrix.shape[0]):\n",
    "        for j in range(i + 1, cosine_matrix.shape[1]):\n",
    "            if cosine_matrix[i][j] > threshold:\n",
    "                indices_to_drop.append(j)\n",
    "\n",
    "    indices_to_drop = list(set(indices_to_drop))\n",
    "    df_artigosperiodo = df_artigosperiodo.drop(df_artigosperiodo.index[indices_to_drop])\n",
    "\n",
    "    # 3. Plotar o gráfico de evolução\n",
    "\n",
    "    # Agrupando por ano\n",
    "    artigos_por_ano = df_artigosperiodo.groupby('ANO_PUB').size().reset_index(name='count')\n",
    "\n",
    "    # Preenchimento padrão para todos os anos\n",
    "    fill_colors = ['#1f77b4'] * artigos_por_ano.shape[0]\n",
    "\n",
    "    # Para o último ano, deixar sem preenchimento (somente borda)\n",
    "    last_year = artigos_por_ano['ANO_PUB'].iloc[-1]\n",
    "    fill_colors[-1] = 'rgba(0,0,0,0)'\n",
    "\n",
    "    # Plotagem\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Adicionar barras para cada ano\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=artigos_por_ano['ANO_PUB'],\n",
    "        y=artigos_por_ano['count'],\n",
    "        name='Total de Artigos por Ano',\n",
    "        marker=dict(color=fill_colors,\n",
    "                    line=dict(color='#1f77b4', width=2))\n",
    "    ))\n",
    "\n",
    "    # Adicionar linha de média\n",
    "    mean_articles = artigos_por_ano['count'].mean()\n",
    "    years = artigos_por_ano['ANO_PUB'].values\n",
    "\n",
    "    # Excluindo o último ano da linha de média\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=years[0],\n",
    "        y0=mean_articles,\n",
    "        x1=years[-2],\n",
    "        y1=mean_articles,\n",
    "        line=dict(color=\"Red\", width=2, dash=\"dashdot\")\n",
    "    )\n",
    "\n",
    "    # Configurações adicionais do gráfico\n",
    "    fig.update_layout(\n",
    "        title=\"Evolução da quantidade de participação em artigos por ano concluídos, média e artigos do ano em curso\",\n",
    "        xaxis_title=\"Ano\",\n",
    "        yaxis_title=\"Número de Artigos\",\n",
    "        legend_title=\"Legenda\",\n",
    "        xaxis=dict(tickvals=all_years),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            x=0.2,\n",
    "            y=0.99\n",
    "    ),\n",
    "\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Ingerir dados de entrada</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização dos arquivos de entrada de dados\n",
    "\n",
    "(listas de pessoal e listas da VPEIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categorias_capes.txt',\n",
       " 'classificações_publicadas_todas_as_areas_avaliacao1672761192111.csv',\n",
       " 'df_artigos.csv',\n",
       " 'df_secoes.csv',\n",
       " 'Impact-Factor-2023.csv',\n",
       " 'lista_lattes-fioce.csv',\n",
       " 'lista_orientadores.csv',\n",
       " 'lista_revistas.csv',\n",
       " 'lista_revistas_nan',\n",
       " 'lista_servidores-fioce.csv',\n",
       " 'lista_todos_servidores-fioce.csv']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(pathcsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24102022_Tabela_1844948_TabelaAreasConhecimento_atualizada_2022.doc',\n",
       " 'capes_areas-de-conhecimento.pdf',\n",
       " 'cnpq-dgp_rel_consultaegresso_por_egresso_instituicao.xls',\n",
       " 'cnpq-dgp_rel_consulta_parametrizada_linha_pesquisa.xls',\n",
       " 'cnpq-dgp_rel_indicadores_gerais_areas.xls',\n",
       " 'cnpq-dgp_rel_indicadores_gerais_grandes_areas.xls',\n",
       " 'cnpq-dgp_rel_indicadores_gerais_por_instituicao.xls',\n",
       " 'cnpq_tabela-areas-conhecimento.pdf',\n",
       " 'fioce_colaboradores-2023.xls',\n",
       " 'fioce_graficos.pptx',\n",
       " 'fioce_producao_2008.01-2023.06.xlsx',\n",
       " 'fiocruz_unidade-desconhecida.xlsx',\n",
       " 'Impact-Factor-2023.pdf',\n",
       " 'Impact-Factor-2023.txt',\n",
       " 'passo-a-passo-area-cientifica.docx',\n",
       " 'passo-a-passo-area-cientifica.pdf',\n",
       " 'passo-a-passo-area-cientifica.txt']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(pathzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artigos_desde_ano_ingresso_fiocruz_ceara.csv',\n",
       " 'artigos_desde_ano_ingresso_fiocruz_ceara.xlsx',\n",
       " 'artigos_fiocruz_ceara.csv',\n",
       " 'artigos_fiocruz_ceara.xlsx',\n",
       " 'cnpq_areas-pesquisa.csv',\n",
       " 'df_artigos.csv',\n",
       " 'df_artigos_servidores_ingresso_fioce.csv',\n",
       " 'df_artigos_servidores_ingresso_fioce.xlsx',\n",
       " 'df_secoes.csv',\n",
       " 'df_secoes_doutores_mestres.csv',\n",
       " 'df_secoes_publicadores.csv',\n",
       " 'df_secoes_servidores.csv',\n",
       " 'df_servidores_ingresso_fioce.csv',\n",
       " 'df_servidores_ingresso_fioce.xlsx']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(pathout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingestão das planilhas de produção da VPEIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl --trusted-host files.pythonhosted.org\n",
    "# !pip install xlrd --trusted-host files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publicações  FioCE 2008_2023:   646\n",
      "Publicações variadas Fiocruz:  6524\n"
     ]
    }
   ],
   "source": [
    "fioce_2008_2013 = pd.read_excel(io=pathzip+'fioce_producao_2008.01-2023.06.xlsx', skiprows=1, header=0)\n",
    "print(f'Publicações  FioCE 2008_2023: {len(fioce_2008_2013):5}')\n",
    "# fioce_2008_2013.head(3)\n",
    "\n",
    "fiocuz_producao = pd.read_excel(io=pathzip+'fiocruz_unidade-desconhecida.xlsx', skiprows=1, header=0)\n",
    "print(f'Publicações variadas Fiocruz: {len(fiocuz_producao):5}')\n",
    "# fiocuz_producao.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fiocruz_id', 'Título', 'Ano', 'Resumo', 'Palavras-chaves do autor',\n",
       "       'Veículo de publicação', 'DOI ', 'Tipologia documental', 'Instiuições',\n",
       "       'Unidades/ Siglas', 'Pais da Instiuição ', 'Autores ',\n",
       "       'Áreas do conhecimento CNPq (lattes do servidor)',\n",
       "       'Áreas temáticas identificadas pelo Observatório',\n",
       "       'Área do conhecimento CNPq Nível 1 ',\n",
       "       'Área do conhecimento CNPq Nível 2',\n",
       "       'Área do conhecimento CNPq Nível 3 ',\n",
       "       'Área do conhecimento CNPq Nível 4 ',\n",
       "       'Área do conhecimento CNPq Nível 1 )',\n",
       "       'Área do conhecimento CNPq Nível 2.1',\n",
       "       'Área do conhecimento CNPq Nível 3',\n",
       "       'Área do conhecimento CNPq Nível 4 .1',\n",
       "       'Nível 1 ; Nível 2 ; Nível 3 ; Nível 4               Utilizar ; (ponto e víruga como separador) ',\n",
       "       'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fioce_2008_2013.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['{\"Roberto Wagner Júnior Freire de Freitas\"}',\n",
       "       '{\"Ivana Cristina de Holanda Cunha Barreto\",\"Luiz Odorico Monteiro de Andrade\"}',\n",
       "       '{\"Margareth Borges Coutinho Gallo\"}',\n",
       "       '{\"Luiz Odorico Monteiro de Andrade\"}',\n",
       "       '{\"Carlos R. K. Paier\",\"Carolane M. Almeida\",\"Claudia C. Gatto\",\"Claudia Pessoa\",\"PatrÃ\\xadcia M. Miguel\",\"Pedro H. O. Santiago\"}',\n",
       "       '{\"G. P. Furtado\",\"L. F. Ribeiro\",\"M. R. Lourenzoni\",\"R. J. Ward\"}',\n",
       "       '{\"Ivana Cristina de Holanda Cunha Barreto\"}',\n",
       "       '{\"Barreto, Ivana Cristina de Holanda Cunha\",\"Evangelista, Aline Luiza de Paulo\"}',\n",
       "       '{\"AmÃ¡lia dos Santos Ferreira\",\"Andreimar Martins Soares\",\"Fernando Berton Zanchi\",\"FlÃ¡via Raquel Fernandes do Nascimento\",\"JoÃ£o Rafael Valentim Silva\",\"Johnny Ramos do Nascimento\",\"Leandro Soares Moreira Dill\",\"Leonardo de Azevedo Calderon\",\"Marcos Roberto Lourenzoni\",\"Neuza Biguinati de Barros\",\"Roberto Nicolete\",\"Sharon Rose AragÃ£o Macedo\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Edgar De Barros Filho MarÃ§al\",\"Isabelle Montenegro Alves Marinho\",\"Juliana Ximenes Damasceno\",\"MaÃ\\xadra Barbosa Coutinho\",\"Pedro CÃ©sar Mesquita Cals De Oliveira\"}',\n",
       "       '{\"Alice Sampaio Barreto da Rocha\",\"Ana Carolina da Fonseca Mendonca\",\"Anderson Brandao Leite\",\"Andre Felipe Leal Bernardes\",\"Andrea Cony Cavalcanti\",\"Anna Carolina Dias Paixao\",\"Camila Indiani de Oliveira\",\"Claudio Sachhi\",\"Cliomar Alves do Santos\",\"Cristiano Fernandes da Costa\",\"Dalane Loudal Florentino Teixeira\",\"Edson Delatorre\",\"Fabio Miyajima\",\"Felipe G. Naveca\",\"Fernando Couto Motta\",\"Gabriel L. Wallau\",\"Gonzalo Bello\",\"Irina Riediger\",\"Joao Felipe Bezerra\",\"Lidio Goncalves lima Neto\",\"Luciana Appolinario\",\"Maria do Carmo Debur\",\"Marilda Mendonca Siqueira\",\"Paola Cristina Resende\",\"Pedro Santos-Muccillo\",\"Renata Serrano Lopes\",\"Ricardo Khoury\",\"Rodrigo Ribeiro-Rodrigues\",\"Sandra Bianchini Fernandes\",\"Tatiana Schaffer Gregianini\",\"Tiago Graf\",\"Tirza Mattos\"}',\n",
       "       '{\"Andrea Queiroz Maranhao\",\"Angela Donato Maia Malaquias\",\"Carla Freire Celedonio Fernandes\",\"Cleberson de Freitas Fernandes\",\"Eridan Orlando Pereira Tramontina Florean\",\"Livia Erika Carlos Marques\",\"Maria Izabel Florindo Guedes\",\"Rodrigo G. Stabeli\",\"Soraya S. Pereira\"}',\n",
       "       '{\"Ana Lays Braga\",\"Claudener Souza Teixeira\",\"Gabriel C. A. da Hora\",\"Jaime Ribeiro Filho\",\"Maria Flaviana Bezerra Morais-Braga\",\"Victor Juno Alencar Fonseca\"}',\n",
       "       '{\"Carneiro, Fernando Ferreira\",\"Pessoa, Vanira Matos\"}',\n",
       "       '{\"Jaime Ribeiro Filho\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Lyana Leal Rocha\",\"Maria Vieira de lima Saintrain\"}',\n",
       "       '{\"de lima Gonçalves, Fabíola\",\"de Paula Sousa, Luiza\",\"Lawrence, Herenia\",\"Pimentel Gomes Fernandes Vieira, Anya\",\"Vieira de lima Saintrain, Maria\"}',\n",
       "       '{\"Campos, Adriana Guerra\",\"Gurgel, Aline do Monte\"}',\n",
       "       '{\"Cicera D. Morais-Tintino\",\"Fabia F. Campina\",\"Henrique D. M. Coutinho\",\"Jacqueline C. Andrade\",\"Jaime Ribeiro Filho\",\"Jose P. Siqueira-Junior\",\"Lucindo J. Quintans-Junior\",\"Maria do S. Costa\",\"Maria Flaviana B. M. Braga\",\"Paulo W. Limaverde\",\"Raimundo L. Pereira\",\"Saulo R. Tintino\",\"Tereza C. Leal-Balbino\",\"Valdir Q. Balbino\"}',\n",
       "       '{\"Alison de Sousa RebouÃ§as\",\"Carlos Alessandro Fuzo\",\"Marcos Roberto Lourenzoni\",\"NatÃ¡lia Fernandes Frota\"}',\n",
       "       '{\"Adriana Costa Bacelo\"}',\n",
       "       '{\"Anamaria Testa Tambelini\",\"Andre Campos Burigo\",\"Cheila Nataly Galindo Bedor\",\"Fernando Ferreira Carneiro\",\"karen Friedrich\",\"Lia Giraldo da Silva Augusto\"}',\n",
       "       '{\"Ivana Barreto\",\"Mauro Oliveira\",\"Milton Mendes\",\"Odorico Andrade\",\"Oton Braga\",\"Renato Freitas\"}',\n",
       "       '{\"Adelaide M. S. Antunes\",\"Jorge Lima MagalhÃ£es\",\"Zulmira Hartz\"}',\n",
       "       '{\"Carla Freire Celedonio Fernandes\",\"Juliana Pavan Zuliani\",\"Karla Patricia Luna\",\"Neriane Monteiro Nery\"}',\n",
       "       '{\"Antonio Marcos Aires Barbosa\"}',\n",
       "       '{\"Machado, Maria de Fátima Antero Sousa\",\"Moreira, Maria Rosilene Cândido\",\"Oliveira, Anderson Milfont Feitosa de\",\"Xavier, Samyra Paula Lustoza\"}',\n",
       "       '{\"Araújo, Márcio Flávio Moura de\",\"Braga, Hévila Ferreira Gomes Medeiros\",\"Melo, Emanuella Silva Joventino\",\"Oliveira,  Isabelly Gomes de\",\"Santos, Lydia Vieira Freitas dos\",\"Silva, Antônio Uelton de Araújo da\"}',\n",
       "       '{\"Anna Carolina Machado Marinho\",\"Claudia Maria da Conceição\"}',\n",
       "       '{\"Márcio Flávio Moura de Araújo\",\"Roberto Wagner Júnior Freire de Freitas\"}',\n",
       "       '{\"donat Alexander de Chapeaurouge\"}',\n",
       "       '{\"Ana Maria Parente Garcia Alencar\",\"Carla Regina de Souza Teixeira\",\"Danilo Ferreira de Souza\",\"Gerdane Celene Nunes Carvalho\",\"Jessica de Menezes Nogueira\",\"Jose Claudio Garcia Lira Neto\",\"Kenya Waleria de Siqueira Coelho Lisboa\",\"Marcia Aparecida Ciol\",\"Marcio Flavio Moura de Araujo\",\"Marta Maria Coelho Damasceno\",\"Regina Lucia Lino Marques\",\"Roberto Wagner Junior Freire de Freitas\"}',\n",
       "       '{\"Ana Carolina Justino de Araújo\",\"Cicera Datiane de Morais Oliveira Tintino\",\"Henrique Douglas Melo Coutinho\",\"Jaime Ribeiro Filho\",\"Pedro Ivo Palacio Leite\",\"Priscilla Ramos Freitas\",\"Raíra Justino Oliveira Costa\",\"Ray Silva de Almeida\",\"Saulo Relison Tintino\",\"Vitória Assunção Ferreira\"}',\n",
       "       '{\"Antonio Wlisses da Silva\",\"Carla de Fatima Alves Nonato\",\"Cicera Janaine Camilo\",\"Emerson Vinicius Silva de Melo\",\"Grazyna Kowalska\",\"Helcio Silva dos Santos\",\"Henrique Douglas Melo Coutinho\",\"Irwin Rose Alencar de Menezes\",\"Jaime Ribeiro Filho\",\"Jane Eire Alencar de Meneses\",\"Joanda Paolla Raimundo E. Silva\",\"Jose Galberto Martins da Costa\",\"Josean Fechine Tavares\",\"Maria Kueirislene Amancio Ferreira\",\"Radoslaw Kowalski\",\"Tomasz Baj\"}',\n",
       "       '{\"Ana Carolina Justino de Araujo\",\"Antonia Thassya Lucas dos Santos\",\"Cicera Datiane de Morais Oliveira-Tintino\",\"Cicero Deschamps\",\"Clara Mariana Goncalves Lima\",\"Francisco Roberto de Azevedo\",\"Gianluca Caruso\",\"Henrique Douglas Melo Coutinho\",\"Jaime Ribeiro Filho\",\"Joao Tavares Calixto-Junior\",\"Jose Bezerra de Araujo Neto\",\"Luiz Everson da Silva\",\"Maria Milene Costa da Silva\",\"Nadezhda Golubkina\",\"Priscilla Ramos Freitas\",\"Saulo Relison Tintino\",\"Wanderlei do Amaral\"}',\n",
       "       '{\"Ana Carolina Matias Dinelly Pinto\",\"Fatima de Cassia Evangelista de Oliveira\",\"Fernanda Montenegro de Carvalho Araujo\",\"Ludmilla Freire Caetano\",\"Marcela Helena Gambim Fonseca\",\"Maria Francilene Souza Silva\"}',\n",
       "       '{\"Regis Bernardo Brandim Gomes\"}',\n",
       "       '{\"João Hermínio Martins da Silva\",\"Paula Mello de Luca\",\"Paulo Renato Rivas Totino\",\"Rodrigo Nunes Rodrigues da Silva\"}',\n",
       "       '{\"Andre D. Luchessi\",\"Aruana J. M. C. R. Pinheiro\",\"Eduardo M. de Sousa\",\"Elizabeth S. Fernandes\",\"Iracelle C. Abreu\",\"Joao G. G. Araujo\",\"Lidio G. Lima-Neto\",\"Lucia C. F. Marques\",\"Raimundo A. G. de Oliveira\",\"Roberto Nicolete\",\"Selma N. Silva\",\"Vivian N. Silbiger\"}',\n",
       "       '{\"Cristian Vicson Gomes Pinheiro\",\"JoÃ£o Pedro Viana Rodrigues\",\"Maria Jania Teixeira\",\"NatÃ¡lia Vasconcelos de Souza\",\"Roberto Nicolete\",\"Ronaldo Nascimento de Oliveira\",\"Wildson Max Barbosa da Silva\",\"Yasmim Mendes Rocha\"}',\n",
       "       '{\"Amalia dos S. Ferreira\",\"Andreimar M. Soares\",\"Fernando B. Zanchi\",\"Flavia R. F. do Nascimento\",\"Joa R. Valentim-Silva\",\"Johnny R. do Nascimento\",\"Leandro S. M. Dill\",\"Leonardo de A. Calderon\",\"Marcos R. Lourenzoni\",\"Neuza B. de Barros\",\"Roberto Nicolete\",\"Rodrigo S. Silva\",\"Sharon R. A. Macedo\"}',\n",
       "       '{\"Amalia dos Santos Ferreira\",\"Ana Paula Azevedo dos Santos\",\"Andre Alvares Marques Vale\",\"Flavia Raquel Fernandes Nascimento\",\"Jefferson Mesquita Brito\",\"Lucilene Amorim Silva\",\"Mayara Cristina Pinto da Silva\",\"Paulo Vitor Soeiro Pereira\",\"Roberto Nicolete\",\"Rosane Nassar Meireles Guerra\"}',\n",
       "       '{\"Amalia dos Santos Ferreira\",\"Joao Herminio Martins da Silva\",\"Joao Rafael Valentim-Silva\",\"Larissa Deadame de Figueiredo Nicolete\",\"Neuza Biguinati de Barros\",\"Roberto Nicolete\",\"Sharon Rose Aragao Macedo\"}',\n",
       "       '{\"Amalia dos Santos Ferreira\",\"Aramys Silva Reis\",\"Bruno de Paulo Ribeiro\",\"Claudio Romero Farias Marinho\",\"Dalila Nunes Cysne\",\"Flavia Maria Mendonca do Amaral\",\"Flavia Raquel Fernandes Nascimento\",\"Roberto Nicolete\",\"Rosane Nassar Meireles Guerra\",\"Thiare Silva Fortes\"}',\n",
       "       '{\"Aleff F. Francisco\",\"Anderson M. Kayano\",\"Andreimar M. Soares\",\"Carla F. C. Fernandes\",\"Fernando B. Zanchi\",\"Juliana P. Zuliani\",\"Leandro S. M. Dill\",\"Marcela C. S. Silva\",\"Marcos B. Luiz\",\"Marcos R. M. Fontes\",\"Marilia P. Gouveia\",\"Nidiane D. R. Prado\",\"Rodrigo G. Stabeli\",\"Rosa M. O. Sousa\",\"Soraya S. Pereira\"}',\n",
       "       '{\"Alice M. C. Martins\",\"Emanuel Paula MagalhÃ£es\",\"MÃ¡rcia Machado Marinho\",\"Marlos de Medeiros Chaves\",\"Ramon R. P. P. B. de Menezes\",\"Roberto Nicolete\",\"Ronaldo Nascimento de Oliveira\",\"Tiago Lima Sampaio\",\"Valentina Nascimento e Melo de Oliveira\",\"Yasmim Mendes Rocha\"}',\n",
       "       '{\"Gabriel AcÃ¡cio. de Moura\",\"JanaÃ\\xadna de Oliveira Freitas\",\"JoÃ£o Pedro Viana. Rodrigues\",\"Juliana Ramos. de Oliveira\",\"Roberto Nicolete\",\"Vanessa Pinheiro GonÃ§alves Ferreira\",\"Yasmim Mendes. Rocha\"}',\n",
       "       '{\"Camila Maria L. Machado\",\"Claudia Pessoa\",\"Daniel Pereira Bezerra\",\"Edilberto R. Silveira\",\"Nayara C. de Aquino\",\"Paulo Michel P. Ferreira\",\"Roger Chammas\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira\",\"Maria Vieira de lima Saintrain\"}',\n",
       "       '{\"Amelia S. Ferreira\",\"Anderson M. Kayano\",\"Andreimar M. Soares\",\"Larissa D. F. Nicolete\",\"Monika P. Tagliari\",\"Neuza B. de Barros\",\"Roberto Nicolete\",\"Sharon R. Aragdo Macedo\"}',\n",
       "       '{\"Andreimar Martins Soares\",\"Roberto Nicolete\"}',\n",
       "       '{\"Antonia Maria das Gracas Lopes Cito\",\"Bruno Quirino Araujo\",\"Claudia Pessoa\",\"Daisy Jereissati Barbosa Lima\",\"Flavia Pereira da Silva Airoldi\",\"Jurandy do Nascimento Silva\",\"Nayana Bruna Nery Moncao\",\"Paulo Michel Pinheiro Ferreira\"}',\n",
       "       '{\"Amanda Cordeiro de Oliveira Carvalho\",\"Eduarda Maria Duarte Rodrigues\",\"Glaucia Margarida Bezerra Bispo\",\"Kenya Waleria de Siqueira Coelho Lisboa\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner Junior Freire Freitas\"}',\n",
       "       '{\"Camila Almeida Neves de Oliveira\",\"Eduarda Maria Duarte Rodrigues\",\"Glaucia Margarida Bezerra Bispo\",\"Marta Maria Coelho Damasceno\",\"Milena Silva Costa\",\"Roberto Wagner Junior Freire de Freitas\"}',\n",
       "       '{\"Carleara Weiss\",\"Fabricia Bezerra de Castro Alves Silveira\",\"Jose Claudio Garcia Lira Neto\",\"Marcio Flavio Moura de Araujo\"}',\n",
       "       '{\"Anangela Ravena da Silva Leal\",\"Bruno Moreira de Carvalho\",\"Clarissa Teixeira\",\"Cleanto Luiz Maia Silva\",\"Constanca Britto\",\"Daniela de Pita Pereira\",\"Jacenir Reis dos Santos Mallet\",\"Mauricio Luiz Vilela\",\"Raimundo Leoberto Torres de Sousa\",\"Regis Gomes\",\"Silvia Alcantara Vasconcelos\",\"Simone Mousinho Freire\",\"Thais de Araujo Pereira\"}',\n",
       "       '{\"Camara, Ana Maria Chagas Sette\",\"Gonçalves, Carla Beatrice Crivellaro\",\"lima Júnior, Francisco Cristovão Mota\",\"Nuto, Sharmênia de Araújo Soares\"}',\n",
       "       '{\"Fábio Miyajima\"}', '{\"Fernando Braga Stehling Dias\"}',\n",
       "       '{\"Marlos de Medeiros Chaves\"}',\n",
       "       '{\"Anna Carolina Machado Marinho\"}',\n",
       "       '{\"Alton Swennes\",\"Andrea Martinez Aguirre\",\"Fabio Miyajima\",\"Joseph A. Sorg\",\"Mary Elizabeth Tessier\",\"Nazli Yalcinkaya\",\"Paul Roberts\",\"Qinglong Wu\",\"Tor Savidge\"}',\n",
       "       '{\"Andre L. Fuly\",\"Andreimar M. Soares\",\"Angelo J. Magro\",\"Bibiana M. de Souza\",\"Carlos A. H. Fernandes\",\"Diana S. Butzke\",\"Jose C. Rosa\",\"Jose R. Giglio\",\"Lara F. Vieira\",\"Leonardo A. Calderon\",\"Marcia Gallacci\",\"Marcos R. M. Fontes\",\"Mario S. Palma\",\"Rodrigo G. Stabeli\",\"Walter L. G. Cavalcante\"}',\n",
       "       '{\"Ana C. da Silva\",\"Ayrles F. B. Silva\",\"Chayenne A. de Sa\",\"Cleverson D. T. Freitas\",\"Davi F. Farias\",\"Gilvan P. Furtado\",\"Jeanlex S. de Sousa\",\"Joao P. B. Oliveira\",\"Juliana A. C. Ribeiro\",\"Marcio Ramos\",\"Maria Z. R. Silva\",\"Mirele S. Vasconcelos\",\"Rafael A. Zambelli\",\"Sandro R. Silveira\",\"Thalles B. Grangeiro\"}',\n",
       "       '{\"Dirk Schreen\",\"Lidianne Fernandes da Silva Lobo\",\"Luciana Vladia Carvalhedo Fragoso\",\"Marcio Flavio Moura de Araujo\",\"Maria Lucia Zanetti\",\"Marta Maria Coelho Damasceno\"}',\n",
       "       '{\"Carla Freire Celedonio Fernandes\",\"Gilvan Pessoa Furtado\",\"Larissa Queiroz Pontes\",\"Marcela Helena Gambim Fonseca\",\"Marcus Rafael Lobo Bezerra\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Carlos Roberto Silveira Correa\",\"Maria Vieira de Lima Saintrain\",\"SharmÃªnia de AraÃºjo Soares Nuto\",\"Suzanne Vieira Saintrain\"}',\n",
       "       '{\"Cameron D. Norman\",\"Herenia P. Lawrence\",\"Laurie Hoffman-Goetz\",\"Paola Calvasina\"}',\n",
       "       '{\"Anya P.G.F. Vieira-Meyer\",\"George T. De M.Candeiro\",\"Helena P.G. Santos\",\"MaÃ\\xadra B. Coutinho\",\"Maria V. Saintrain\"}',\n",
       "       '{\"Carla F. C. Fernandes\",\"Gilvan P. Furtado\",\"Juliana P. Zuliani\",\"Marcos B. Luiz\",\"Rodrigo G. Stabeli\",\"Soraya dos S. Pereira\"}',\n",
       "       '{\"Andrelisse Arruda\",\"Anna Carolina Machado Marinho\",\"Carla Freire Celedonio Fernandes\",\"Eliza Lima dos Santos\",\"Nairo Brilhante-da-Silva\",\"Rodrigo Guerino Stabeli\",\"Rosa Maria de Oliveira Sousa\",\"Soraya dos Santos Pereira\"}',\n",
       "       '{\"Eduarda Maria Duarte Rodrigues\",\"Emiliana Bezerra Gomes\",\"Glaucia Margarida Bezerra Bispo\",\"Jose Claudio Garcia Lira Neto\",\"Kenya Waleria de Siqueira Coelho Lisboa\",\"Marcio Flavio Moura de Araujo\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner Junior Freire de Freitas\"}',\n",
       "       '{\"Roberto Nicolete\"}',\n",
       "       '{\"Andrea Fagundes Grava\",\"Gleiciene Felix Magalhaes\",\"Luiz Hildebrando Pereira da Silva\",\"Patricia Puccinelli Orlandi\",\"Paulo Afonso Nogueira\",\"Tatiane Silva\"}',\n",
       "       '{\"Antonio Miguel Vieira Monteiro\",\"Carlos Alberto Vieira Batista\",\"Claudia Maria Fontes de Oliveira\",\"Constancia Flavia Junqueira Ayres\",\"Fatima Souza\",\"Jose Constantino Silveira\",\"Leda N. Regis\",\"Maria Alice Varjal de Melo-Santos\",\"Mercia Cristiane Santana da Cunha\",\"Ridelane Veiga Acioli\",\"Rosangela Maria Rodrigues Barbosa\",\"Wayner Vieira Souza\"}',\n",
       "       '{\"Aline Augusti Boligon\",\"Henrique Douglas Melo Coutinho\",\"Irwin Rose Alencar de Menezes\",\"Jaime Ribeiro Filho\",\"José Henrique Alves Pereira\",\"Maria Celeste Vega\",\"Vanessa de Carvalho Nilo Bitu\",\"Vinícius de Carvalho Nilo Bitu Ferreira\"}',\n",
       "       '{\"Alessandra Gomes Marques Pacheco\",\"Ana Paula de Oliveira\",\"Claudia do O. Pessoa\",\"Erica Martins de Lavor\",\"Grasielly Rocha Souza\",\"Henrique Douglas Melo Coutinho\",\"Irwin Rose Alencar de Menezes\",\"Jackson Roberto Guedes da Silva Almeida\",\"Larissa Alves Ribeiro de Oliveira Macedo\",\"Marcilia Pinheiro da Costa\",\"Mariana Gama E. Silva\",\"Raimundo Goncalves de Oliveira Junior\"}',\n",
       "       '{\"Maximiliano Loiola Ponte de Souza\",\"Rossano Cabral Lima\"}',\n",
       "       '{\"Marcela Helena Gambim Fonseca\",\"Raphael Trevizani\",\"Stephanie Bath de Morais\",\"Tatiana de Arruda Campos Brasil de Souza\",\"Tayna da Silva Fiuza\"}',\n",
       "       '{\"Gilvan Pessoa Furtado\",\"Marcela Helena Gambim Fonseca\"}',\n",
       "       '{\"Ana Lucia Pontes\",\"Antonio Carlile Holanda Lavor\",\"Bruce Bartholow Duncan\",\"Camila Giugliani\",\"Daniela Riva Knauth\",\"Erno Harzheim\",\"Marcia Maria Tavares Machado\",\"Maria Idalice Barbosa\",\"Miria Campos Lavor\",\"Vera Joana Bornstein\"}',\n",
       "       '{\"Almeida, Magda Moura\",\"Carneiro, Fernando Ferreira\",\"Pessoa, Vanira Matos\"}',\n",
       "       '{\"Alexandra Christine Helena Frankland Sawaya\",\"Antonio Gilberto Ferreira\",\"Christiane Schineider Machado\",\"Claudia Pessoa\",\"Fatima de Cassia Evangelista de Oliveira\",\"Joao Benhur Mokochinski\",\"Magda Vieira Cardoso\",\"Marta Chagas Monteiro\",\"Monica Soares de Campos\",\"Osmany Cuesta-Rubio\",\"Roseane Guimaraes Ferreira\",\"Tatiana Onofre de Lira\",\"Yohandra Reyes Torres\"}',\n",
       "       '{\"Ana Maria Parente Garcia Alencar\",\"Jose Claudio Garcia Lira Neto\",\"Marcio Flavio Moura de Araujo\",\"Maria Lucia Zanetti\",\"Maria Wendiane Gueiros Gaspar\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner Junior Freire de Freitas\"}',\n",
       "       '{\"Machado, Lucas Dias Soares\",\"Machado, Maria de Fátima Antero Sousa\",\"Mesquita, Caroline Antero Machado\",\"Miranda, Karla Corrêa lima\",\"Moreira, Maria Rosilene Cândido\",\"Teixeira, Olga Feitosa Braga\"}',\n",
       "       '{\"Leite, Paloma Loiola\",\"Machado, Lucas Dias Soares\",\"Machado, Maria de Fátima Antero Sousa\",\"Moreira, Maria Rosilene Cândido\",\"Silva, Maria Rocineide Ferreira\",\"Xavier, Samyra Paula Lustoza\"}',\n",
       "       '{\"Andrade, Luiz Odorico Monteiro de\",\"Barreto, Ivana Cristina de Holanda Cunha\",\"Freitas, Roberto Wagner Junior Freire de\",\"Nuto, Sharmenia de Araújo Soares\",\"Pessoa, Vanira Matos\",\"Ribeiro, Kelen Gomes\",\"Sousa, Maria de Fátima Antero de\",\"Vieira-Meyer, Anya Pimental Gomes Fernandes\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira Meyer\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Luiz Odorico Monteiro de Andrade\",\"Roberto Wagner Júnior Freire de Freitas\",\"Sharmênia de Araújo Soares Nuto\",\"Vanira Matos Pessoa\"}',\n",
       "       '{\"Andre Reynaldo Santos Périssé\",\"Beatriz Fátima Alves de Oliveira\",\"Roberto Wagner Júnior Freire de Freitas\",\"Sandra de Souza Hacon\",\"Sharmênia de Araújo Soares Nuto\"}',\n",
       "       '{\"Adriano LÃºcio Peracchi\",\"JosÃ© LuÃ\\xads Passos Cordeiro\",\"Luiz Flamarion Barbosa de Oliveira\",\"Marcione Brito de Oliveira\",\"Martha Lima BrandÃ£o\"}',\n",
       "       '{\"João Hermínio Martins da Silva\"}',\n",
       "       '{\"Ana Carolina GuimarÃ£es\",\"Joao H. M. da Silva\",\"Laurent Emmanuel Dardenne\",\"Luiz Phillippe R. Baptista\",\"Vanessa V. C. Sinatti\"}',\n",
       "       '{\"Aline de Oliveira Albuquerque\",\"Geraldo Rodrigues Sartori\",\"Haroldo Cid da Silva Junior\",\"Joao Herminio Martins da Silva\"}',\n",
       "       '{\"Barbosa, Ana Caroline Mendes\",\"Carneiro, Fernando Ferreira\",\"Pessoa, Vanira Matos\",\"Silva, Flora Viana Elizeu da\",\"Sombra Neto, Luis Lopes\"}',\n",
       "       '{\"Barreto, Ivana Cristina de Holanda Cunha\",\"Carvalho, Juliana Burlamaqui\",\"Torres, Rafael Bruno Silva\"}',\n",
       "       '{\"Gomes, Silvia Helena Pereira\",\"Machado, Lucas Dias Soares\",\"Machado, Maria de Fátima Antero Sousa\",\"Nuto, Sharmênia de Araújo Soares\",\"Pequeno, Alice Maria Correia\",\"Sobral, Iriana Lays lima\"}',\n",
       "       '{\"Jaime Ribeiro Filho\",\"Kellen Cristina da Silva Gasque\"}',\n",
       "       '{\"Albuquerque, Izabelle Mont´alverne Napoleão\",\"Barreto, Ivana Cristina Holanda Cunha\",\"Gomes, Valéria Bastos\",\"Torres, Amélia Romana Almeida\"}',\n",
       "       '{\"Ana Vladia Bandeira Moreira\",\"Jose Claudio Garcia Lira Neto\",\"Marcio Flavio Moura de Araujo\",\"Maria Aparecida Alves de Oliveira Serra\",\"Maria do Livramento Paula\",\"Maria Wendiane Gueiros Gaspar\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner Junior Freire de Freitas\",\"Vanessa Derenji de Mello\",\"Vivian Saraiva Veras\"}',\n",
       "       '{\"Anderson C. S. Feitosa\",\"Bruno C. Cavalcanti\",\"Bruno L. Sousa\",\"Claudia Pessoa\",\"Eufranio N. da Silva\",\"Ewerton W. S. Caetano\",\"Fatima C. E. Oliveira\",\"Francisco A. M. Sales\",\"Gleiston G. Dias\",\"Ito L. Barroso-Neto\",\"Luiz O. Ladeira\",\"Marcilia P. Costa\",\"Rainer Fischer\",\"Stefano di Fiore\",\"Valder N. Freire\"}',\n",
       "       '{\"Deusilene Souza Vieira\",\"Juan Miguel Villalobos Salcedo\",\"Larissa Deadame de Figueiredo Nicolete\",\"Lourdes Maria Pinheiro Borzacov\",\"Roberto Nicolete\"}',\n",
       "       '{\"Danilo Ferreira de Sousa\",\"Marcio Flavio Moura de Araujo\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner Junior Freire de Freitas\",\"Vanessa Derenji de Mello\"}',\n",
       "       '{\"Erly Catarina Moura\",\"FabrÃ\\xadcio Vieira Cavalcante\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Juan Cortez-Escalante\",\"Leonor Maria Pacheco Santos\",\"Mauro Niskier Sanchez\"}',\n",
       "       '{\"Fabio Miyajima\",\"Fernanda Remigio Nunes\",\"Francisco Jose Candido da Silva\",\"Lisandra Serra Damasceno\",\"Luis Arthur Brasil Gadelha Farias\",\"Pablo Eliack Linhares de Holanda\"}',\n",
       "       '{\"Adonai Alvino Pessoa Junior\",\"Alexandro Guterres\",\"Danielle Forneas\",\"Elba Regina Sampaio de Lemos\",\"Emmanuel Messias Vilar\",\"Jorlan Fernandes\",\"Jose Luis Passos Cordeiro\",\"Martha Macedo de lima Barata\",\"Martin Roberto del Valle Alvarez\",\"Michelle Santos Ferreira\",\"Pedro Cordeiro-Estrela\",\"Renata Carvalho de Oliveira\",\"Ricardo Moratelli\",\"Roberto Leonan Morim Novaes\",\"Rui Cerqueira da Silva\",\"Sergio Luiz Althoff\",\"Tatiana Rozental\"}',\n",
       "       '{\"Claudia Pessoa\",\"Cristiana Libardi Miranda Furtado\",\"Daniel Pascoalino Pinheiro\",\"Gilvan Pessoa Furtado\",\"Kaio Cesar Simiano Tavares\",\"Louhanna Pinheiro Rodrigues Teixeira\",\"Maria Claudia dos Santos Luciano\",\"Mayara Magna de lima Melo\",\"Renan da Silva Santos\",\"Ronald Feitosa Pinheiro\",\"Sarah Leyenne Alves Sales\"}',\n",
       "       '{\"Fabio lima Custodio\",\"Karina Baptista dos Santos\",\"Laurent Emmanuel Dardenne\",\"Raphael Trevizani\"}',\n",
       "       '{\"Costa, Samuel Carvalho\",\"Lima, Danilo Lopes Ferreira\",\"Marques, Thâmia Martins\",\"Neri, Jiovanne Rabelo\",\"Santos, Helena Paula Guerra dos\",\"Veras, Pedro Jessé lima\"}',\n",
       "       '{\"Carlos Alberto Andrade Serra dos Santos\",\"Clarissa Porfirio Mendes\",\"Danilo de Jesus Costa\",\"Marcio Flavio Moura de Araujo\",\"Maria Aparecida Alves de Oliveira Serra\",\"Mary Elizabeth de Santana\",\"Mauro Francisco Brito Filho\"}',\n",
       "       '{\"Adriana Vieira-de-Abreu\",\"Andrea Surrage Calheiros\",\"Celidarque da Silva Dias\",\"Christianne Bandeira Melo\",\"Diego da Silva Mendes\",\"Jaime Ribeiro Filho\",\"Katharinne Ingrid Moraes de Carvalho\",\"MÃ¡rcia Regina Piuvezam\",\"Marco AurÃ©lio Martins\",\"PatrÃ\\xadcia T. Bozza\"}',\n",
       "       '{\"Amelia Ribeiro de Jesus\",\"Brunheld Maia Dutra\",\"Clarissa Romero Teixeira\",\"Francisco Rafael Marciano Fonseca\",\"Margarida Maria de lima Pompeu\",\"Maria Jania Teixeira\",\"Naya Lucia de Castro Rodrigues\",\"Roque Pacheco de Almeida\",\"Tatiana Rodrigues de Moura\",\"Ticiana Monteiro Abreu\"}',\n",
       "       '{\"Ana Cristina lima Leite\",\"Arinice de Menezes Costa\",\"Claudia Pessoa\",\"Daisy Jereissati Barbosa Lima\",\"Diogo Rodrigo Magalhaes Moreira\",\"Gevanio Bezerra de Oliveira Filho\",\"Jamile Magalhaes Ferreira\",\"Jurandy do Nascimento Silva\",\"Maria Goretti Rodrigues de Queiroz\",\"Patricia Marcal da Costa\",\"Paulo Michel Pinheiro Ferreira\",\"Renata Rosado Drumond\"}',\n",
       "       '{\"B. C. Cavalcanti\",\"C. Pessoa\",\"M. F. C. dos Santos\",\"P. M. P. Ferreira\",\"R. G. S. Berlinck\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Caroline Barbosa Lourenco\",\"Jose Manuel Peixoto Caldas\",\"July Grassiely de Oliveira Branco\",\"Maria Vieira de lima Saintrain\",\"Suzanne Vieira Saintrain\"}',\n",
       "       '{\"Marlos de Medeiros Chaves\",\"Roberto Nicolete\"}',\n",
       "       '{\"Ana Cristina lima Leite\",\"Carlos Alberto de Simone\",\"Claudia Pessoa\",\"Diogo Rodrigo Magalhaes Moreira\",\"Elisalva Teixeira Guimaraes\",\"Gevanio Bezerra Oliveira Filho\",\"Jose Wanderlan Pontes Espindola\",\"Laura Rubio Gonzalez\",\"Lucas Cunha Duarte Coelho\",\"Marcelo Montenegro Rabello\",\"Marcelo Zaldini Hernandes\",\"Marcos Verissimo de Oliveira Cardoso\",\"Milena Botelho Pereira Soares\",\"Paulo Michel Pinheiro Ferreira\",\"Suellen Melo Tiburcio Cavalcanti\"}',\n",
       "       '{\"Campos, Eugenio de Moura\",\"Cordeiro, Rebecca de Aguiar\",\"Souza, Maximiliano Loiola Ponte de\"}',\n",
       "       '{\"Aguiar, Jaina Bezerra de\",\"Monteiro de Andrade, Luiz Odorico\",\"Ribeiro, Kelen Gomes\"}',\n",
       "       '{\"Carles Muntaner\",\"Carlos QuiÃ±onez\",\"Denise Gastaldo\",\"Paola Calvasina\"}',\n",
       "       '{\"AntÃ´nio Mauro Barbosa de Oliveira\",\"FÃ¡bio JosÃ© Gomes de Sousa\",\"Francisca Raquel de Vasconcelos Silveira\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Luiz Odorico Monteiro de Andrade\",\"Nardelli Brenda Soares Barros\",\"Osvaldo de Souza\",\"Rebecca Lucena Theophilo\",\"Vielceketlin Franco Viana\"}',\n",
       "       '{\"Larissa de FÃ¡tima Pontes Aguiar Alves\",\"MÃ¡rcio FlÃ¡vio Moura de AraÃºjo\",\"Manoel Miqueias Maia\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner JÃºnior Freire de Freitas\"}',\n",
       "       '{\"Gilvan Pessoa Furtado\",\"Livia Soares Zaramela\",\"Marjorie Cornejo Pontelli\",\"Rafael Silva-Rocha\",\"Tie Koide\"}',\n",
       "       '{\"Aline Albuquerque\",\"Andrielly Henriques\",\"Beatriz Chaves\",\"Disraeli Vasconcelos\",\"Ernesto Raul Caffarena\",\"Geraldo Sartori\",\"JoÃ£o Herminio Martins-Da-silva\",\"Luca Andrade\",\"Wilson Savino\"}',\n",
       "       '{\"Borges, Bráulio Viera de Sousa\",\"Falcão, Lariza Martins\",\"Freitas, Roberto Wagner Júnior Freire de\",\"Lira Neto, José Cláudio Garcia\",\"Silva, Andréa Pereira da\"}',\n",
       "       '{\"Adriana Costa Bacelo\",\"Andrea Ramalho\",\"Claudia dos Santos Cople-Rodrigues\",\"Eliane Paiva\",\"Georg Ingebourg\",\"Pedro Emmanuel Alvarenga Americano Brasil\",\"Valeria Cavalcanti Rolla\"}',\n",
       "       '{\"Alda Maria da Cruz\",\"Carrel Xavier Martins Lima\",\"Clarissa Romero Teixeira\",\"Diane Isabelle Magno Cavalcante\",\"Francisco Rafael Marciano Fonseca\",\"Maria Jania Teixeira\",\"Naya Lucia Rodrigues de Castro\",\"Rafaelle de Paula Freire\",\"Raquel Peralva Ribeiro-Romao\",\"Regis Gomes\"}',\n",
       "       '{\"AndrÃ© Luiz Maia Roque\",\"Birgit Arnholdt-Schmitt\",\"Clesivan Pereira dos Santos\",\"Daniel Ferreira FeijÃ³\",\"JoÃ£o HermÃ\\xadnio Martins da Silva\",\"JosÃ© HÃ©lio Costa\",\"KÃ¡tia Daniella da Cruz Saraiva\",\"Karine LeitÃ£o Lima Thiers\",\"Rachel Alves Maia\"}',\n",
       "       '{\"Amilcar Sabino Damazo\",\"Carrie A. Duckworth\",\"Domingos Tabajara de Oliveira Martins\",\"Eduarda Pavan\",\"Fabio Miyajima\",\"Joaquim Corsino da Silva Lima\",\"Karuppusamy Arunachalam\",\"Layren Ferreira Antonielli\",\"Ruberlei Godinho de Oliveira\"}',\n",
       "       '{\"Alex E. Clark\",\"Alexander L. Perryman\",\"Aline De Oliveira Albuquerque\",\"Ana C. Puhl\",\"Bruna Katiele De Paula Sousa\",\"Bruno Junior Neves\",\"Carolina Horta Andrade\",\"Eugene Muratov\",\"Fabio Urbina\",\"Gabriela Dias Noske\",\"Geraldo Rodrigues Sartori\",\"Glaucius Oliva\",\"Guilherme E. Souza\",\"Jair L. Siqueira-Neto\",\"JoÃ£o HermÃ\\xadnio Martins Da Silva\",\"JosÃ© TeÃ³filo Moreira-Filho\",\"Ketllyn Irene Zagato De Oliveira\",\"Melina Mottin\",\"Nathalya Cristina De Moraes Roso Mesquita\",\"Rafael V. C. Guido\",\"Sean Ekins\"}',\n",
       "       '{\"Betty Diamond\",\"Bruno C. Rocha\",\"Carolina Gallego-Marin\",\"Dhelio B. Pereira\",\"Douglas T. Golenbock\",\"Humberto Gravina\",\"Isabella C. Hirako\",\"Joseph Vinetz\",\"Marco Antonio Ataide\",\"Ricardo T. Gazzinelli\",\"Rosane B. de Oliveira\",\"Sanjay Ram\",\"Warrison A. Andrade\"}',\n",
       "       '{\"Anderson Milfont Feitosa de Oliveira\",\"Estelita lima Candido\",\"Larissa lima Barros\",\"Maria de Fatima Antero Sousa Machado\",\"Maria Rosilene Candido Moreira\",\"Natalia Campos Parente\",\"Raul de Freitas Aquino\"}',\n",
       "       '{\"Aderita Sena\",\"Carlos Corvalan\",\"Carlos Freitas\",\"Christovam Barcellos\",\"Fernando Carneiro\",\"Marcel Pedroso\",\"Patrícia Feitosa Souza\",\"Tais Alpino\"}',\n",
       "       '{\"Abdulrazak B. Ibrahim\",\"Alex Chapeaurouge\",\"Ana Cristina de Oliveira Monteiro-Moreira\",\"Leonardo R. Oliveira Normando\",\"Stephen P. Mackessy\",\"Thiago L. Juca\"}',\n",
       "       '{\"Fernanda Montenegro de Carvalho Araujo\",\"Luiz Odorico Monteiro de Andrade\",\"Marcela Helena Gambim Fonseca\",\"Tamiris de Fatima Goebel de Souza\"}',\n",
       "       '{\"Amanda Campelo lima de Melo\",\"Ana Carolina Matias Dinelly Pinto\",\"Eduardo Ruback dos Santos\",\"Fernanda Montenegro de Carvalho Araujo\",\"Germana Silva Vasconcelos\",\"Luiz Odorico Monteiro de Andrade\",\"Marcela Helena Gambim Fonseca\",\"Maria Francilene Souza Silva\"}',\n",
       "       '{\"Claudia Mendonca Bezerra\",\"Claudio Casanova\",\"Evandro Marques de Menezes Machado\",\"Fernando Braga Stehling Dias\",\"Lileia Diotaiuti\"}',\n",
       "       '{\"Fernando Abad-Franch\",\"Fernando Araujo Monteiro\",\"Fernando Braga Stehling Dias\",\"LilÃ©ia Diotaiuti\",\"NicolÃ¡s Jaramillo O.\",\"Rodrigo Gurgel-GonÃ§alves\"}',\n",
       "       '{\"Anderson Sa-Nunes\",\"Iva Kolarova\",\"Matheus Carneiro\",\"Regis Gomes\"}',\n",
       "       '{\"Jaime Ribeiro Filho\",\"John Ogbaji Igoli\",\"Raffaele Capasso\",\"Yanna Carolina Ferreira Teles\"}',\n",
       "       '{\"Arruda, Gisele Maria Melo Soares\",\"Barreto, Ivana Cristina de Holanda Cunha\",\"Loiola, Francisco Antônio\",\"Pontes, Ricardo José Soares\"}',\n",
       "       '{\"Amanda Cavalcante Frota\",\"Ana Ester Maria Melo Moreira\",\"Jaina Bezerra de Aguiar\",\"Kelen Gomes Ribeiro\",\"Luiz Odorico Monteiro de Andrade\"}',\n",
       "       '{\"Bruno de Bezerril Andrade\",\"Hardy Kornfeld\",\"Kiyoshi Ferreira Fukutani\",\"María Belen Arriaga Gutiérrez\",\"Nathella Pavan Kumar\",\"Subash Babu\",\"Thabata Alves Moniz de Aragão Oliveira\",\"Vijay Viswanathan\"}',\n",
       "       '{\"Ana Cristina de Oliveira Monteiro Moreira\",\"Atanu Biswas\",\"Erivan Souza Oliveira\",\"Francisco Rogenio da Silva Mendes\",\"Huai N. Cheng\",\"Joao Pedro Viana Rodrigues\",\"Maria do Socorro Rocha Bastos\",\"Mighay Lovera\",\"Nadya Virginia lima Peixoto Maia\",\"Renato de Azevedo Moreira\",\"Valessa Rios Pires\"}',\n",
       "       '{\"Adriana Silva Pontes\",\"Anderson Makoto Kayano\",\"Andreimar Martins Soares\",\"Carla Freire Celedonio Fernandes\",\"Juliana Pavan Zuliani\",\"Mauro Valentino Paloschi\",\"Neriane Monteiro Nery\",\"Onassis Boeri de Castro\",\"Rodrigo Guerino Stabeli\",\"Soraya dos Santos Pereira\",\"Sulamita da Silva Setubal\",\"Weverson Luciano Pires\"}',\n",
       "       '{\"Gerdane Celene Nunes Carvalho\",\"Jose Claudio Garcia Lira-Neto\",\"Marcio Flavio Moura de Araujo\",\"Maria Lucia Zanetti\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner Junior Freire de Freitas\"}',\n",
       "       '{\"Ana C. P. J. Costae\",\"Danilo F. Sousa\",\"Francisco E. R. Paes\",\"Marcio F. M. Araujo\",\"Maria A. A. O. Serra\",\"Maria Conceicao S. O. Cunha\",\"Maria L. Paula\",\"Maria V. O. Queiroz\",\"Marta M. C. Damasceno\",\"Roberto W. J. F. Freitas\",\"Vanessa E. C. S. Freire\",\"Vivian S. Veras\"}',\n",
       "       '{\"Danilo Ferreira de Sousa\",\"Joana Furtado de Figueiredo Neta\",\"Jose Claudio Garcia Lira Neto\",\"Marcio Flavio Moura de Araujo\",\"Maria Veraci Oliveira Queiroz\",\"Marida Conceicao dos Santos Oliveira Cunha\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner Junior Freire de Freitasa\",\"Vivian Saraiva Veras\"}',\n",
       "       '{\"R. Freitas\"}',\n",
       "       '{\"Arturo Alejandro Zavala Zavala\",\"Carlos Alexandre Fett\",\"Fabio Miyajima\",\"Michelle Jalousie Kommers\",\"Rosilene Andrade Silva Rodrigues\",\"Ruberlei Godinho de Oliveira\",\"Sikiru Olaitan Balogun\",\"Viviane Regina Leite Moreno Ultramari\",\"Waleria Christiane Rezende Fett\"}',\n",
       "       '{\"Ana Maria Parente Garcia Alencar\",\"Carla Regina de Souza Teixeira\",\"Gerdane Celene Nunes Carvalho\",\"Jose Claudio Garcia Lira Neto\",\"Kenya Waleria Siqueira Coelho Lisboa\",\"Marcia Aparecida Ciol\",\"Marcio Flavio Moura de Araujo\",\"Maria Lucia Zanetti\",\"Marta Maria Coelho Damasceno\",\"Regina Lucio Lino Marques\",\"Roberto Wagner Junior Freire de Freitas\"}',\n",
       "       '{\"Ana Carolina Justino de Araujo\",\"Cicera Datiane de Morais Oliveira-Tintino\",\"Cristina Rodrigues dos Santos Barbosa\",\"Henrique Douglas Melo Coutinho\",\"Humberto Medeiros Barreto\",\"Ieda Maria Begnini\",\"Irwin Rose Alencar de Menezes\",\"Jaime Ribeiro Filho\",\"Jose Bezerra de Araujo Neto\",\"Luiz Everson da Silva\",\"Maria Isabel Lacowicz Krautler\",\"Michele Caroline Nasato\",\"Priscilla Ramos Freitas\",\"Ricardo Andrade Rebelo\",\"Sandro Lucio Mireski\",\"Saulo Relison Tintino\"}',\n",
       "       '{\"Alice Sampaio Rocha\",\"Edson Delatorre\",\"Elisa Cavalcante Pereira\",\"FÃ¡bio Miyajima\",\"Felipe Gomes Naveca\",\"Gabriel Luz Wallau\",\"Gonzalo Bello\",\"Helisson Faoro\",\"Ighor Arantes Gomes\",\"Luciana Reis Appolinario\",\"Marilda MendonÃ§a Siqueira\",\"Paola Cristina Resende\",\"Renata Serrano Lopes\",\"TainÃ¡ Moreira Martins Venas\",\"Tiago GrÃ¤f\"}',\n",
       "       '{\"Anderson C. S. Feitosa\",\"Bruno C. Cavalcanti\",\"Claudia Pessoa\",\"Eufranio N. da Silva Junior\",\"Ewerton W. S. Caetano\",\"Fatima C. E. Oliveira\",\"Francisco A. M. Sales\",\"Gleiston G. Dias\",\"Luiz O. Ladeira\",\"Marcilia P. Costa\",\"Rainer Fischer\",\"Stefano di Fiore\",\"Valder N. Freire\"}',\n",
       "       '{\"Adriano Defini Andricopulo\",\"Andrea Mendes do Nascimento\",\"Andres Mauricio Caraballo-Rodriguez\",\"Bruno Coelho Cavalcanti\",\"Claudia Pessoa\",\"Fernanda Oliveira Chagas\",\"Leticia Veras Costa-Lotufo\",\"Manoel Odorico de Moraes\",\"Monica Tallarico Pupo\",\"Norberto Peporine Lopes\",\"Raphael Conti\",\"Renata Krogh\",\"Weilan Gomes da Paixao Melo\"}',\n",
       "       '{\"Andreimar M. Soares\",\"Anna Carolina M. Marinho\",\"Carla F. C. Fernandes\",\"Gilvan Pessoa Furtado\",\"Juliana P. Zuliani\",\"Marcela Cristina S. Silva\",\"Marcela H. G. Fonseca\",\"Marcos B. Luiz\",\"Nauanny K. R. L. Silva\",\"Raphael Trevizani\",\"Roberto Nicolete\",\"Rodrigo G. Stabeli\",\"Soraya S. Pereira\"}',\n",
       "       '{\"Carlos Alessandro Fuzo\",\"Gilvan Pessoa Furtado\",\"Lucas Ferreira Ribeiro\",\"Marcos Roberto Lourenzoni\",\"Maria-Eugenia Guazzaroni\",\"Raquel Fonseca-Maldonado\",\"Richard J. Ward\"}',\n",
       "       '{\"Gilvan Pessoa Furtado\",\"JosÃ© Carlos Santos Salgado\",\"Luana Parras Meleiro\",\"Richard John Ward\",\"Sibeli Carli\"}',\n",
       "       '{\"Andr R. L. Damasio\",\"Camila R. Santos\",\"Gilvan P. Furtado\",\"Lucas F. Ribeiro\",\"Luiz A. B. de Moraes\",\"Marcos R. Lourenzoni\",\"Maria de Lourdes T. M. Polizeli\",\"Mario T. Murakami\",\"Richard J. Ward\",\"Rosa L. Cordeiro\"}',\n",
       "       '{\"Elizabeth Ferreira Rangel\",\"Jose Luis Passos Cordeiro\",\"Simone Miranda da Costa\"}',\n",
       "       '{\"Claudia Pessoa\",\"Cristiana Libardi Miranda Furtado\",\"Gilvan Pessoa Furtado\",\"Manoel Odorico Moraes\",\"Maria Claudia dos Santos Luciano\",\"Renan da Silva Santos\"}',\n",
       "       '{\"Claudia do O. Pessoa\",\"Cristiana Libardi Miranda Furtado\",\"Daniel Pascoalino Pinheiro\",\"Gilvan Pessoa Furtado\",\"Larissa Queiroz Pontes\",\"Pedro Mikael da Silva Costa\",\"Sarah Leyenne Alves Sales\",\"Sarah Sant\\'anna Maranhao\"}',\n",
       "       '{\"Adriana Gioda\",\"Andre Reynaldo Santos Perisse\",\"Edenilo Baltazar Barreira Filho\",\"Francisco Wagner de Sousa\",\"karen dos Santos Goncalves\",\"Lucas de Oliveira do Couto\",\"Sandra de Souza Hacon\",\"Sharmenia de Araujo Soares Nuto\"}',\n",
       "       '{\"Dias, Maria Socorro de Araújo\",\"Forte, Franklin Delano Soares\",\"Freire, Roberto Wagner Junior\",\"Pinto, Antônio Germane Alves\",\"Silva Júnior, Fernando José Guedes da\",\"Vieira-Meyer, Anya Pimentel Gomes Fernandes\"}',\n",
       "       '{\"Almeida, Magda Moura de\",\"Carneiro, Fernando Ferreira\",\"Costa, Leandro Araujo da\",\"Dias, Alexandre Pessoa\",\"Machado, Maria de Fátima Antero Sousa\",\"Menezes, Francisco Wagner Pereira\",\"Pessoa, Vanira Matos\"}',\n",
       "       '{\"Ferreira, Cibelly Melo\",\"Nuto, Sharmênia de Araújo Soares\",\"Pessoa, Vanira Matos\",\"Silva, Maria Rocineide Ferreira da\"}',\n",
       "       '{\"Alencar, Ana Maria Parente Garcia\",\"Araújo, Márcio Flávio Moura de\",\"Firmino, Paulo Renato Alves\",\"Formiga, Natália Pinheiro Fabrício\",\"Oliveira, Célida Juliana\",\"Rebouças, Vitória de Cássia Félix\"}',\n",
       "       '{\"Elaine Ferreira do Nascimento\",\"Regis Bernardo Brandim Gomes\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira Meyer\",\"Janássia Gondim Monteiro\",\"Leonardo Barbosa Rolim\",\"Márcio Flávio Moura de Araújo\",\"Roberto Wagner Junior Freire Freitas\",\"Sharmênia de Araújo Soares Nuto\"}',\n",
       "       '{\"Amalia Santos Ferreira\",\"Dionatas Ulisses de Oliveira Meneguetti\",\"Neuza Biguinati de Barros\",\"Roberto Nicolete\",\"Sharon Rose Aragao Macedo\",\"Thamy Yamashita Shibayama\",\"Valdir Alves Facundo\"}',\n",
       "       '{\"Ana Maria Parente Garcia Alencar\",\"Kenya Waleria de Siqueira Coelho Lisboa\",\"Marta Maria Coelho Damasceno\",\"Niciane Bandeira Pessoa Marinho\",\"Roberto Wagner Junior Freire de Freitas\",\"Vitoria de Cassia Felix Reboucas\"}',\n",
       "       '{\"Amalia S. Ferreira\",\"Joao G. Ribeiro\",\"Mayara C. P. da Silva\",\"Neuza B. de Barros\",\"Norton R. D. L. P. Rossi\",\"Roberto Nicolete\",\"Rosane N. M. Guerra\",\"Sharon R. A. Macedo\"}',\n",
       "       '{\"Antonio Carlos Rosario Vallinoto\",\"Beatriz Dias\",\"Claudio Manuel Goncalves da Silva Leite\",\"Danielle Silveira Macedo\",\"Fabio Miyajima\",\"Gabriella Pequeno Costa Gomes de Aguiar\",\"Luciano Pamplona de goes Cavalcanti\",\"Maria Elisabete Amaral de Moraes\",\"Renata Amaral de Moraes\",\"Silvania Maria Mendes Vasconcelos\"}',\n",
       "       '{\"Jesem Douglas Yamall Orellana\",\"Maximiliano Loiola Ponte de Souza\"}',\n",
       "       '{\"Bernardo Rodrigues Teixeira\",\"Camila dos Santos Lucio\",\"Elba Regina Sampaio de Lemos\",\"Fernando de Oliveira Santos\",\"Gabriel Rosa Cavalcanti\",\"Hudson Lemos\",\"Jorlan Fernandes\",\"Jose Luis Passos Cordeiro\",\"Pablo Rodrigues Goncalves\",\"Paulo Sergio D\\'andrea\",\"Renata Carvalho de Oliveira\",\"Rute Hilario Albuquerque de Sousa\"}',\n",
       "       '{\"Ana Cláudia de Araújo Teixeira\"}',\n",
       "       '{\"Ariany lima Sousa Torres\",\"Daniel Camara Teixeira\",\"Emanuelly Thays Muniz Figueiredo Silva\",\"Gilvan Pessoa Furtado\",\"Kaio Cesar Simiano Tavares\",\"Leonardo Tondello Martins\",\"Louhanna Pinheiro Rodrigues Teixeira\",\"Ludmilla Freire Caetano\",\"Marcela Helena Gambim Fonseca\",\"Matheus Soares Alves\",\"Raquel Caminha Dantas\",\"Renato de Azevedo Moreira\",\"Saul Gaudencio Neto\"}',\n",
       "       '{\"A. A. Coelho\",\"A. T. L. Sampaio\",\"A. Vieira-Meyer\",\"C. S. M. Sousa\",\"M. F. A. S. Machado\",\"P. M. Rocha\",\"S. A. C. Uchoa\",\"T. X. A. Pinheiro\"}',\n",
       "       '{\"Adriano Martins\",\"Ana Silva\",\"Anya Meyer\",\"Carl Kendall\",\"Carlos Sanhueza\",\"Cristiane Frota\",\"Dawn Wesson\",\"Fabio Myiajima\",\"Fernanda Araujo\",\"Francisco Correia\",\"Francisco Junior\",\"Ilka Alcantara\",\"Ivana Barreto\",\"Jose Junior\",\"Larissa Araujo\",\"Leda Simoes\",\"Ligia Kerr\",\"Livia Dias\",\"Lucas Vasconcelos\",\"Luciano Pamplona\",\"Marco Ribeiro\",\"Maria Teixeira\",\"Paulo Sousa\",\"Rosa Almeida\",\"Shirlene Lima\",\"Susy Saraiva\"}',\n",
       "       '{\"Ana Patricia Pereira Morais\",\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Isabella lima Barbosa Campelo\",\"Jose Maria Ximenes Guimaraes\",\"Karolina de Sousa Lopes\",\"Maria de Fatima Antero Sousa Machado\",\"Neiva Francenely Cunha Vieira\",\"Paula Sacha Frota Nogueira\",\"Roberto Wagner Junior Freire de Freitas\",\"Sharmenia de Araujo Soares Nuto\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Karla PatrÃ\\xadcia Cardoso Amorim\",\"Maria de FÃ¡tima Antero Sousa Machado\",\"Maria Socorro de AraÃºjo Dias\",\"Maristela InÃªs Osawa Vasconcelos\",\"Neiva Francenely Cunha Vieira\",\"Roberto Wagner JÃºnior Freire de Freitas\",\"SharmÃªnia de AraÃºjo Soares Nuto\"}',\n",
       "       '{\"AntÃ´nio Germane Alves Pinto\",\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Fernando JosÃ© Guedes da Silva JÃºnior\",\"Franklin Delano Soares Forte\",\"Maria Socorro de AraÃºjo Dias\",\"Roberto Wagner Junior Freire\"}',\n",
       "       '{\"Adriana Rocha Simiao\",\"Andre Luiz de Abreu\",\"Andre Ricardo Ribas Freitas\",\"Camila de Sousa Lins\",\"Carlos Henrique Morais de Alencar\",\"Clayton Pereira Silva Lima\",\"Daniele Rocha Queiroz Lemos\",\"Darlan da Silva Candido\",\"Deborah Nunes de Melo Braga\",\"Emerson Luiz lima Araujo\",\"Fabio Miyajima\",\"Fabio Rocha Fernandes Tavora\",\"Fernanda Montenegro de Carvalho Araujo\",\"Francisca Kalline de Almeida Barreto\",\"Izabel Leticia Cavalcante Ramalho\",\"Jean-Paul Carrera\",\"Joao Lidio da Silva Goncalves Vianez Junior\",\"John Washington Cavalcante\",\"Leda Maria Simoes Mello\",\"Leonardo Hermes Dutra\",\"Luciano Monteiro Franco\",\"Luciano Pamplona de goes Cavalcanti\",\"Luiz Tadeu Moraes Figueiredo\",\"Marcelo Nunes Pereira Melo\",\"Marcilio Jorge Fumagalli\",\"Marcio Roberto Teixeira Nunes\",\"Mayara Jane Miranda da Silva\",\"Michel Platini Caldas de Souza\",\"Nuno Rodrigues Faria\",\"Oliver G. Pybus\",\"Rafael Ribeiro Barata\",\"Rhaquel de Morais Alves Barbosa Oliveira\",\"Ronaldo de Jesus\",\"Shirlene Telmos Silva de Lima\",\"Vagner de Souza Fonseca\",\"William Marciel de Souza\"}',\n",
       "       '{\"Adriano Ferreira Martins\",\"Ana Ecilda Lima Ellery\",\"Arachu Castro\",\"Carl Kendall\",\"Christopher Dunn\",\"Francisco Marto Leal Pinheiro\",\"Ivana Cristina de Holanda Barreto\",\"Jeni Stolow\",\"Kelly Alves de Almeida Furtado\",\"Ligia Kerr\",\"Lina Moses\",\"Livia Dias\",\"Mariana Campos da Rocha Feitosa\",\"Mayara Paz Albino dos Santos\"}',\n",
       "       '{\"Aline L. de P. Evangelista\",\"Hugo L.C.T. Barroso\",\"Ismayle de S. Santos\",\"Ivana C. de H. C. Barreto\",\"JoÃ£o B.F. Neto\",\"Joseane de O. V. Paiva\",\"Luiz Odorico M. de Andrade\",\"Rodrigo L.A. Almeida\",\"Rossana M.C. Andrade\",\"Thais N. Gouveia\"}',\n",
       "       '{\"AntÃ´nio Mauro Barbosa de Oliveira\",\"Daniel Barreto de Andrade\",\"Jean-Louis Denis\",\"JosÃ© Neuman de Souza\",\"Kelen Gomes Ribeiro\",\"Luiz Odorico Monteiro de Andrade\",\"Luzia LucÃ©lia Saraiva Ribeiro\",\"Raimundo Valter Costa Filho\",\"Silas Santiago Lopes Pereira\"}',\n",
       "       '{\"Amy Nunn\",\"Francisco Inacio Bastos\"}',\n",
       "       '{\"Andrea Santos Lima\",\"Carlos Feitosa Luna\",\"Haiana Charifker Schindler\",\"Karen Machado Gomes\",\"Klarissa Miranda Guarines\",\"LÃ\\xadlian Maria Lapa Montenegro\",\"Maria Madileuza Carneiro Neves\",\"Rafael Silva Duarte\"}',\n",
       "       '{\"Camila de Souza Ronconi\",\"Camila Patricio Braga Filgueira\",\"Cipriano Ferreira da Silva Junior\",\"Claudino Limeira\",\"Cristiane Batista Mattos\",\"Elisa Cupolillo\",\"Gabriel Eduardo Melim Ferreira\",\"Helen Paula de Jesus Silva\",\"Lilian Motta Cantanhede\",\"Renato Porrozzi\",\"Ricardo de Godoi Mattos Ferreira\"}',\n",
       "       '{\"A. J. H. Tasco\",\"A. M. do Nascimento\",\"C. Pessoa\",\"I. J. O. Sousa\",\"I. V. Rodrigues\",\"K. N. Machado\",\"M. J. Salvador\",\"P. M. P. Ferreira\"}',\n",
       "       '{\"Claudia do O. Pessoa\",\"Franciane Goncalves dos Santos\",\"Heverton Mendes Araujo\",\"Roberto Nicolete\",\"Ronaldo Nascimento de Oliveira\",\"Valentina Nascimento Melo de Oliveira\",\"Vanessa Pinheiro Goncalves Ferreira\"}',\n",
       "       '{\"Alessandra L. Esteves\",\"Diogo D. do Nascimento\",\"Fabiana M. S. U. Moncorvo\",\"Flavia F. M. de Sousa\",\"Graca M. S. Guerra\",\"Janine Boniatti\",\"Jose L. N. de Aguiar\",\"Juliana J. S. Medeiros\",\"Lucas G. Regis\",\"Luiz E. M. Ferreira\",\"Marcelo Henrique da Cunha Chaves\",\"Margareth B. C. Gallo\",\"Nelson M. Nunes\",\"Rafael C. Seiceira\"}',\n",
       "       '{\"Andre de Abreu Range Aguirre\",\"Jacqueline Cavalcante Barros\",\"Marcos Valerio Garcia\",\"Matias Pablo Juan Szabo\",\"Renato Andreotti\"}',\n",
       "       '{\"Antonio Carlile Holanda Lavor\"}',\n",
       "       '{\"Alun R. Coker\",\"Ana Cristina de Oliveira Monteiro-Moreira\",\"Bruno Bezerra da Silva\",\"David J. Abraham\",\"Felipe Domingos de Sousa\",\"Gilvan Pessoa Furtado\",\"Igor de sa Carneiro\",\"James S. Owen\",\"Jingxu Guo\",\"Marcos Roberto Lourenzoni\",\"Maria Izabel Florindo Guedes\",\"Marina Duarte Pinto Lobo\",\"Renato de Azevedo Moreira\",\"Yiwei Guan\"}',\n",
       "       '{\"Cipriano Ferreira da Silva Junior\",\"Elisa Cupolillo\",\"Juan Miguel Villalobos Salcedo\",\"Katia Paula Felipin\",\"Lilian Motta Cantanhede\",\"Marcos Massayuki Ito\",\"Renato Porrozzi\",\"Ricardo de Godoi Mattos Ferreira\",\"Roberto Nicolete\"}',\n",
       "       '{\"Aisha K. Yousafzai\",\"Ana Patrícia Pereira Morais\",\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Carlos Henrique Campos Meyer\",\"Grayce Alencar Albuquerque\",\"José Maria Ximenes Guimarães\",\"Marcia C. Castro\",\"Maria Vieira de lima Saintrain\",\"Regina Glaucia Lucena Aguiar Ferreira\"}',\n",
       "       '{\"Cristiana Libardi Miranda-Furtado\",\"Flavia Gaona de Oliveira-Gennaro\",\"Rosana Maria dos Reis\",\"Viviane Paiva Santana\"}',\n",
       "       '{\"JosÃ© L. P. Cordeiro\",\"Lucas P. Teixeira\",\"Marcelo F. Moro\",\"Marcus V. C. da Silva\",\"Rubson P. Maia\",\"SÃ¢mila S. Lima\"}',\n",
       "       '{\"Csar Moura\",\"Fabio Gomes\",\"Mauro Oliveira\",\"Morgana Ribeiro\",\"Odorico Andrade\",\"Renato Freitas\"}',\n",
       "       '{\"Cláudia Pernencar\",\"Cristiane Mourão\",\"Deivith Oliveira\",\"Fábio de Sousa\",\"Inga Saboia\",\"Ivana Barreto\",\"Kamila Gomes\",\"Odorico Monteiro\",\"Raquel Silveira\"}',\n",
       "       '{\"Adelia Maria de Miranda Henriques-Souza\",\"Alvaro J. P. Moreira\",\"Bart C. Jacobs\",\"Carlos Alexandre Antunes de Brito\",\"Dawn Gourlay\",\"Hugh J. Willison\",\"Lance Turtle\",\"Lindomar J. Pena\",\"Livia Brito Bezerra de Albuquerque\",\"Marcela Lopes Santos\",\"Maria de Fatima Pessoa Militao de Albuquerque\",\"Maria I. de Morais Machado\",\"Maria L. Brito Ferreira\",\"Mark A. Ellul\",\"Michael J. Griffiths\",\"Rafael Freitas de Oliveira Franca\",\"Raquel Medialdea-Carrera\",\"Ravi Mehta\",\"Roberta da Paz Melo\",\"Solange D. Mesquita\",\"Sonja E. Leonhard\",\"Susan Halstead\",\"Suzannah B. Lant\",\"Tom Solomon\"}',\n",
       "       '{\"Machado, Maria de Fátima Antero Sousa\",\"Moreira, Maria Rosilene Cândido\",\"Oliveira, Rogério Sampaio de\"}',\n",
       "       '{\"Carlos Alberto Andrade Serra dos Santos\",\"Daniella Pontes Matos\",\"Francisca Jacinta Feitoza de Oliveira\",\"Liniker Scolfild Rodrigues da Silva\",\"Marcio Flavio Moura de Araujo\",\"Maria Aparecida Alves de Oliveira Serra\",\"Mateus Dantas Torres\"}',\n",
       "       '{\"Anamaria Testa Tambellini\",\"Ary Miranda\",\"Fernando Ferreira Carneiro\",\"Guilherme Franco Netto\",\"Hermano Albuquerque Castro\",\"Lia Giraldo da Silva\",\"Marla Kuhn\",\"Nelson Gouveia\",\"Volney de Magalhaes Camara\"}',\n",
       "       '{\"Antonio Carlile Holanda Lavor\",\"Bruce Bartholow Duncan\",\"Camila Giugliani\",\"Erno Harzheim\",\"Joao Baptista Humbwavali\",\"Lisiane Hauser\",\"Maria Idalice Barbosa\",\"Patricia Barros Thomas\"}',\n",
       "       '{\"Adna de Araujo Silva\",\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Fabiane do Amaral Gubert\",\"Lidiane Nogueira Reboucas\",\"Maria Talyta Mota Pinheiro\",\"Roberto Wagner Junior Freire de Freitas\",\"Valter Cordeiro Barbosa Filho\"}',\n",
       "       '{\"Luciane Soares de Lima\",\"Manoel Antonio dos Santo\",\"Maria Amelia de Souza\",\"Maria Lucia Zanetti\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner Junior Freire de Freitas\"}',\n",
       "       '{\"Celso Vladimiro Cunha\",\"Dimas Tadeu Covas\",\"Evandra Strazza Rodrigues\",\"Joao Paulo Tavanez\",\"Juan Miguel Villalobos-Salcedo\",\"Larissa Deadame de Figueiredo Nicolete\",\"Mariana Tomazini Pinto\",\"Paulo Tavanez\",\"Roberto Nicolete\",\"Simone Kashima\"}',\n",
       "       '{\"Cynthia Costa de Souza\",\"Jesem Douglas Yamall Orellana\",\"Maximiliano Loiola Ponte de Souza\"}',\n",
       "       '{\"Joseane Pessanha\",\"LÃºcia Rotenberg\",\"Luciana Fernandes Portela\",\"Luciana Gomes\",\"Maria de Jesus Mendes da Fonseca\",\"Rosane Harter Griep\"}',\n",
       "       '{\"Antonio Leonel de lima Junior\",\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Luiz Odorico Monteiro de Andrade\",\"Roberto Ribeiro Maranhao\"}',\n",
       "       '{\"Andre A. Vieira\",\"Antonio L. Braga\",\"Bruno C. Cavalcanti\",\"Carlos A. de Simone\",\"Claudia Pessoa\",\"Eufranio N. da Silva Junior\",\"Igor R. Brandao\",\"Teiliane R. Carneiro\",\"Wagner O. Valenca\"}',\n",
       "       '{\"Adriana da Rocha TomÃ©\",\"Adriana Rolim Campos\",\"Ana Cristina de Oliveira Monteiro-Moreira\",\"Anida Maria Moraes Gomes\",\"Ayrles Fernanda BrandÃ£o da Silva\",\"David J. Abraham\",\"Erika Freitas Mota\",\"Felipe Domingos de Sousa\",\"Francisco RogÃªnio da Silva Mendes\",\"James S. Owen\",\"Marcos Roberto Lourenzoni\",\"Pedrinha DiÃ³genes Vasconselos\",\"Renato de Azevedo Moreira\",\"Xu Shiwen\"}',\n",
       "       '{\"Amrita Roy\",\"Chacko Jobichen\",\"Chapeaurouge Alex\",\"J. Sivaraman\",\"Nandhakishore Rajagopalan\",\"R. Manjunatha Kini\",\"Sun Qingxiang\"}',\n",
       "       '{\"João Hermínio Martins da Silva\",\"Paula Mello de Luca\",\"Rodrigo Nunes Rodrigues da Silva\"}',\n",
       "       '{\"Amanda de Oliveira Matos\",\"Geraldo Rodrigues Sartori\",\"Helioswilton Sales-Campos\",\"Joao Herminio Martins da Silva\",\"Marcelle Silva-Sales\",\"Pedro Henrique dos Santos Dantas\",\"Sandeep Tiwari\",\"Siomar de Castro Soares\",\"Thais Cristina Vilela Rodrigues\",\"Vasco Ariston de Carvalho Azevedo\"}',\n",
       "       '{\"Bianca Cechetto Carlos\",\"Fernanda J. Cabral\",\"Gerhard Wunderlich\",\"Luciana G. Vianna\",\"Luiz Hildebrando P. da Silva\",\"Marcia M. Medeiros\",\"Nadia Maria Silva\",\"Rodrigo G. Stabeli\",\"Rosimeire D. Martha\"}',\n",
       "       '{\"Ana Angelica Romeiro Cardoso\",\"Maria Dinara de Araujo Nogueira\",\"Maria Raquel da Silva Lima\",\"Paula Matias Soares\",\"Rafaela Dantas Gomes\",\"Rosangela Gomes dos Santos\"}',\n",
       "       '{\"Alexandre D. Costa\",\"Artur Santos-Miranda\",\"Catherine Ropert\",\"Danilo Roman-Campos\",\"Diego Santos Souza\",\"Jader S. Cruz\",\"Julliane Joviano-Santos\",\"Policarpo Sales-Junior\"}',\n",
       "       '{\"Barreto, Ivana Cristina de Holanda\",\"Esteche, Frederico Fernando\",\"Ferreira, Marcelo José Monteiro\",\"Fiuza, Tatiana Monteiro\",\"Montenegro Junior, Renan Magalhães\",\"Rebouças, Barbarah Nogueira\",\"Ribeiro, Marco Túlio Aguiar Mourão\",\"Sousa, Geziel dos Santos de\"}',\n",
       "       '{\"Aime Oliveira\",\"Felipe O. S. Santos\",\"Helena Eri Shimizu\",\"Ivana C. H. C. Barreto\",\"Joao Paulo Alves Oliveira\",\"Joselia Souza Trindade\",\"Leonor Maria Pacheco Santos\",\"Poliana Araujo Palmeira\",\"Vanira Matos Pessoa\",\"Wallace Santos\",\"Yamila Comes\"}',\n",
       "       '{\"Adriana Andrade Carvalho\",\"Ana Cristina lima Leite\",\"Claudia Pessoa\",\"Daniel de Araujo Viana\",\"Francisco Vagnaldo Fechine-Jamacaru\",\"Gevanio Bezerra de Oliveira Filho\",\"Manoel Odorico de Moraes\",\"Marcilia Pinheiro da Costa\",\"Marcos Verissimo de Oliveira Cardoso\",\"Patricia Marcal da Costa\",\"Paulo Michel Pinheiro Ferreira\",\"Suellen Melo Tiburcio Cavalcanti\"}',\n",
       "       '{\"Andrea Grava\",\"Luis Andre Mariuba\",\"Marcia Medeiros\",\"Patricia Puccinelli Orlandi\",\"Paulo Afonso Nogueira\",\"Rudson Holanda\"}',\n",
       "       '{\"Dalma Maria Banic\",\"João Hermínio Martins da Silva\",\"Joseli de Oliveira Ferreira\",\"Josué da Costa lima Junior\",\"Rodrigo Nunes Rodrigues da Silva\"}',\n",
       "       '{\"Alberto Moreno\",\"Balwan Singh\",\"Dalma Maria Banic\",\"Esmeralda V. S. Meyer\",\"FÃ¡tima Santos\",\"Jianlin Jiang\",\"JoÃ£o HermÃ\\xadnio Martins Da Silva\",\"Joseli de Oliveira Ferreira\",\"JosuÃ© Da Costa Lima\",\"Mary R. Galinski\",\"Rodrigo Nunes Rodrigues-Da-silva\"}',\n",
       "       '{\"Ana Carolina Guimaraes\",\"Joao Herminio Martins da Silva\",\"Laurent Dardenne\",\"Luiz Phillippe R. Baptista\",\"Marcelo Alves Ferreira\",\"Vanessa de V. C. Sinatti\"}',\n",
       "       '{\"Ernesto Raul Caffarena\",\"Flavia Calmon-Hamaty\",\"Joao H. M. da Silva\",\"Michael Hahne\",\"Wilson Savino\"}',\n",
       "       '{\"Alexandre Magno Rodrigues Teixeira\",\"Carla Freire Celedonio Fernandes\",\"Emanuelle Machado Marinho\",\"Emmanuel Silva Marinho\",\"Francisco Wagner Q. Almeida-Neto\",\"Helcio Silva dos Santos\",\"Marcia Machado Marinho\",\"Maria Geysillene Castro Matos\",\"Paulo Nogueira Bandeira\",\"Pedro de Lima-Neto\",\"Ramon Roseo Paula Pessoa Bezerra de Menezes\",\"Tiago lima Sampaio\"}',\n",
       "       '{\"Emanuel Pereira Silva\",\"Fillipe de Oliveira Pereira\",\"Gabriela Ribeiro de Sousa\",\"Jailton de Souza-Ferrari\",\"Jaime Ribeiro Filho\",\"Jose Maria Barbosa-Filho\",\"Juliana Moura-Mendes\",\"Marcelo Antonio Nobrega da Rocha\",\"Risley Nikael Medeiros Silva\"}',\n",
       "       '{\"Amanda K. Sousa\",\"Ana Luíza A. R. Martin\",\"Diogo T. Carvalho\",\"Fernando G. Figueredo\",\"Francisco A. V. dos Santos\",\"Henrique D. M. Coutinho\",\"Irwin R. A. de Menezes\",\"Jaime Ribeiro Filho\",\"Marta M. F. Fonteles\",\"Pablo A. M. Farias\",\"Thiago S. Freitas\"}',\n",
       "       '{\"Claudia Pessoa\",\"Everton Jose Ferreira de Araujo\",\"Fernando Aecio de Amorim Carvalho\",\"Francisco das Chagas Alves Lima\",\"Layana Karine Farias Lima\",\"Luis Mario Rezende Junior\",\"Oskar Almeida Silva\",\"Paulo Michel Pinheiro Ferreira\",\"Rivelilson Mendes de Freitas\",\"Stanley Juan Chavez Gutierrez\"}',\n",
       "       '{\"Fernanda Otaviano Martins\",\"Luciana Borges Retamoso\",\"Maria Teresa Villela Romanos\",\"Matheus Melo Pithon\",\"Orlando Motohiro Tanaka\",\"RogÃ©rio Lacerda dos Santos\",\"TaÃ\\xads de Morais Alves da Cunha\"}',\n",
       "       '{\"Anita O. B. P. B. Martins\",\"Bonglee Kim\",\"Fabiolla R. S. Passos\",\"Henrique Douglas M. Coutinho\",\"Irwin Rose Alencar de Menezes\",\"Isabel S. Alc Antara\",\"Jackson Roberto G. S. Almeida\",\"Jaime Ribeiro Filho\",\"Lindaiane B. R. Dantas\",\"Lucindo J. Quintans-Junior\",\"Maria Rayane C. de Oliveira\",\"Natalia Cruz-Martins\",\"S. Cicero Pedro\",\"Ticiano M. Dantas\"}',\n",
       "       '{\"Amanda Campelo lima de Melo\",\"Fernanda Montenegro de Carvalho Araujo\",\"Germana Silva Vasconcelos\",\"Ludmilla Freire Caetano\",\"Marcela Helena Gambim Fonseca\",\"Maria da Conceicao Rodrigues Fernandes\",\"Tamires Cardoso Matsui\"}',\n",
       "       '{\"Ana PatrÃ\\xadcia Pereira Morais\",\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Isabella Lima Barbosa Campelo\",\"JosÃ© Maria Ximenes GuimarÃ£es\",\"Maria de FÃ¡tima Antero Sousa Machado\",\"Neiva Francenely Cunha Vieira\",\"Paula Sacha Frota Nogueira\",\"Roberto Wagner JÃºnior Freire de Freitas\",\"SharmÃªnia de AraÃºjo Soares Nuto\"}',\n",
       "       '{\"Ana Karina de Sousa Gadelha\",\"Ivana Cristina de Holanda Cunha Barreto\"}',\n",
       "       '{\"Ana Ester Maria Melo Moreira\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Kelen Gomes Ribeiro\",\"Luiz Odorico Monteiro de Andrade\",\"Maria Socorro de Araujo Dias\",\"Neusa Goya\"}',\n",
       "       '{\"Daniel Andrade\",\"Flavio Cardoso\",\"Francisco G.S. Da Silva\",\"Ivana Cristina De Holanda Cunha Barreto\",\"Jose Neuman\",\"Luiz Odorico Monteiro Andrade\",\"Luzia Lucelia Saraiva Ribeiro\",\"Mauro Oliveira\",\"Raimundo Valter\",\"Samuel Albuquerque\",\"William Vitorino\"}',\n",
       "       '{\"Maximiliano Loiola Ponte de Souza\",\"Roberto Wagner Júnior Freire de Freitas\"}',\n",
       "       '{\"FlÃ¡via Garcia De Carvalho\",\"Inesita Soares De Araujo\",\"Marcelo SimÃ£o De Vasconcellos\"}',\n",
       "       '{\"Ana Ester Maria Melo Moreira\",\"Francisca Alanny AraÃºjo Rocha\",\"Ivana Cristina de Holanda Cunha Barreto\"}',\n",
       "       '{\"Araújo, Márcio Flávio Moura de\",\"Campos, Regina Kelly Guimarães Gomes\",\"Fernandes, Andrea Rodriguez Lannes\",\"Ferreira, Adriana Gomes Nogueira\",\"Lima, Francisca Elisângela Texeira\",\"Mesquita, Kirley Kethellen Batista\",\"Pinheiro, Patrícia Neyva da Costa\",\"Santos, Miguel Henrique da Silva dos\"}',\n",
       "       '{\"Cicera Datiane de Morais Oliveira-Tintino\",\"Henrique Douglas Melo Coutinho\",\"Janaina Esmeraldo Rocha\",\"Joao Pedro Viana Rodrigues\",\"Jose Geraldo de Alencar Santos Junior\",\"Priscila Ramos Freitas\",\"Raimundo Luiz Silva Pereira\",\"Roberto Nicolete\",\"Vanessa Pinheiro Goncalves\"}',\n",
       "       '{\"Agnes Magri\",\"Cassamo Ussemane Mussagy\"}',\n",
       "       '{\"Aline Albuquerque\",\"Andrielly Santos-Costa\",\"Disraeli Vasconcelos\",\"Geraldo Rodrigues Sartori\",\"Joao Herminio Martins da Silva\",\"Luca Andrade\",\"Wilson Savino\"}',\n",
       "       '{\"Andre Machado Siqueira\",\"Daniele Rocha Queiroz Lemos\",\"Fabio Miyajima\",\"Francisca Kalline de Almeida Barreto\",\"Luciano Pamplona de goes Cavalcanti\",\"sara Mendes D\\'angelo\"}',\n",
       "       '{\"Ivana Cristina de Holanda Cunha Barreto\",\"Sharmênia de Araújo Soares Nuto\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Brune Marjorie Dias Frota Carvalho\",\"Camila Pontes Feijao\",\"George Taccio de Miranda Candeiro\",\"Giulio Gavini\",\"Marco Antonio Hungaro Duarte\",\"Rodrigo Ricci Vivan\"}',\n",
       "       '{\"GeÃ³rgia AlcÃ¢ntara Alencar Melo\",\"Joselany Ã\\x81fio Caetano\",\"Maria Alzete de Lima\",\"Maria de FÃ¡tima Antero Sousa Machado\",\"Nelson Miguel Galindo Neto\",\"Renan Alves Silva\"}',\n",
       "       '{\"Benjamin R. Green\",\"Cameron P. Simmons\",\"Fernando Braga Stehling Dias\",\"Guilherme Costa\",\"Jacqui Montgomery\",\"Joao Silveira Moledo Gesto\",\"Julia Peixoto\",\"Katherine L. Anders\",\"Luciano Andrade Moreira\",\"peter A. Ryan\",\"Scott L. O\\'neill\",\"Simon Kutcher\",\"Sofia B. Pinto\"}',\n",
       "       '{\"Clara M. G. Lima\",\"Debora L. da Silva\",\"Henrique D. M. Coutinho\",\"Irwin R. A. de Menezes\",\"Ivonea S. do Nascimento\",\"Josiane F. da Silva\",\"Leticia A. Goncalves\",\"Mayeen U. Khandaker\",\"Mohammad R. I. Faruque\",\"Rafael da C. I. Fontan\",\"Renata F. Santana\",\"Sarah de O. Rodrigues\",\"Silvani Verruck\",\"Talha bin Emran\",\"Waseem Khalid\"}',\n",
       "       '{\"Izaltina Silva-Jardim\",\"Neuza B. Barros\",\"Pietro Ciancaglini\",\"Roberto Nicolete\",\"Rodrigo G. Stabeli\",\"Valdir A. Facundo\",\"Vanessa Migliaccio\"}',\n",
       "       '{\"Ana Carolina Justino de AraÃºjo\",\"CÃ\\xadcera Datiane de Morais Oliveira-Tintino\",\"Henrique Douglas Melo Coutinho\",\"JoÃ£o Pedro Viana Rodrigues\",\"JosÃ© Bezerra de AraÃºjo Neto\",\"JosÃ© Geraldo de Alencar Santos JÃºnior\",\"Maria Milene Costa da Silva\",\"Pedro Everson Alexandre de Aquino\",\"Raimundo Luiz Silva Pereira\",\"Roberto Nicolete\",\"Vanessa Pinheiro GonÃ§alves Ferreira\"}',\n",
       "       '{\"Augusto C.A. Oliveira\",\"Claudia Pessoa\",\"Daniel P. Pinheiro\",\"Durcilene A. da Silva\",\"EufrÃ¢nio N. da Silva JÃºnior\",\"FÃ¡bio O.S. Ribeiro\",\"FÃ¡tima C.E. Oliveira\",\"Guilherme Zocolo\",\"Luciana V. RebouÃ§as\",\"MarcÃ\\xadlia P. Costa\",\"Marcia S. Rizzo\",\"Maria Francilene S. Silva\",\"Renata G. Almeida\",\"Roberto Nicolete\",\"Vanessa Pinheiro G. Ferreira\"}',\n",
       "       '{\"Andreimar Martins Soares\",\"Fernando Berton Zanchi\",\"Roberto Nicolete\"}',\n",
       "       '{\"Danielle Crawshaw\",\"Jose Luis Passos Cordeiro\",\"Jose M. V. Fragoso\",\"Luiz Flamarion B. Oliveira\"}',\n",
       "       '{\"Camila Nayane de Carvalho Lima\",\"Claudio Costa dos Santos\",\"Danielle Macedo\",\"David F. de Lucena\",\"Deiziane Viana da Silva Costa\",\"Fabio Miyajima\",\"Francisca Clea F. de Sousa\",\"Francisca Taciana Sousa Rodrigues\",\"Francisco Eliclecio Rodrigues da Silva\",\"Joao Quevedo\",\"Marcos Romario Matos de Souza\",\"Michael Maes\",\"Silvania Maria Mendes Vasconcelos\",\"Tatiana Barichello\"}',\n",
       "       '{\"Ademir Jesus Martins\",\"Ary A. Hoffmann\",\"Daniel Antunes Maciel Villela\",\"Fernando B. S. Dias\",\"Gabriel Sylvestre\",\"Gabriela de Azambuja Garcia\",\"Gordana RaÅ¡iÄ\\x87\",\"Guilherme Borges da Costa\",\"JosÃ© Bento Pereira Lima\",\"Luciano A. Moreira\",\"Marion F. Shadbolt\",\"Martha T. Petersen\",\"Rafael Maciel-de-Freitas\",\"Raquel Aguiar\",\"Ricardo LourenÃ§o-de-Oliveira\",\"Scott L. O\\'Neill\",\"Yi Dong\"}',\n",
       "       '{\"Antonio Leonel de Lima JÃºnior\",\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Bruno Souza Benevides\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Maria Vieira de Lima Saintrain\",\"Roberto Ribeiro MaranhÃ£o\",\"SharmÃªnia de AraÃºjo Soares Nuto\"}',\n",
       "       '{\"Benedito Medrado\",\"Jorge Lyra\"}',\n",
       "       '{\"Eliany Nazare Oliveira\",\"Erika Vanessa Serejo Costa\",\"Francisco Rosemiro Guimaraes Ximenes Neto\",\"Jardel Alcantara Negreiros\",\"Marta Celia Cunha\",\"Marta Evelin de Carvalho\"}',\n",
       "       '{\"Andrea Pereira da Silva\",\"Jose Claudio Garcia Lira Neto\",\"Marcio Flavio Moura de Araujo\",\"Marta Maria Coelho Damasceno\",\"Mauricio Batista Paes Landim\",\"Roberto Wagner Junior Freire de Freitas\"}',\n",
       "       '{\"Caio B. Castro\",\"Claudia do O. Pessoa\",\"Diogo Denardi Porto\",\"Edy Sousa de Brito\",\"Elenilson de Godoy Alves Filho\",\"Guilherme Juliao Zocolo\",\"Helena Becker\",\"Kirley Marques Canuto\",\"Licia dos Reis Luz\",\"Maria Francilene S. Silva\"}',\n",
       "       '{\"Delane Viana Gondim\",\"Fabio Miyajima\",\"Jonas Nogueira Ferreira Maciel GusmÃ£o\",\"Karuza Maria Alves Pereira\",\"Lorena Vasconcelos Vieira\",\"Luane Macedo de Sousa\",\"Paula Goes\",\"Thays Allane Cordeiro Maia\"}',\n",
       "       '{\"Aline L. de P. Evangelista\",\"Ismayle S. Santos\",\"Ivana Cristina de H. C. Barreto\",\"Joseane O. Paiva\",\"Luiz Odorico M. de Andrade\",\"Paulo Duarte\",\"Pedro Almir M. de Oliveira\",\"Rebecca L. Theophilo\",\"Rossana M. C. Andrade\"}',\n",
       "       '{\"Caetano Souto-Maior\",\"Fernando Braga Stehling Dias\",\"Gabriel Sylvestre\",\"M. Gabriela M. Gomes\",\"Rafael Maciel-de-Freitas\"}',\n",
       "       '{\"Adriano Abbud\",\"Andre Luiz de Menezes\",\"Carlos Eduardo Calzavara-Silva\",\"Cristina Mendes de Oliveira\",\"Elisa Cavalcante Pereira\",\"Eneida de Oliveira\",\"Fabio Miyajima\",\"Fernanda Marques Godinho\",\"Fernando Stehling Dias\",\"Gabriel da Rocha Fernandes\",\"Gabriel Luz Wallau\",\"Ighor Arantes Gomes\",\"Irina Riediger\",\"Maria do Carmo Debur\",\"Marilda Mendonca Siqueira\",\"Paola Cristina Resende\",\"Pedro Alves\",\"Regina Bones Barcellos\",\"Richard Steiner Salvato\",\"Rodrigo Ribeiro-Rodrigues\",\"Rubens do Monte-Neto\",\"Tatiana Schaeffer Gregianini\",\"Thais de Souza Silva\"}',\n",
       "       '{\"Ã\\x8dsis V. Biembengut\",\"Marcos R. Lourenzoni\",\"Natalia F. Frota\",\"PatrÃ\\xadcia Shigunov\",\"Tatiana A. C. B. de Souza\"}',\n",
       "       '{\"Ana Virginia Frota Guimaraes\",\"Marcos Roberto Lourenzoni\",\"Natalia Fernandes Frota\"}',\n",
       "       '{\"Alexander L. Perryman\",\"Carolina Horta Andrade\",\"Joao H. Martins da Silva\",\"Melina Mottin\",\"Rodolpho C. Braga\",\"Roosevelt A. da Silva\",\"sean Ekins\"}',\n",
       "       '{\"Jesem Douglas Yamall Orellana\",\"Maximiliano Loiola Ponte de Souza\",\"Paulo Cesar Basta\"}',\n",
       "       '{\"Maximiliano Loiola Ponte de Souza\"}',\n",
       "       '{\"Augusto Cesar Aragao Oliveira\",\"Claudia Pessoa\",\"Felipe A. R. Rodrigues\",\"Laura Nogueira de Faria Cardoso\",\"Marcus Vinicius Nora de Souza\",\"Maria Claudia dos Santos Luciano\",\"Thais Cristina Mendonca Nogueira\"}',\n",
       "       '{\"Alan R. Clarke\",\"Cleberson J. S. Queiroz\",\"D. Mark Pritchard\",\"Dale Vimalachandran\",\"Fabio Miyajima\",\"Fei Song\",\"John R. Jenkins\",\"karen R. Reed\",\"Nadeem Al-Khafaji\"}',\n",
       "       '{\"Bruno C. Cavalcanti\",\"Claudia C. Gatto\",\"Claudia Pessoa\",\"Divya K. Nair\",\"Eufranio N. da Silva Junior\",\"Guilherme A. M. Jardim\",\"Irishi N. N. Namboothiri\",\"Kaio M. de Farias\",\"Maria do Carmo F. R. Pinto\",\"Tiago T. Guimaraes\"}',\n",
       "       '{\"Vanira Matos Pessoa\"}',\n",
       "       '{\"Ana Beatriz Lopes de Souza\",\"Barbara Oliveira Baptista\",\"Cesare Bianco-Junior\",\"Claudio Tadeu Daniel-Ribeiro\",\"Evelyn Kety Pratt Riccio\",\"Joao Herminio Martins da Silva\",\"Josue Costa lima Junior\",\"Lilian Rose Pratt-Riccio\",\"Linda Eva Amoah\",\"Marcelo Ribeiro-Alves\",\"Michael Theisen\",\"Paulo Renato Rivas Totino\",\"Rodrigo Medeiros Souza\",\"Susheel Kumar Singh\"}',\n",
       "       '{\"Ã\\x89rika Paula Castro\",\"Ã\\x81ureo Banhos dos Santos\",\"Adriana Bocchiglieri\",\"Adriana Loeser dos Santos Barbosa\",\"Adriano Garcia Chiarello\",\"Adriano Pereira Paglia\",\"Adriele Aparecida Pereira\",\"Adryelle Francisca de Souza Moreira\",\"Agnis Cristiane de Souza\",\"Aiesca Pellegrin\",\"Ailin Gatica\",\"Akyllan Zoppi Medeiro\",\"Alan Deivid Pereira\",\"Alan Gerhardt Braz\",\"Alberto Yanosky\",\"Alejandro Eduardo Jorge Valenzuela\",\"Alessandra Bertassoni\",\"Alessandra dos Santos Venturini do Prado\",\"Alessandra Ferreira Dales Nava\",\"Alessandro Rocha\",\"Alex Augusto Abreu Bovo\",\"Alex Bager\",\"Alexandra Cravino\",\"Alexandra dos Santos Pires\",\"Alexandre Camargo Martensen\",\"Alexandre Filippini\",\"Alexandre Reis Percequillo\",\"Alexandre Vogliotti\",\"Alexsander Zamorano Antunes\",\"Aline Cristina Leite de Oliveira\",\"Allan Jefferson da Silva de Oliveira\",\"Allison Devlin\",\"Almir de Paula\",\"Aluane Silva Ferreira\",\"Alvaro GarcÃ\\xada-Olaechea\",\"Amadeo SÃ¡nchez\",\"Amanda Subalusky\",\"Amane PaldÃªs GonÃ§ales\",\"Ana Carla Medeiros Morato de Aquino\",\"Ana Carolina Srbek-Araujo\",\"Ana Caroline L. AraÃºjo\",\"Ana Cecilia Gozzi\",\"Ana Cecilia Ochoa\",\"Ana Cristina Mendes de Oliveira\",\"Ana Cristyna Reis Lacerda\",\"Ana Karina Francisco\",\"Ana Maria de Oliveira Paschoal\",\"Ana Paula Nascimento Gomes\",\"Ana Paula Potrich\",\"Ana Priscila Medeiros OlÃ\\xadmpio\",\"Ana Rojas\",\"Ana Yoko Ykeuti Meiga\",\"Anah Tereza de Almeida JÃ¡como\",\"Analice Maria CalaÃ§a\",\"Anderson FeijÃ³\",\"Anderson Pagoto\",\"AndrÃ© Borja Miranda\",\"AndrÃ© Chein Alonso\",\"AndrÃ© Felipe Barreto-Lima\",\"AndrÃ© LuÃ\\xads Luza\",\"AndrÃ© Restel Camilo\",\"AndrÃ© Tavares\",\"AndrÃ© Valle Nunes\",\"AndrÃ©s de Miguel\",\"Andre Lanna\",\"Andreas Kindel\",\"Andressa Gatti\",\"Andrezza Bellotto Nobre\",\"Anielise da ConceiÃ§Ã£o CampÃªlo\",\"Anna Carolina Figueiredo de Albuquerque\",\"Antonio de la Torre\",\"Antonio Mangione\",\"Antonio Rossano Mendes Pontes\",\"Ariel Guilherme Santos do Nascimento\",\"Arlei Marcili\",\"Arthur Soares Fernandes\",\"Artur Luiz de Almeida Felicio\",\"Atilla Colombo Ferreguetti\",\"Augusto JoÃ£o Piratelli\",\"Beatris Felipe Rosa\",\"Beatriz Azevedo Cezila\",\"Benoit de Thoisy\",\"Bianca Cruz Morais\",\"Bianca Ingberman\",\"Bianca KÃ¶hler\",\"Bibiana GÃ³mez-Valencia\",\"Bruna Bertagni de Camargo\",\"Bruna M. Bezerra\",\"Bruna Tamasauskas\",\"Bruno A. T. Parahyba Campos\",\"Bruno Busnello Kubiak\",\"Bruno Henrique Saranholi\",\"Bruno K. Nakagawa\",\"Bruno Pereira Leles\",\"Bruno R. Ribeiro\",\"Burton K. Lim\",\"CÃ¡ssia Yumi Ikuta\",\"Calebe Pereira Mendes\",\"Camila Alvez Islas\",\"Camila Aoki\",\"Camila Cantagallo Devids\",\"Camila Figueiredo\",\"Camila Matias Goes de Abreu\",\"Camila Raquel Silva Oliveira\",\"Camila Righetto Cassano\",\"Camile Lugarini\",\"Carin Caputo\",\"Carla Cristina Gestich\",\"Carla Denise Tedesco\",\"Carla Fabiane de Vera y Conde\",\"Carla Grasiele Zanin Hegel\",\"Carlos Benhur Kasper\",\"Carlos De Angelo\",\"Carlos E. V. Grelle\",\"Carlos Eduardo Fragoso\",\"Carlos Eduardo Lustosa EsbÃ©rard\",\"Carlos Eduardo Verona\",\"Carlos Frederico Duarte Rocha\",\"Carlos Henrique Salvador\",\"Carlos Leonardo Vieira\",\"Carlos Roberto AbrahÃ£o\",\"Carlos Rodrigo Brocardo\",\"Carolline Zatta Fieker\",\"Caryne Braga\",\"Catalina SÃ¡nchez Lalinde\",\"CecÃ\\xadlia Bueno\",\"CecÃ\\xadlia LicariÃ£o Barreto Luna\",\"Cesar Cestari\",\"Christine Del Vechio Koike\",\"Christoph Knogge\",\"Christopher Brian Anderson\",\"Cindy M. Hurtado\",\"Cintia Ferreira Antunes de Oliveira\",\"Cintia Tellaeche\",\"Clarice Silva CesÃ¡rio\",\"Clarissa Alves da Rosa\",\"Claudia GuimarÃ£es Costa\",\"Claudia Zukeran Kanda\",\"Cristiana SimÃ£o Seixas\",\"Cristiano TrapÃ© Trinca\",\"Cristina F. LÃ³pez-Fuerte\",\"Cristina Jaques da Cunha\",\"Cynthia Doutel Ribas\",\"Cyntia Cavalcante Santos\",\"Daiane Buscariol\",\"Daiane Carreira\",\"Daiane Chaves do Nascimento\",\"Danianderson Rodrigues Carvalho\",\"Daniel da Silva Ferraz\",\"Daniel Galiano\",\"Daniel Henrique Homem\",\"Daniel JesÃºs-Espinosa\",\"Daniela A. S. BÃ´lla\",\"Daniele Janina Moreno\",\"Danielle de Oliveira Moreira\",\"Danielle Leal Ramos\",\"Danilo Angelucci de Amorim\",\"Darci Moraes Barros-Battesti\",\"Davi Castro Tavares\",\"David Echeverri Lopez\",\"David M. Post\",\"Dayvid Rodrigues Couto\",\"Dennis Nogarolli PatrocÃ\\xadnio\",\"Diana LetÃ\\xadcia Kruger Pacheco Carvalho\",\"Diego Afonso Silva\",\"Diego CÃ³rdoba\",\"Diego Queirolo\",\"Diego Varela\",\"Dilmar Alberto Goncalves de Oliveira\",\"Diogo Cavenague Casanova\",\"Douglas de Matos Dias\",\"Douglas Machado da Silva\",\"Eder Barbier\",\"Edgar Federico Rivadeneira\",\"Eduardo Alexandrino\",\"Eduardo Carrano\",\"Eduardo Marques Santos\",\"Eduardo Martins Venticinque\",\"Edwin HernÃ¡ndez-PÃ©rez\",\"Egberto da Fonseca Casazza\",\"Elizabeth P. Anderson\",\"Elmary da Costa Fraga\",\"Elson Fernandes de Lima\",\"Elvira D\\'Bastiani\",\"Emerson Monteiro Vieira\",\"Emiliano Guijosa-Guadarrama\",\"Enrique M. GonzÃ¡lez\",\"Erica Vanessa Maggiorini\",\"Erick Francisco Silva de Aguiar\",\"Erik Daniel MartÃ\\xadnez-Nambo\",\"Erika de la PeÃ±a-CuÃ©llar\",\"Ezequiel PedÃ³\",\"FÃ¡bio de Oliveira Roque\",\"FabÃ\\xadola Keesen Ferreira\",\"Fabiana Cristina S. Alves de Melo\",\"Fabiana Lopes Rocha\",\"Fabiana Luques Fonseca\",\"Fabiane Girardi\",\"Fabiano Rodrigues de Melo\",\"Felipe Bortolotto Peters\",\"Felipe Moreli Fantacini\",\"Felipe Pedrosa\",\"Felipe Pessoa da Silva\",\"Felipe VÃ©lez-GarcÃ\\xada\",\"Fernanda Cavalcanti de Azevedo\",\"Fernanda D. Abra\",\"Fernanda Guedes da Silva\",\"Fernanda Maria Neri\",\"Fernanda Zimmermann Teixeira\",\"Fernando Antonio dos Santos Fernandez\",\"Fernando Carvalho\",\"Fernando de Castro Jacinavicius\",\"Fernando Ferreira\",\"Fernando Ferreira de Pinho\",\"Fernando GonÃ§alves\",\"Fernando Henrique Puertas\",\"Fernando Ibanez Martins\",\"Fernando Lima\",\"Fernando M. Contreras-Moreno\",\"Fernando SilvÃ©rio Ribeiro\",\"Fernando Tortato\",\"Fernandode Camargo Passos\",\"Filipe M. Patel\",\"FlÃ¡via Pereira Tirelli\",\"FlÃ¡vio Henrique GuimarÃ£es Rodrigues\",\"FlÃ¡vio Kulaif Ubaid\",\"Flavia Caruso\",\"Francesca Belem Lopes Palmeira\",\"Francisco Grotta Neto\",\"Francisco Homem Gabriel\",\"Franco Leandro de Souza\",\"Francys E. da Veiga da Costa\",\"Frederico Gemesio Lemos\",\"Gabriel Ferreira Vianna Di Panigai\",\"Gabriel Lima de Aguiar\",\"Gabriel S. Magezi\",\"Gabriel Selbach Hofmann\",\"Gabriela Heliodoro\",\"Gabriela Rosa Graviola\",\"Gabriela Schuck\",\"Gabriela Teixeira Duarte\",\"Gabrielle Beca\",\"Gabrielle Ribeiro de Andrade\",\"Geovana Linhares de Oliveira\",\"GermÃ¡n JimÃ©nez Romero\",\"Geruza Leal Melo\",\"Geverson Luiz Dierings\",\"Gilberto Sabino-Santos\",\"Gindomar Gomes Santana\",\"Giordano Ciocheti\",\"Gisele Lamberti Zanirato\",\"Gisele Lessa\",\"Giselle Bastos Alves\",\"Graziele Oliveira Batista\",\"Greici Maia Behling\",\"Guilherme Braga Ferreira\",\"Guilherme Casoni da Rocha\",\"Guilherme MourÃ£o\",\"Gustavo A. Maras\",\"Gustavo Alves da Costa Toledo\",\"Gustavo Gonsioroski\",\"Gustavo R. Canale\",\"Harley SebastiÃ£o\",\"Helena Alves do Prado\",\"Helena de Godoy Bergallo\",\"Helio Kinast Cruz Secco\",\"Henrique Llacer Roig\",\"Henrique RajÃ£o\",\"Henrique Santiago Alberto Carlos\",\"Herbert de Oliveira B. Duarte\",\"Hiago Ermenegildo\",\"Hilda FÃ¡tima de Jesus Pena\",\"Hilton Entringer JÃºnior\",\"HipÃ³lito Ferreira Paulino Neto\",\"Hudson de Macedo Lemos\",\"Hugo del Castillo\",\"Hugo Fernandes-Ferreira\",\"Hugo Ignacio CoitiÃ±o Banquero\",\"Ignacio Roesler\",\"Igor Kintopp Ribeiro\",\"Igor Oliveira\",\"Igor Pfeifer Coelho\",\"Ingrid M. S. Lima\",\"Isabel Muniz Bechara\",\"Isabel Salgueiro Lermen\",\"Isac Mella MÃ©ndez\",\"Isadora Beraldi Esperandio\",\"Ita de Oliveria Silva\",\"Italo Mourthe\",\"ItiberÃª Piaia Bernardi\",\"JÃ©ssica AbonÃ\\xadzio Gouvea\",\"JÃ©ssica Caroline de Faria FalcÃ£o\",\"JÃ©ssica Paloma Ferreira\",\"Jacqueline R. Miller\",\"Jader Marinho-Filho\",\"Jairo JosÃ© Zocche\",\"James Charles Russell\",\"JÃºlia Emi de Faria Oshima\",\"JÃºlio CÃ©sar Bicca-Marques\",\"Jardel BrandÃ£o Seibert\",\"Javier de la Maza\",\"Javier Hinojosa\",\"Jean Carlos Ramos Silva\",\"Jean Pierre Santos\",\"Jean R. S. Vitule\",\"Jeffrey J. Thompson\",\"Jessica Castro-Prieto\",\"Jimmy Pincheira-Ulbrich\",\"JoÃ£o Carlos Zecchini Gebin\",\"JoÃ£o Gabriel Ribeiro Giovanelli\",\"JoÃ£o M. D. Miranda\",\"JoÃ£o Pedro Souza-Alves\",\"JoÃ£o Rafael Gomes de Almeida Marins\",\"Joana Zorzal Nodari\",\"Jociel Ferreira Costa\",\"Jonas Sponchiado\",\"Jonathas Linds de Souza\",\"Jorge Alberto Gallo\",\"Jorge JosÃ© Cherem\",\"JosÃ© LuÃ\\xads Passos Cordeiro\",\"JosÃ© MaurÃ\\xadcio Barbanti Duarte\",\"JosÃ© Oliveira Dantas\",\"JosÃ© Roberto de Matos\",\"JosÃ© Salatiel Rodrigues Pires\",\"JosÃ© Soares Ferreira Neto\",\"Juan AndrÃ©s MartÃ\\xadnez Lanfranco\",\"Juan Camilo de la Cruz Godoy\",\"Juan Carlos Rudolf\",\"Juan Felipe ReÃ¡tiga Parrish\",\"Juan Francisco Tellarini\",\"Juan L. PeÃ±a-MondragÃ³n\",\"Juan Pablo Arrabal\",\"Juan Reppucci\",\"Juan Ruiz-Esparza\",\"Julia Beduschi\",\"Juliana Fernandes Ribeiro\",\"Juliana Monteiro de Almeida Rocha\",\"Juliana Rodrigues Ferreira\",\"Juliana Silveira dos Santos\",\"Juliane Pereira-Ribeiro\",\"Juliani Bruna Zanoni\",\"Juliano AndrÃ© Bogoni\",\"Julio Javier ChacÃ³n Pacheco\",\"KÃ¡tia Regina Pisciotta\",\"Karl-Ludwig Schuchmann\",\"Karlo GregÃ³rio Guidoni-Martins\",\"Kathrin Burs\",\"Katia Maria Paschoaletto Micchi de Barros Ferraz\",\"Katyucha Von Kossel de Andrade Silva\",\"Keila MacFadem Juarez\",\"Keynes de la Cruz-FÃ©lix\",\"Kimberly Danielle Rodrigues de Morais\",\"Lana PavÃ£o CandelÃ¡ria\",\"Larissa Fornitano\",\"Larissa Lynn Bailey\",\"Larissa Oliveira GonÃ§alves\",\"Laura Fasola\",\"Laura Johanna Nova LeÃ³n\",\"Layla Reis de Andrade\",\"Leandro de Oliveira Marques\",\"Leandro Jerusalinsky\",\"Leandro Macedo\",\"Leandro Santana Moreira\",\"Leandro Silveira\",\"Leonardo de Carvalho Oliveira\",\"Leonardo Henrique da Silva\",\"Leonardo La Serra\",\"Leonardo Marques Costa\",\"Leonardo Rodrigues Sartorello\",\"Leticia Prado Munhoes\",\"Liany Regina B. Oliveira-Silva\",\"Ligia Ferracine de Pina\",\"Lilian Bonjorne\",\"Lilian Elaine Rampim\",\"Lilian P. Sales\",\"Liliani Marilia Tiepolo\",\"Lina Marcela GarcÃ\\xada Loaiza\",\"LucÃ\\xada InÃ©s RodrÃ\\xadguez-Planes\",\"LucÃ\\xada MartÃ\\xadn\",\"Lucas GonÃ§alves da Silva\",\"Lucas Lacerda Toth Quintilham\",\"Lucas Neves Perillo\",\"Luciana Souza AraÃºjo\",\"Luciana Zago Silva\",\"Luciano Carramaschi de AlagÃ£o Querido\",\"Luciano Ferreira da Silva\",\"Luciano Francisco La Sala\",\"Luciano Tessare Bopp\",\"Ludmila Hufnagel\",\"Luiz Flamarion Barbosa de Oliveira\",\"Luiz Gustavo Rodrigues Oliveira-Santos\",\"Luiz Henrique Lyra\",\"Luiza Neves GuimarÃ£es\",\"Luz Fernanda Jimenez Segura\",\"Luziene ConceiÃ§Ã£o de Sousa\",\"Lydia MÃ¶cklinghoff\",\"M. Laura GuichÃ³n\",\"M. Noelia Barrios-Garcia\",\"MÃ¡rcio Leite de Oliveira\",\"MÃ¡rio LuÃ\\xads Orsi\",\"MÃ´nica Andrade da Silva\",\"MaÃ\\xadsa Ziviani Alves Martins\",\"Magnus Machado Severo\",\"MarÃ\\xada Eugenia Iezzi\",\"MarÃ\\xada JosÃ© Andrade-NÃºÃ±ez\",\"MarÃ\\xadlia A. S. Barros\",\"Marcela Alvares Oliveira\",\"Marcela FiguerÃªdo Duarte Moraes\",\"Marcela GuimarÃ£es Moreira Lima\",\"Marcell Soares Pinheiro\",\"Marcella do Carmo PÃ´nzio\",\"Marcello Guerreiro\",\"Marcelo Cervini\",\"Marcelo da Silva\",\"Marcelo Juliano Rabelo Oliveira\",\"Marcelo Magioli\",\"Marcelo Passamani\",\"Marcelo Silva de Almeida\",\"Marco AurÃ©lio GalvÃ£o da Silva\",\"Marcos Adriano Tortato\",\"Marcos Amaku\",\"Marcos AntÃ´nio Melo\",\"Marcos E. Coutinho\",\"Marcos PÃ©rsio Dantas Santos\",\"Marcus V. Vieira\",\"Maria Augusta Andrade\",\"Maria Claudene Barros\",\"Maria Cristina Ferreira do Rosario\",\"Maria Dolores Alves dos Santos Domit\",\"Maria EmÃ\\xadlia de Avelar Fernandes\",\"Maria Histele Sousa do Nascimento\",\"Maria Lucia Lorini\",\"Maria Piedad Baptiste\",\"Maria Santina de Castro Morini\",\"Mariana B. Nagy-Reis\",\"Mariana Bueno Landis\",\"Mariana Moncassim Vale\",\"Mariana Sampaio Xavier\",\"Mariane C. Kaizer\",\"Mariano Maudet Bergel\",\"Mariela Borgnia\",\"Marina Lima da Silva\",\"Marina Ochoa Favarini\",\"Marina Rivero\",\"Marina Sales Munerato\",\"Marina Trancoso Zaluar\",\"Marina Winter\",\"Marina Xavier da Silva\",\"Marina Zanin\",\"MarinÃªz Isaac Marques\",\"Mario Burke Haberfeld\",\"Mario S. Di Bitetti\",\"Maron Galliez\",\"Martin R. Alvarez\",\"Martina Malerba\",\"Mateus Melo Dias\",\"Mateus Yan de Oliveira\",\"Matheus GonÃ§alves dos Reis\",\"Matheus Rocha Jorge CorrÃªa\",\"MaurÃ\\xadcio Eduardo Graipel\",\"MaurÃ\\xadcio M. NÃºÃ±ez-Regueiro\",\"Mauricio N. Godoi\",\"Mauricio Osvaldo Moura\",\"Mauro Galetti\",\"Mauro Sanvicente Lopez\",\"Maximiliano Augusto Benedetti\",\"Mayara GuimarÃ£es BeltrÃ£o\",\"Micaela Camino\",\"Michel Barros Faria\",\"Michel Miretzki\",\"Micheli Ribeiro Luiz\",\"Michell Perine\",\"Miguel Ã\\x82ngelo Marini\",\"Miguel Coutinho Moretta Monteiro\",\"Milene Alves-Eigenheer\",\"Milton Cezar Ribeiro\",\"Miriam Lucia Lages Perilli\",\"Monicque Silva Pereira\",\"Mozart Caetano de Freitas Junior\",\"NatÃ¡lia Mundim TÃ´rres\",\"Natalia Cossa\",\"Natalia Mariana Denkiewicz\",\"Natalie Olifiers\",\"Natasha Moraes de Albuquerque\",\"NathÃ¡lia Detogne\",\"NathÃ¡lia Fernandes Canassa\",\"Nelson Henrique de Almeida Curi\",\"Newton Gurgel Filho\",\"NicolÃ¡s Fernando Seoane\",\"Nicole da Rosa Oliveira\",\"Nicoli Megale\",\"Nielson Pasqualotto\",\"Nilton Carlos CÃ¡ceres\",\"Nivaldo Peroni\",\"Noeli Zanella\",\"Olivier Pays\",\"Omolabake Alhambra Silva Arimoro\",\"Orlando Acevedo-Charry\",\"Pablo Perovic\",\"Pablo Rodrigues GonÃ§alves\",\"Paloma Marques Santos\",\"Pamella GusmÃ£o de GoÃ©s Brennand\",\"PatrÃ\\xadcia Kerches Rogeri\",\"PatrÃ\\xadcia Rosas Ribeiro\",\"PatrÃ\\xadcio Adriano da Rocha\",\"Patricia Ribeiro Salgado Pinha\",\"Patrick Farias\",\"Patrick Ricardo de LÃ¡zari\",\"Paula Akkawi\",\"Paula Anabel Pedreira\",\"Paula Cristina Rodrigues de Almeida MauÃ©s\",\"Paula Fabiana Pinheiro\",\"Paula Koeler Lira\",\"Paula Modenesi Ferreira\",\"Paula Sanches Martin\",\"Paulina Arroyo-Gerala\",\"Paulo de Tarso Zuquim Antas\",\"Paulo Henrique Marinho\",\"Paulo Henrique Peira Ruffino\",\"Paulo Henrique S. A. Camargo\",\"Paulo Landgref Filho\",\"Paulo Roberto Amaral\",\"Paulo RogÃ©rio Mangini\",\"Pedro Cordeiro-Estrela\",\"Pedro Henrique de Faria Peres\",\"Pedro Manoel Galetti\",\"Pedro RamÃ\\xadrez-Bautista\",\"Pierre-Cyril Renaud\",\"Pietro de Oliveira Scarascia\",\"Pollyanna Alves de Barros\",\"Pryscilla Moura Lombardi\",\"RÃ´mulo Theodoro Costa\",\"Rafael Bessa\",\"Rafael Cerqueira Castro de Souza\",\"Rafael D. Zenni\",\"Rafael Flores Peredo\",\"Rafael Hoogesteijn\",\"Rafael Loyola\",\"Rafael Souza Cruz Alves\",\"Raisa Reis de Paula Rodarte\",\"Ramon Lima Silva\",\"Ramonna de Oliveira\",\"Raone BeltrÃ£o-Mendes\",\"Raony de MacÃªdo Alencar\",\"Raquel Costa da Silva\",\"Rayssa Pedroso\",\"Rebeca Ferreira Sampaio\",\"Renan Lieto Alves Ribeiro\",\"Renata Pardini\",\"Renata Twardowsky Ramalho Bonikowski\",\"Renata Valls Pagotto\",\"Ricardo Augusto Dias\",\"Ricardo Bassini-Silva\",\"Ricardo Corassa Arrais\",\"Ricardo S. Bovendorp\",\"Ricardo Sampaio\",\"Ricardo Sartorello\",\"Rita de Cassia Bianchi\",\"Roberta Montanheiro Paolino\",\"Roberto Fusco-Costa\",\"Roberto Guilherme Trovati\",\"Robson Odeli EspÃ\\xadndola Hack\",\"Rodiney de Arruda Mauro\",\"Rodrigo de Almeida Nobre\",\"Rodrigo Delmonte Gessulli\",\"Rodrigo LeÃ³n PÃ©rez\",\"Rodrigo Lima Massara\",\"Rodrigo Medina FrÃ³es da Silva\",\"RogÃ©rio Cunha de Paula\",\"RogÃ©rio Grassetto Teixeira da Cunha\",\"Ronaldo GonÃ§alves Morato\",\"Rosane Vera Marques\",\"Rubem Augusto da PaixÃ£o Dornas\",\"Rubia Santana Andrade\",\"SÃ´nia A. Talamoni\",\"SÃ©rgio Bazilio\",\"Salvatore Siciliano\",\"Samara Arsego Guaragni\",\"Samir GonÃ§alves Rolim\",\"Samuel Astete\",\"Sandra Cavalcanti\",\"Sandra Maria Hartz\",\"Santiago Carvalho\",\"Sara Cortez\",\"Saulo Meneses Silvestre de Sousa\",\"Saulo Ramos Lima\",\"SebastiÃ¡n A. Ballari\",\"SebastiÃ¡n AndrÃ©s Costa\",\"SebastiÃ¡n Cirignoli\",\"Sebastian GarcÃ\\xada-R\",\"Sergio Solari Torres\",\"Silvana Back Franco\",\"Simone RebouÃ§as Martins\",\"Soledad de Bustos\",\"Stefani Gabrieli Age\",\"Stephen Francis Ferrari\",\"Talitha Mayumi Francisco\",\"Tatiane Micheletti\",\"Tayanna MedonÃ§a da Silva Godim\",\"Thais Guimaraes Luiz\",\"Thales Renato Ochotorena de Freitas\",\"Thamy De Almeida Moreira\",\"Thiago Ferreira Rodrigues\",\"Ubiratan Piovezan\",\"Umberto Cotrim Barcos\",\"Valeria Castilho Onofrio\",\"Valeria L. Martin-Albarracin\",\"Valeria Towns\",\"ValquÃ\\xadria Cabral AraÃºjo\",\"Vanesa Bejarano\",\"Vanessa Kanaan\",\"Vanessa Salete Daga\",\"Vanner Boere\",\"VerÃ´nica Parente Gomes de Araujo\",\"VerÃ³nica Victoria Benitez\",\"Victor Hugo Duarte da Silva\",\"Victor Leandro-Silva\",\"Vilma Clarice Geraldi\",\"VinÃ\\xadcius Augusto GalvÃ£o Bastazini\",\"VinÃ\\xadcius Peron de Oliveira Gasparotto\",\"VinÃ\\xadcius Santana Orsini\",\"Vinicius Alberici\",\"Vinicius JosÃ© Alves Pereira\",\"VirgÃ\\xadnia Santiago da Silva\",\"Viviana Rojas Bonzi\",\"Viviane Maria Guedes Layme\",\"Viviane Mottin\",\"Waldney Pereira Martins\",\"Walfrido Moraes Tomas\",\"Walna Micaelle de Moraes Pires\",\"Wellington Hannibal\",\"Wesley DÃ¡ttilo\",\"Whaldener Endo\",\"William BercÃª\",\"William Douglas Carvalho\",\"William Magnusson\",\"Yamil Di Blanco\",\"Yan Gabriel Celli Ramos\",\"Yenifer G. RodrÃ\\xadguez-CalderÃ³n\",\"Yuri Geraldo Gomes Ribeiro\",\"Yuri Raia Mendes\",\"Zilca Campos\"}',\n",
       "       '{\"Ã\\x82ngela Camila Deffaci\",\"Ã\\x89rica Hasui\",\"Ã\\x89rika Paula Castro\",\"Adauto de Souza Ribeiro\",\"Adriana Bocchiglieri\",\"Adriani Hass\",\"Adriano Canteri\",\"Adriano Garcia Chiarello\",\"Adriano Pereira Paglia\",\"Adriele Aparecida Pereira\",\"Agnis Cristiane de Souza\",\"Ailin Gatica\",\"Akyllam Zoppi Medeiro\",\"Alan Eriksson\",\"Alan Nilo Costa\",\"Alberto A. Yanosky\",\"Alberto GonzÃ¡lez-Gallina\",\"Alejandro Jesus de la Cruz\",\"Alessandra Bertassoni\",\"Alex Augusto Abreu Bovo\",\"Alex Bager\",\"Alexandra Cravino Mol\",\"Alexandra Maria Ramos Bezerra\",\"Alexandre Martins Costa Lopes\",\"Alexandre Percequillo\",\"Alexandre Vogliotti\",\"Alexine Keuroghlian\",\"Alfonso Christopher ZÃºÃ±iga Hartley\",\"Allison L. Devlin\",\"Almir de Paula\",\"Alvaro GarcÃ\\xada-Olaechea\",\"Amadeo SÃ¡nchez\",\"Ana Carla Medeiros Morato Aquino\",\"Ana Carolina Srbek-Araujo\",\"Ana Cecilia Ochoa\",\"Ana Cristina Tomazzoni\",\"Ana Cristyna Reis Lacerda\",\"Ana Elisa de Faria Bacellar\",\"Ana Kellen Nogueira Campelo\",\"Ana MarÃ\\xada Herrera Victoria\",\"Ana Maria de Oliveira Paschoal\",\"Ana Paula Nascimento Gomes\",\"Ana Paula Potrich\",\"Ana Priscila Medeiros OlÃ\\xadmpio\",\"Ana Raissa Cunha Costa\",\"Anah Tereza de Almeida JÃ¡como\",\"Analice Maria CalaÃ§a\",\"AnamÃ©lia Souza Jesus\",\"Ananda de Barros Barban\",\"Anderson Claudino Rolim\",\"Anderson FeijÃ³\",\"Anderson Pagoto\",\"Andiara Paula Hermann\",\"Andiara Silos Moraes de Castro e Souza\",\"AndrÃ© Chein Alonso\",\"AndrÃ© Faria MendonÃ§a\",\"AndrÃ© LuÃ\\xads Luza\",\"AndrÃ© Luis Botelho Moura\",\"AndrÃ© Luiz Ferreira da Silva\",\"AndrÃ© Monteiro\",\"AndrÃ© Valle Nunes\",\"Andre Monnerat Lanna\",\"Andre Pinassi Antunes\",\"Andrea Dechner\",\"Andrea Siqueira Carvalho\",\"Andres Jose Novaro\",\"Andressa Barbara Scabin\",\"Andressa Gatti\",\"Andrezza Bellotto Nobre\",\"Anelise Montanarin\",\"Anna Carolina Figueiredo de Albuquerque\",\"Antonio Marcelo Mangione\",\"Antonio Millas Silva Pinto\",\"Antonio Rossano Mendes Pontes\",\"Ariane Teixeira Bertoldi\",\"Armando Muniz Calouro\",\"Arthur Fernandes\",\"Arystene Nicodemo Ferreira\",\"Atilla Colombo Ferreguetti\",\"Augusto Lisboa Martins Rosa\",\"Aureo Banhos\",\"Beatriz Azevedo Cezila\",\"Beatriz da Silva de Souza Francisco\",\"Beatriz de Mello Beisiegel\",\"Benoit de Thoisy\",\"Bianca dos Santos Neves\",\"Bianca Ingberman\",\"Brenda Pereira-Silva\",\"Bruna Bertagni de Camargo\",\"Bruna da Silva Andrade\",\"Bruna Silva Santos\",\"Bruno Augusto Torres Parahyba Campos\",\"Bruno Busnello Kubiak\",\"Bruno Henrique Saranholi\",\"Bruno Leles\",\"Bruno Rodrigo de Albuquerque FranÃ§a\",\"Calebe Pereira Mendes\",\"Camila Alvez Islas\",\"Camila Cantagallo Devids\",\"Camila FÃ¡tima Priante\",\"Camila Pianca\",\"Camila Rodrigues\",\"Camilla AngÃ©lica de Lima\",\"Camilo Ribeiro de Lima\",\"CÃ\\xadntia M. Lopes\",\"Carla Cristina Gestich\",\"Carla Denise Tedesco\",\"Carlos A. Peres\",\"Carlos Benhur Kasper\",\"Carlos Cesar Durigan\",\"Carlos De Angelo\",\"Carlos Eduardo Fragoso\",\"Carlos Eduardo Verona\",\"Carlos Fonseca\",\"Carlos Frederico Duarte Rocha\",\"Carlos Hass\",\"Carlos Henrique Salvador\",\"Carlos Leonardo Vieira\",\"Carmen Elena BarragÃ¡n Ruiz\",\"Carolina Carvalho Cheida\",\"Caroline CharÃ£o Sartor\",\"Caroline da Costa Espinosa\",\"Caroline Leuchtenberger\",\"Carolline Zatta Fieker\",\"Caryne Braga\",\"Catalina SÃ¡nchez-Lalinde\",\"Cauanne Iglesias Campos Machado\",\"CecÃ\\xadlia LicariÃ£o Luna\",\"Cecilia Cronemberger\",\"Christine Del Vechio\",\"Christine Steiner S. Bernardo\",\"Cindy Meliza Hurtado\",\"Clarissa Alves da Rosa\",\"Claudia Cristina Cinta\",\"Claudia Guimaraes Costa\",\"Claudia Paola ZÃ¡rate-CastaÃ±eda\",\"Claudia Zukeran Kanda\",\"Claudio Leite Novaes\",\"Clinton N. Jenkins\",\"Cristiana SimÃ£o Seixas\",\"Cristiane Martin\",\"Cristiane PatrÃ\\xadcia Zaniratto\",\"Cristiano TrapÃ© Trinca\",\"Cristina Fabiola LÃ³pez-Fuerte\",\"Cristina Jaques da Cunha\",\"Crizanto Brito De-Carvalho\",\"CuauhtÃ©moc ChÃ¡vez\",\"Cyntia Cavalcante Santos\",\"Daiana Jeronimo Polli\",\"Daiane Buscariol\",\"Daiane Cristina Carreira\",\"Daniel da Silva Ferraz\",\"Daniel Galiano\",\"Daniel Thornton\",\"Daniela Lamattina\",\"Daniele Janina Moreno\",\"Danielle Oliveira Moreira\",\"Danilo Augusto Farias\",\"Darci Moraes Barros-Battesti\",\"Davi Castro Tavares\",\"David Costa Braga\",\"Denise Alemar Gaspar\",\"Diana Friedeberg\",\"Diego Afonso Silva\",\"Diego AstÃºa\",\"Diego Carvalho Viana\",\"Diego J. Lizcano\",\"Diego M. Varela\",\"Diogo Loretto\",\"Diogo Maia GrÃ¤bin\",\"Donald P. Eaton\",\"Douglas de Matos Dias\",\"Douglas Machado da Silva\",\"Edeltrudes Maria Valadares CalaÃ§a Camara\",\"Eder Barbier\",\"Edgar ChÃ¡vez-GonzÃ¡lez\",\"Ednaldo CÃ¢ndido Rocha\",\"Edson de Souza Lima\",\"Eduardo Carrano\",\"Eduardo Delgado Rigacci\",\"Eduardo Eizirik\",\"Eduardo Marques Santos\",\"Eduardo Martins Venticinque\",\"Eduardo Nakano-Oliveira\",\"Eduardo Roberto Alexandrino\",\"Edvandro Abreu Ribeiro\",\"Eleonore Setz\",\"Eliana CÃ©sar Laranjeira Duarte Rocha\",\"Elildo Alves Ribeiro Carvalho\",\"Elisabete Rechenberg\",\"Elmary da Costa Fraga\",\"Eloisa Neves MendonÃ§a\",\"Elvira D\\'Bastiani\",\"Emiliana Isasi-CatalÃ¡\",\"Emiliano Esterci Ramalho\",\"Emiliano Guijosa-Guadarrama\",\"Enrique GonzÃ¡lez\",\"Erica Naomi Saito\",\"Erich Fischer\",\"Erick Francisco Aguiar\",\"Erick Sekiama Rocha\",\"Erik Daniel MartÃ\\xadnez Nambo\",\"Erika de la PeÃ±a-CuÃ©llar\",\"Evellyn Borges de Freitas\",\"Ezequiel PedÃ³\",\"FÃ¡bio Angelo Melo Soares\",\"FabÃ\\xadola Keesen Ferreira\",\"Fabiana Lopes Rocha\",\"Fabiane de Aguiar Pereira\",\"Fabiane Girardi\",\"Fabiano Rodrigues de Melo\",\"Fabio de Oliveira Roque\",\"Fabio Gabriel DÃ\\xadaz-Santos\",\"Fabio Mello Patiu\",\"Fabio Oliveira do Nascimento\",\"Fabio Rohe\",\"Fabricio Diaz-Santos\",\"Felipe Bittioli R. Gomes\",\"Felipe Martello\",\"Felipe Moreli Fantacini\",\"Felipe Pedrosa\",\"Felipe Pessoa da Silva\",\"Felipe Velez-Garcia\",\"Fernanda Cavalcanti de Azevedo\",\"Fernanda Cristina de Barros\",\"Fernanda da Silva Santos\",\"Fernanda Delborgo Abra\",\"Fernanda do Passo Ramalho\",\"Fernanda Guedes da Silva\",\"Fernanda Martins Hatano\",\"Fernanda Michalski\",\"Fernando Anaguano-Yancha\",\"Fernando C. Passos\",\"Fernando CÃ©sar GonÃ§alves Bonfim\",\"Fernando de Castro Jacinavicius\",\"Fernando GonÃ§alves\",\"Fernando Henrique Puertas\",\"Fernando M. Contreras-Moreno\",\"Fernando Pedroni\",\"Fernando Rodrigo Tortato\",\"Filipe Martins Santos\",\"FlÃ¡via GuimarÃ£es Chaves\",\"FlÃ¡vio Eduardo Vilas Boas\",\"FlÃ¡vio Kulaif Ubaid\",\"Flavia Pereira Tirelli\",\"Flavio Henrique GuimarÃ£es Rodrigues\",\"Francesca Belem Lopes Palmeira\",\"Francisco Grotta-Neto\",\"Francisco Palomares\",\"Franco Leandro Souza\",\"Francys Emanuelle Costa\",\"Frederico G. R. FranÃ§a\",\"Frederico Gemesio Lemos\",\"Fredy RamÃ\\xadrez Pinto\",\"Gabriel Lima Aguiar\",\"Gabriel Selbach Hofmann\",\"Gabriela Heliodoro\",\"Gabriela Teixeira Duarte\",\"Gabrielle Beca\",\"Gabrielle Ribeiro de Andrade\",\"Galo Zapata-RÃ\\xados\",\"GastÃ³n AndrÃ©s Fernandez GinÃ©\",\"George V. N. Powell\",\"Geraldo Wilson Fernandes\",\"German Forero-Medina\",\"Geruza L. Melo\",\"Gindomar Gomes Santana\",\"Giordano Ciocheti\",\"Giselle Bastos Alves\",\"Glauber Henrique Borges de Oliveira Souto\",\"Glenda JÃ©ssica Villarroel\",\"Grasiela Edith de Oliveira Porfirio\",\"Graziele Oliveira Batista\",\"Greici Maia Behling\",\"Guido Marcos Ayala Crespo\",\"Guilherme de Miranda MourÃ£o\",\"Guilherme Zamarian Rezende\",\"Gustavo Alves da Costa Toledo\",\"Heitor Miraglia Herrera\",\"Helena Alves Prado\",\"Helena de Godoy Bergallo\",\"Helio Secco\",\"Henrique Llacer Roig\",\"Henrique RajÃ£o\",\"Henrique Villas Boas Concone\",\"Herbert Duarte\",\"Hiago Ermenegildo\",\"HipÃ³lito Ferreira Paulino Neto\",\"Howard Quigley\",\"Hudson Macedo Lemos\",\"Hugo Cabral\",\"Hugo Fernandes-Ferreira\",\"Hugo Fernando del Castillo\",\"Igor Kintopp Ribeiro\",\"Igor Pfeifer Coelho\",\"Ingridi Camboim Franceschi\",\"Isabel Melo\",\"Isabella Oliveira-Bevan\",\"Italo Mourthe\",\"ItiberÃª Bernardi\",\"J. Antonio de la Torre\",\"JÃ©ssica Abonizio Gouvea\",\"JÃ¶rn Ziegler\",\"Jader Marinho-Filho\",\"Jaime Martinez\",\"Jaime Xavier Palacios Perez\",\"Jairo PÃ©rez-Torres\",\"Jamile BubaduÃ©\",\"Jana Rangel Silveira\",\"JÃºlia Emi de Faria Oshima\",\"JÃºlia Ilha\",\"Jardel BrandÃ£o Seibert\",\"Jasmim Felipe Oliveira\",\"Jasmine Resende Assis\",\"Javier De la Maza\",\"Javier Hinojosa\",\"Jean Paul Metzger\",\"Jeffrey James Thompson\",\"Jens-Christian Svenning\",\"Jesus Rodrigues Domingos Souza\",\"Jimmy Pincheira-Ulbrich\",\"JoÃ£o Carlos Zecchini Gebin\",\"JoÃ£o Gabriel Ribeiro Giovanelli\",\"JoÃ£o Luiz Rossi Junior\",\"JoÃ£o Miranda\",\"JoÃ£o Paulo Gava Just\",\"JoÃ£o Paulo Pandini Favoretti\",\"JoÃ£o Paulo Villani\",\"JoÃ£o Pedro Souza-Alves\",\"Joana Zorzal Nodari\",\"Jociel Ferreira Costa\",\"Joedison Rocha\",\"John Polisar\",\"Jonas Sponchiado\",\"Jorge JosÃ© Cherem\",\"Jorge Reppold Marinho\",\"JosÃ© Carlos Chaves dos Santos\",\"JosÃ© Clemensou dos Reis JÃºnior\",\"JosÃ© Cordeiro\",\"JosÃ© de Sousa e Silva JÃºnior\",\"JosÃ© Fernando Moreira RamÃ\\xadrez\",\"JosÃ© HernÃ¡n Sarasola\",\"JosÃ© MaurÃ\\xadcio Barbanti Duarte\",\"JosÃ© Oliveira Dantas\",\"JosÃ© OtÃ¡vio Venancio\",\"JosÃ© Salatiel Rodrigues Pires\",\"Jose Ariel Rodriguez-Pulido\",\"Jose Eduardo Mantovani\",\"Jose Luis Cartes\",\"Jose Milton Longo\",\"Jose Roberto de Matos\",\"Joseph E. Hawes\",\"Joyce GonÃ§alves Santos\",\"Juan AndrÃ©s MartÃ\\xadnez Lanfranco\",\"Juan Carlos Rudolf\",\"Juan Felipe Charre-Medellin\",\"Juan Ignacio ZanÃ³n-MartÃ\\xadnez\",\"Juan L. PeÃ±a-MondragÃ³n\",\"Juan Manuel Campos Krauer\",\"Juan Pablo Arrabal\",\"Juan Ruiz-Esparza\",\"Julia Beduschi\",\"Julia Camara Assis\",\"Julia Carolina Mata\",\"Juliana Bonanomi\",\"Juliana Jordao\",\"Juliana Monteiro de Almeida-Rocha\",\"Juliana Silveira dos Santos\",\"Juliane Pereira-Ribeiro\",\"Juliani Bruna Zanoni\",\"Juliano AndrÃ© Bogoni\",\"Julio Javier ChacÃ³n Pacheco\",\"Kamila Marianne Contreras Palma\",\"Karen B. Strier\",\"Karen Giselle Rodriguez Castro\",\"Karl Didier\",\"Karl L. Schuchmann\",\"Karla ChÃ¡vez-Congrains\",\"Kathrin Burs\",\"Katia M. P. M. B. Ferraz\",\"Keila Macfadem Juarez\",\"Kevin Flesher\",\"Kimberly Danielle Rodrigues Morais\",\"LaÃ\\xads Aline Grossel\",\"LaÃ\\xads Lautenschlager\",\"Lais Camila Dahmer\",\"Lana Resende de Almeida\",\"Larissa de NazarÃ© Barros Barbosa\",\"Larissa Fornitano\",\"Larissa L. Bailey\",\"Larissa Nascimento Barreto\",\"Laura Magnolia Villalba\",\"Laura Martins MagalhÃ£es\",\"Laury Cullen\",\"LÃ\\xadvia Maria de Paula\",\"Leandro Marques\",\"Leandro Santana Moreira\",\"Leandro Silveira\",\"Leonardo de Carvalho Oliveira\",\"Leonardo de Paula Gomes\",\"Leonardo dos Santos Aguiar\",\"Leonardo Henrique da Silva\",\"Leonardo Marques Costa\",\"Leonardo Sartorello\",\"Leonardo Siqueira MendonÃ§a\",\"Leonor Adriana Valenzuela\",\"LetÃ\\xadcia Benavalli\",\"Leticia Coutinho Sangy Dias\",\"Leticia Prado Munhoes\",\"Lilian Bonjorne\",\"Lilian Catenacci\",\"Lilian Elaine Rampim\",\"Lorena Anne Nascimento\",\"LucÃ\\xada MartÃ\\xadnez Retta\",\"Lucas GonÃ§alves da Silva\",\"Lucas Neves Perillo\",\"Lucas Pacciullio Gaspar\",\"Lucas Quintilham\",\"Lucas Ramis Segura\",\"Lucas Rodrigo Rezende\",\"Lucia Nathaly Stefany Rojas\",\"Luciana AraÃºjo\",\"Luciana Zago da Silva\",\"Luciano Carramaschi de AlagÃ£o Querido\",\"Luciano Martins Verdade\",\"Lucy E. Perera-Romero\",\"Ludimila Juliele Carvalho-Leite\",\"Ludmila Hufnagel\",\"Luis Renato Rezende Bernardo\",\"Luiz Flamarion Oliveira\",\"Luiz Gustavo Rodrigues Oliveira Santos\",\"Luiz Henrique Lyra\",\"Luiz Henrique Medeiros Borges\",\"Luiza Neves GuimarÃ£es\",\"MÃ¡rcio Leite de Oliveira\",\"MaÃ\\xadra Benchimol\",\"MaÃ\\xadsa Ziviani Alves Martins\",\"Magnus Machado Severo\",\"Maira Giuliana Quatrocchi\",\"Manoel Rodrigues\",\"MarÃ\\xada Beatriz NuÃ±ez\",\"MarÃ\\xada Celina Carrizo\",\"MarÃ\\xada Cristina PeÃ±uela Mora\",\"MarÃ\\xada Eugenia Iezzi\",\"MarÃ\\xadlia A. S. Barros\",\"Marcel JosÃ© Franco Penteado\",\"Marcela Alvares Oliveira\",\"Marcela FiguerÃªdo Duarte Moraes\",\"Marcela GuimarÃ£es Moreira Lima\",\"Marcella do Carmo PÃ´nzio\",\"Marcelo Alejandro Villegas\",\"Marcelo Augusto dos Santos Junior\",\"Marcelo Cervini\",\"Marcelo da Silva\",\"Marcelo Hideki Yamane\",\"Marcelo Magioli\",\"Marcelo Passamani\",\"Marcia Maria de Assis Jardim\",\"Marcos Adriano Tortato\",\"Marcos de Souza Lima Figueiredo\",\"Marcos Silveira\",\"Marcus VinÃ\\xadcius Vieira\",\"Margareth L. Sekiama\",\"Maria Augusta Andrade da Silva\",\"Maria Brunini Siviero\",\"Maria Claudene Barros\",\"Maria Cristina Ferreira do RosÃ¡rio\",\"Maria del Carmen Fleytas Jover\",\"Maria Elisa de Freitas Morandi\",\"Maria EmÃ\\xadlia Avelar Fernandes\",\"Maria Emilia Huerta\",\"Maria Estela Viscarra SiÃ±ani\",\"Maria JoÃ£o Ramos Pereira\",\"Maria Laura Gomez Vinassa\",\"Maria Lucia Lorini\",\"Maria Luisa S. P. Jorge\",\"Maria Santina Morini\",\"Mariana Bueno Landis\",\"Mariana Guenther\",\"Mariana M. Vale\",\"Mariana Nagy-Reis\",\"Mariana Sampaio Xavier\",\"Mariana Silva Tavares\",\"Mariane Kaizer\",\"Marianela Velilla\",\"Mariano Maudet Bergel\",\"Marilia Teresinha Hartmann\",\"Marina Lima da Silva\",\"Marina Rivero\",\"Marina Salles Munerato\",\"Marina Xavier da Silva\",\"Marina Zanin\",\"MarinÃªz Isaac Marques\",\"Mario Haberfeld\",\"Mario S. Di Bitetti\",\"Mark Bowler\",\"Maron Galliez\",\"MartÃ\\xadn R. Alvarez\",\"Martha Lucia Ortiz-Moreno\",\"Martin Alejandro Montes\",\"Martin Buschiazzo\",\"Mateus Melo-Dias\",\"Matheus GonÃ§alves Reis\",\"Matheus Rocha Jorge CorrÃªa\",\"Mathias W. Tobler\",\"Matthew E. Gompper\",\"MaurÃ\\xadcio BrandÃ£o Vecchi\",\"MaurÃ\\xadcio Eduardo Graipel\",\"MaurÃ\\xadcio Quoos Konzen\",\"Mauricio Neves Godoi\",\"Mauricio Nunez-Regueiro\",\"Mauricio O. Moura\",\"Mauro Galetti\",\"Maximiliano VÃ\\xadctor Pardo\",\"Mayara GuimarÃ£es BeltrÃ£o\",\"Melissa Mongelli\",\"Meyline Oliveira Almeida\",\"Michael P. Gilmore\",\"Michel Barros Faria\",\"Michel Schutte\",\"Micheli Ribeiro Luiz\",\"Milene Alves-Eigenheer\",\"Milton C. Ribeiro\",\"Milton de Paula\",\"Mircea G. Hidalgo-Mihart\",\"Miriam Lucia Lages Perilli\",\"Mozart Caetano Freitas-Junior\",\"Murillo Prado da Silva\",\"NÃªmora Pauletti Prestes\",\"Natalia Mariana Denkiewicz\",\"Natalia Mundim Torres\",\"Natalie Olifiers\",\"Natani Da Silva De Lima\",\"Natasha Moraes de Albuquerque\",\"NathÃ¡lia Fernandes Canassa\",\"Nelson Henrique de Almeida Curi\",\"Nereyda Falconi\",\"Newton Mota Gurgel-Filho\",\"Nielson Pasqualotto\",\"Nilton C. CÃ¡ceres\",\"Nivaldo Peroni\",\"NoÃ© U. de la Sancha\",\"Noeli Zanella\",\"Octavio Monroy-Vilchis\",\"Olivier Pays\",\"Omolabake Alhambra Arimoro\",\"OtÃ¡vio Santi Ribeiro\",\"Pablo Rodrigues GonÃ§alves\",\"Pablo Villalva\",\"Paloma Marques Santos\",\"Pamella Brennand\",\"PatrÃ\\xadcio Rocha\",\"Patricia Rogeri\",\"Paula Akkawi\",\"Paula Cruz\",\"Paula Modenesi Ferreira\",\"Paula Ribeiro Prist\",\"Paula Sanches Martin\",\"Paulina Arroyo-Gerala\",\"Paulo Afonso Hartmann\",\"Paulo Auricchio\",\"Paulo de Tarso Zuquim Antas\",\"Paulo H. S. A. Camargo\",\"Paulo Henrique Marinho\",\"Paulo Henrique Peira Ruffino\",\"Paulo InÃ¡cio Prado\",\"Paulo Wesley Martins\",\"Pedro Cordeiro-Estrela\",\"Pedro Henrique Faria Peres\",\"Pedro Luna\",\"Pedro Manoel Galetti\",\"Pedro Sarmento\",\"Pedro Volkmer de Castilho\",\"Pierre-Cyril Renaud\",\"Pietro Oliveira Scarascia\",\"Priscilla De Paula Andrade Cobra\",\"Pryscilla Moura Lombardi\",\"RÃ´mulo Costa\",\"Rafael Bessa\",\"Rafael Cerqueira Castro de Souza\",\"Rafael Jan Hoogesteijn\",\"Rafael Reyna-Hurtado\",\"Rafael Souza Cruz Alves\",\"Rafael Spilere Romagna\",\"Rafaela Aparecida da Silva\",\"Ramon Lima Silva\",\"Ramonna de Oliveira\",\"RÃºbia Santana Andrade\",\"Raone BeltrÃ£o-Mendes\",\"Raony de MacÃªdo Alencar\",\"Raphaella Coutinho\",\"Raquel Costa da Silva\",\"Raquel L. S. C. CaribÃ© Grando\",\"Rayanne Gama Matos\",\"Raylenne da Silva Araujo\",\"Rayssa Faria Pedroso\",\"Rayssa Mainette Nantes DurÃ£es\",\"Renan Lieto Alves Ribeiro\",\"Renata Chagas\",\"Renata Lara Muylaert\",\"Renata Miotto\",\"Renata Twardowsky Ramalho Bonikowski\",\"Renata Valls Pagotto\",\"Renato Richard HilÃ¡rio\",\"Rhayssa Terra Faria\",\"Ricardo AraÃºjo Pires\",\"Ricardo Bassini-Silva\",\"Ricardo Sampaio\",\"Ricardo Sartorello\",\"Richard Hatakeyama\",\"Rita de Cassia Bianchi\",\"Robert Buitenwerf\",\"Robert Wallace\",\"Roberta Montanheiro Paolino\",\"Roberto Fusco-Costa\",\"Roberto Guilherme Trovati\",\"Roberto Junior Tomasi\",\"Robson Odeli EspÃ\\xadndola Hack\",\"Rodolfo Assis MagalhÃ£es\",\"Rodrigo Affonso de Albuquerque Nobrega\",\"Rodrigo Bernardo\",\"Rodrigo de Almeida Nobre\",\"Rodrigo Lima Massara\",\"Rodrigo Medina FrÃ³es\",\"Rodrigo Paulo da Cunha AraÃºjo\",\"Rodrigo RaÃºl LeÃ³n PÃ©rez\",\"Rodrigo Silva Pinto Jorge\",\"RogÃ©rio Cunha de Paula\",\"RogÃ©rio Grassetto Teixeira da Cunha\",\"RogÃ©rio Martins\",\"Romulo Romeu Nobrega Alves\",\"Ronaldo GonÃ§alves Morato\",\"Rony Garcia-Anleu\",\"Rony Peterson Santos Almeida\",\"RubÃ©n DarÃ\\xado Cueva LoachamÃ\\xadn\",\"Rugieri JuÃ¡rez\",\"SÃ¡vio Augusto de Souza Machado\",\"SÃ©rgio Luiz Althoff\",\"Samanta UchÃ´a Bordallo\",\"Samara Arsego Guaragni\",\"Samia E. Carrillo-Percastegui\",\"Samile Seber\",\"Samuel Astete\",\"Sandra Maria Hartz\",\"Santiago Espinosa\",\"Sara Ã\\x81lvarez Solas\",\"Saulo Meneses Silvestre\",\"Saulo Ramos Lima\",\"Sean Keuroghlian-Eaton\",\"SebastiÃ¡n AndrÃ©s Costa\",\"Sebastian Albanesi\",\"Sergio Bazilio\",\"Sergio Lucena Mendes\",\"Shery Duque Pinheiro\",\"Silvio Junior Napiwoski\",\"Sixto FernÃ¡ndez Ramirez\",\"Sonia Aparecida Talamoni\",\"Stefani Gabrieli Age\",\"TaiguÃ£ CorrÃªa Pereira\",\"Tainah Cruz Moreira\",\"Tatiane Campos Trigo\",\"Tayana MendonÃ§a da Silva Gondim\",\"ThamÃ\\xadris Christina Karlovic\",\"Thiago Cavalcante\",\"Thiago Ferreira Rodrigues\",\"Thiago Maccarini\",\"Thiago Philipe de Camargo e Timo\",\"Tiberio Cesar Monterrubio\",\"Ubiratan Piovezan\",\"Vagner Cavarzere\",\"Valeria Castilho Onofrio\",\"Valeria Towns\",\"Valeska Buchemi Oliveira\",\"ValquÃ\\xadria Cabral AraÃºjo\",\"Vanessa Lazaro Melo\",\"Vanessa Tavares Kanaan\",\"Victor Iwakami\",\"Victor Vale\",\"Vilmar Picinatto Filho\",\"VinÃ\\xadcius Santana Orsini\",\"Vinicius A. G. Bastazini\",\"Vinicius Alberici\",\"Vinicius Rodrigues Tonetti\",\"Vivian da Silva Braz\",\"Viviana B. Rojas Bonzi\",\"Viviane Maria Guedes Layme\",\"Viviane Telles Rodrigues Gaboardi\",\"Vlamir JosÃ© Rocha\",\"Waldney Pereira Martins\",\"Walfrido Moraes Tomas\",\"Wellington Hannibal\",\"Wesley DÃ¡ttilo\",\"Wesley R. Silva\",\"Whaldener Endo\",\"William BercÃª\",\"Yaribeth Bravata de la Cruz\",\"Yuri Geraldo Gomes Ribeiro\"}',\n",
       "       '{\"Alvaro Jose Porto Moreira\",\"Anna Rosala-Hallas\",\"Bart C. Jacobs\",\"Carlos A. Pardo\",\"Carlos Alexandre Antunes de Brito\",\"Celina Maria Turchi Martelli\",\"David W. G. Brown\",\"Girvan Burnside\",\"Hugh J. Willison\",\"Lance Turtle\",\"Lindomar Jose Pena\",\"Maneesh Bhojak\",\"Marcela Lopes Santos\",\"Maria de Fatima Pessoa Militao de Albuquerque\",\"Maria Iris de Morais Machado\",\"Maria Lucia Brito Ferreira\",\"Mark Ellul\",\"Marli Tenorio Cordeiro\",\"Michael J. Griffiths\",\"Rafael Freitas de Oliveira Franca\",\"Rafael Ramos E. Silva\",\"Raquel Medialdea-Carrera\",\"Ravi Mehta\",\"Ricardo A. A. Ximenes\",\"Roberta Paz Melo\",\"Solange Dornelas Mesquita\",\"Sonja E. Leonhard\",\"Suzannah Lant\",\"Tom Solomon\"}',\n",
       "       '{\"Fernanda M. C. Araujo\",\"Ilana C. L. Magalhaes\",\"Livia E. C. Marques\",\"Maria Izabel F. Guedes\",\"Nicolas M. Girao\",\"Pedro F. N. Souza\"}',\n",
       "       '{\"Ana Cristina de Oliveira Monteiro Moreira\",\"Antonio Eufrasio Vieira Neto\",\"Felipe Domingos de Sousa\",\"Frederico Bruno Mendes Batista Moreno\",\"Humberto D\\'muniz Pereira\",\"Marcos Roberto Lourenzoni\",\"Renato de Azevedo Moreira\",\"Thalles Barbosa Grangeiro\"}',\n",
       "       '{\"Andra Vaida\",\"Barry J. Campbell\",\"Carrie A. Duckworth\",\"D. Mark Pritchard\",\"Fabio Miyajima\",\"Felix I. Ikuomola\",\"Jonathan M. Williams\",\"Jorge H. Caamano\",\"Lauren G. Jones\",\"Louise M. Thompson\",\"Michael D. Burkitt\"}',\n",
       "       '{\"Bruno C. Cavalcanti\",\"Claudia Pessoa\",\"Eufranio N. da Silva Junior\",\"Flavio S. Emery\",\"Guilherme F. de Lima\",\"Jose R. Correa\",\"Leandro F. Pedrosa\",\"Lucas C. D. de Rezende\",\"Marilia O. F. Goulart\",\"Marina P. Bruno\",\"Rossimiriam P. de Freitas\",\"Talita B. Gontijo\",\"Thaissa L. Silva\"}',\n",
       "       '{\"Adriana Costa Bacelo\",\"Andrea Ramalho\",\"Claudia dos Santos Cople-Rodrigues\",\"Eliane Paiva\",\"Ingebourg Georg\",\"Pedro Emmanuel Brasil\",\"Sheila Vasques Leandro Argolo\",\"Valeria Cavalcante Rolla\"}',\n",
       "       '{\"Andrade, Luiz Odorico Monteiro de\",\"Goya, Neusa\"}',\n",
       "       '{\"Fernando Ferreira Carneiro\",\"Vanira Matos Pessoa\"}',\n",
       "       '{\"Sharmênia de Araújo Soares Nuto\"}',\n",
       "       '{\"Antonio Jeovah de Andrade Meireles\",\"Fernando Ferreira Carneiro\",\"Luiz Rons Caula da Silva\",\"Naila Saskia Melo Andrade\",\"Vanira Matos Pessoa\"}',\n",
       "       '{\"Anya P. G. F. Vieira-Meyer\",\"Bruno Souza P. Ferreira\",\"Edgar Gomes Marques Sampaio\",\"Maria Vieira de lima Saintrain\",\"Mirna Albuquerque Frota\",\"Suzanne Vieira Saintrain\",\"Taffarel Canuto Nepomuceno\"}',\n",
       "       '{\"Aaron King\",\"Bruno C. Cavalcanti\",\"Claudia Pessoa\",\"Eufrnio N. da Silva Junior\",\"Fabio de Moliner\",\"Flavio S. Emery\",\"Jose B. Vieira Neto\",\"Leandro F. Pedrosa\",\"Marc Vendrell\",\"Rossimiriam P. de Freitas\",\"Talita B. Gontijo\"}',\n",
       "       '{\"C. Pessoa\",\"G. Scola\",\"G.G.N. de S. Wisintainer\",\"J.A.P. Henriques\",\"L.G.S. Souza\",\"M. Roesch-Ely\",\"M.O. de Moraes\",\"S. Moura\",\"T.L.G. Lemos\"}',\n",
       "       '{\"Aline Renata Pavan\",\"Beatriz Silva Urias\",\"Chung man Chin\",\"Gabriela Ribeiro Albuquerque\",\"Geraldo Rodrigues Sartori\",\"Igor Muccilo Prokopczyk\",\"Jean Leandro dos Santos\",\"Joao Herminio Martins da Silva\",\"Tania mara Ferreira Alves\",\"Thais Regina Ferreira de Melo\"}',\n",
       "       '{\"Ana Carolina de Figueiredo Costa\",\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Felipe Franco Marcal\",\"Francisco Claudio Fernandes Alves E. Silva\",\"Iana Aragao Magalhaes\",\"Lis Monteiro de Carvalho Guerra\",\"Luiza Lassi de Araujo Lopes\"}',\n",
       "       '{\"Alencar, Nadyelle Elias Santos\",\"Andrade, Luiz Odorico Monteiro de\",\"Barreto, Ivana Cristina de Holanda Cunha\",\"Raquel, Cheila Pires\",\"Ribeiro, Kelen Gomes\",\"Souza, Daiana Flávia Oliveira de\"}',\n",
       "       '{\"Gabriel Acacio de Moura\",\"Heverton Mendes Araujo\",\"Joao Pedro Viana Rodrigues\",\"Roberto Nicolete\",\"Yasmim Mendes Rocha\"}',\n",
       "       '{\"Adriana S. Pontes\",\"Andreimar M. Soares\",\"Carla F. C. Fernandes\",\"Francisquinha Souza da Silva\",\"Juliana P. Zuliani\",\"Rodrigo G. Stabeli\",\"Silvana D. da Silva\",\"Sulamita da S. Setubal\"}',\n",
       "       '{\"Jacenir Reis dos Santos Mallet\",\"Maurício Luiz Vilela\",\"Regis Bernardo Brandim Gomes\"}',\n",
       "       '{\"Fernando Ferreira Carneiro\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Vanira Matos Pessoa\"}',\n",
       "       '{\"Ana Cristina Oliveira Barreto\",\"Cristiana Brasil de Almeida Reboucas\",\"Karine Moreira de Melo\",\"Lucelia Malaquias Cordeiro\",\"Maria Isis Freire de Aguiar\",\"Rebeca Bandeira Barbosa\",\"Roberto Wagner Junior Freire de Freitas\",\"Suzy Ramos Rocha\"}',\n",
       "       '{\"Carlos Andre Moura Arruda\",\"Diego Dewes da Silva\",\"Fernando Ferreira Carneiro\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Joselia de Souza Trindade\",\"Leonor Maria Pacheco Santos\",\"Vanira Matos Pessoa\",\"Yamila Comes\"}',\n",
       "       '{\"Cecilia Leite Costa\",\"Clarissa Perdigao Mello Ferraz\",\"Fabio Miyajima\",\"Fernanda Montenegro de Carvalho Araujo\",\"Fernando Braga Stehling Dias\",\"Germana Silva Vasconcelos\",\"Marcela Helena Gambim Fonseca\",\"Maria Claudia dos Santos Luciano\",\"Maria da Conceicao Rodrigues Fernandes\",\"Tamires Cardoso Matsui\"}',\n",
       "       '{\"Luiz Odorico Monteiro de Andrade\",\"Marcela Helena Gambim Fonseca\"}',\n",
       "       '{\"Ivana Cristina de Holanda Cunha Barreto\",\"Vanira Matos Pessoa\"}',\n",
       "       '{\"Arruda, Carlos André Moura\",\"Bezerra, Maria das Graças Viana\",\"Machado, Márcia Maria Tavares\",\"Machado, Maria de Fátima Antero Sousa\",\"Pessoa, Vanira Matos\",\"Rigotto, Raquel Maria\"}',\n",
       "       '{\"Abolghasem Siyadatpanah\",\"Alysson Pontes Pinheiro\",\"Cristina Rodrigues dos Santos Barbosa\",\"Francisco Assis Bezerra da Cunha\",\"Henrique Douglas Melo Coutinho\",\"Jackelyne Roberta Scherf\",\"Jaime Ribeiro Filho\",\"Maria Apoliana Costa dos Santos\",\"Nair Silva Macedo\",\"Polrat Wilairatana\",\"Thais Pereira Lopes\",\"Thiago Sampaio de Freitas\"}',\n",
       "       '{\"Daniella Castanheira Bartholomeu\",\"Dhelio Batista Pereira\",\"Graziela Maria Zanini\",\"Lilian Lacerda Bueno\",\"Livia Silva Araujo Passos\",\"Mariana Santos Cardoso\",\"Mauro Shugiro Tada\",\"Natalia Satchiko Hojo-Souza\",\"Pedro Henrique Gazzinelli-Guimaraes\",\"Ricardo Toshio Fujiwara\"}',\n",
       "       '{\"Alessandro Leonardo Alvares Magalhaes\",\"Alexandre Freitas da Silva\",\"Edson Delatorre\",\"Erika Lopes Rocha Batista\",\"Fabio Miyajima\",\"Felipe Gomes Naveca\",\"Fernando Vinhal\",\"Filipe Zimmer Dezordi\",\"Gabriel Luz Wallau\",\"Gonzalo Bello\",\"Helisson Faoro\",\"Katia Correa de Oliveira Santos\",\"Marcelo Gomes\",\"Marilda Mendonca Siqueira\",\"Mirleide Cordeiro dos Santos\",\"Paola Cristina Resende\",\"Ricardo Khoury\",\"Tiago Graf\",\"Vanessa Leiko Oikawa Cardoso\"}',\n",
       "       '{\"Cicero Deschamps\",\"Henrique Douglas Melo Coutinho\",\"Jaime Ribeiro Filho\",\"Jenifer Priscila de Araujo\",\"Joara Nalyda Pereira Carneiro\",\"Jose Galberto Martins da Costa\",\"Josefa Carolaine Pereira da Silva\",\"Luiz Everson da Silva\",\"Maria Flaviana Bezerra Morais-Braga\",\"Tais Gusmao da Silva\",\"Waltecio de Oliveira Almeida\",\"Wanderlei do Amaral\"}',\n",
       "       '{\"Alessandra G. M. Pacheco\",\"Amanda L. Guimaraes\",\"Ana P. Oliveira\",\"Camila S. Araujo\",\"Claudia do O. Pessoa\",\"Edigenia C. C. Araujo\",\"Erica M. Lavor\",\"Henrique C. L. Farias\",\"Jackson R. G. S. Almeida\",\"Larissa A. Rolim\",\"Lucas M. M. Marques\",\"Marcilia P. Costa\",\"Mariana G. Silva\",\"Norberto Peporine Lopes\",\"Raimundo G. Oliveira Junior\",\"Rosemairy L. Mendes\"}',\n",
       "       '{\"Galindo, Aureliane Cadengue\",\"Gurgel, Aline do Monte\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Ferdinando Oliveira Carvalho\",\"Gessyka Mayara Soares Gomes\",\"Gladston Thalles da Silva\",\"Lis Maria Machado Ribeiro Bezerra\",\"Rayssa Veras Camelo\",\"Valter Cordeiro Barbosa Filho\"}',\n",
       "       '{\"Andreimar M. Soares\",\"Candida Deves\",\"Carla F. C. Fernandes\",\"Cesar L. Guimaraes\",\"Diogenes S. Santos\",\"Eduardo R. Honda\",\"Leandro S. Moreira-Dill\",\"Leonardo K. B. Marttinelli\",\"Luiz H. Pereira da Silva\",\"Patricia S. M. Medeiros\",\"Rodrigo G. Stabeli\",\"Rudson J. Holanda\",\"Soraya S. Pereira\"}',\n",
       "       '{\"Daiana de Souza Perce-da-Silva\",\"Dalma Maria Banic\",\"Gustavo Capatti Cassiano\",\"JoÃ£o HermÃ\\xadnio Martins da Silva\",\"JosuÃ© da Costa Lima-Junior\",\"Lana Bitencourt Chaves\",\"Lilian Rose Pratt-Riccio\",\"Ricardo Luiz Dantas Machado\",\"Rodrigo Nunes Rodrigues-da-Silva\"}',\n",
       "       '{\"AntÃ´nia Maria Ramos Franco\",\"AntÃ´nio TÃªva\",\"Arturo Reyes-Sandoval\",\"Cesar Lopez-Camacho\",\"Daiana de Souza Perce-da-Silva\",\"Dalma Maria Banic\",\"Francimeire Gomes Pinheiro\",\"Isabela Ferreira Soares\",\"JoÃ£o HermÃ\\xadnio Martins da Silva\",\"JosuÃ© da Costa Lima-Junior\",\"Lana Bitencourt Chaves\",\"Lilian Rose Pratt-Riccio\",\"Rodrigo Nunes Rodrigues-da-Silva\"}',\n",
       "       '{\"Aline Beatriz Mello Rodrigues\",\"Ana Carolina Ramos Guimaraes\",\"Barbara de Oliveira Baptista\",\"Carolina Moreira Blanco\",\"Claudio Tadeu Daniel-Ribeiro\",\"Evelyn Ketty Pratt Riccio\",\"Fabio Faria da Mota\",\"Gisely Cardoso de Melo\",\"Hugo Amorim dos Santos de Souza\",\"Jenifer Peixoto de Barros\",\"Joao Herminio Martins da Silva\",\"Josue da Costa lima Junior\",\"Lilian Rose Pratt-Riccio\",\"Marcus Vinicius Guimaraes de Lacerda\",\"Paulo Renato Rivas Totino\",\"Rodrigo Medeiros de Souza\",\"Victor Fernandes Escafa\"}',\n",
       "       '{\"Birgit Arnholdt-Schmitt\",\"Carlos Noceda\",\"Disraeli Cavalcante Araújo Vasconcelos\",\"João Hermínio Martins da Silva\",\"José Hélio Costa\",\"Karine Leitão lima Thiers\",\"Shahid Aziz\"}',\n",
       "       '{\"Andre Luiz Maia Roque\",\"Birgit Arnholdt-Schmitt\",\"Clesivan Pereira dos Santos\",\"Geraldo Rodrigues Sartori\",\"Joao Herminio Martins da Silva\",\"Jose Helio Costa\",\"Karine Leitao lima Thiers\",\"Katia Daniella da Cruz Saraiva\"}',\n",
       "       '{\"Andre Reynaldo Santos Perisse\",\"Beatriz Fatima Alves de Oliveira\",\"Edenilo Baltazar Barreira Filho\",\"Lucas de Oliveira do Couto\",\"Ludmilla da Silva Viana Jacobson\",\"Roberto Wagner Junior Freire de Freitas\",\"Sandra de Souza Hacon\",\"Sharmenia de Araujo Soares Nuto\"}',\n",
       "       '{\"Andre C. Teixeira\",\"Andre Machado Siqueira\",\"Carolina G. Fernandes\",\"Deborah N. Melo\",\"Fernanda M. C. Araujo\",\"Giovanna R. P. Lima\",\"Jaume Ordi\",\"Joel B. Filho\",\"Lia C. Araujo\",\"Luciano P. G. Cavalcanti\",\"Luis A. B. G. Farias\",\"Miguel J. Martinez\",\"Paulo H. N. Saldiva\",\"Renata A. A. Monteiro\"}',\n",
       "       '{\"Admir Malaj\",\"Amanj Kurdi\",\"Andrew Hill\",\"Angela Timoney\",\"Antony P. Martin\",\"Arianit Jakupi\",\"Brian Godman\",\"Caridad Pontes\",\"Carolina Zampirolli Dias\",\"Christian Hierlander\",\"Corinne Zara\",\"Dominik Tomek\",\"Durhane Wong-Rieger\",\"Eleonora Allocati\",\"Gisbert Selke\",\"Guenka Petrova\",\"Hye-Young Kwon\",\"Ieva Greiciute-Kuprijanov\",\"Ileana Mardare\",\"Irene Langner\",\"Iris Hoxha\",\"Iva Selke Krulichova\",\"J. F. (hans) Piepenbrink\",\"Johanna C. Meyer\",\"John Yfantopoulos\",\"Jolanta Gulbinovic\",\"Jurij Furst\",\"Lars L. Gustafsson\",\"Luka Voncina\",\"Magdalene Wladysiuk\",\"Merce Obach Cortadellas\",\"Olayinka O. Ogunleye\",\"ott Laius\",\"Oyvind Melien\",\"Patricia Vella Bonanno\",\"Robert Sauermann\",\"Roberta Joppi\",\"Ruaraidh Hill\",\"Seungjin Bae\",\"Steven Simoens\",\"Stuart Mctaggart\",\"Tomasz Bochenek\",\"Tracey-Lea Laba\",\"Vanda Markovic-Pekovic\",\"Vincent de Valk\",\"Wania Cristina da Silva\",\"Wija Oortwijn\",\"Wouter Hamelinck\"}',\n",
       "       '{\"Gabriel Acacio de Moura\",\"Juliana Ramos de Oliveira\",\"Larissa Deadame de Figueiredo Nicolete\",\"Roberto Nicolete\",\"Yasmim Mendes Rocha\"}',\n",
       "       '{\"Alberto Jose Cavalheiro\",\"Ana Paula Negreiros Nunes Alves\",\"Camila Maria Longo Machado\",\"Claudia Pessoa\",\"Daniel Pereira Bezerra\",\"Ingrid Samantha Tavares de Figueiredo\",\"Jose Roberto de Oliveira Ferreira\",\"Jurandy do Nascimento Silva\",\"Manoel Odorico de Moraes\",\"Marcilia Pinheiro da Costa\",\"Nylane Maria Nunes Alencar\",\"Paulo Michel Pinheiro Ferreira\",\"Roger Chammas\"}',\n",
       "       '{\"Alexander L. Silva-Junior\",\"Alfredo Mendrone Jr\",\"Anna F. Cavalcante\",\"Carlos A. Prete\",\"Cesar Almeida-Neto\",\"Charles Whittaker\",\"Christopher Dye\",\"David Schlesinger\",\"Ester C. Sabino\",\"Esther Lopes\",\"Fabio Miyajima\",\"Gabrielle T. Nunes\",\"Isabel C. G. Moura\",\"Karine A. Fladzinski\",\"Lewis Buss\",\"Lilyane A. Xabregas\",\"Luana M. de Souza\",\"Lucas Delerino\",\"Luciana M. B. Carlos\",\"Luciane K. Schier\",\"Luiz A. Filho\",\"Maisa A. Ribeiro\",\"Marcia C. Castro\",\"Marcio K. Oikawa\",\"Maria da Silva\",\"Maria I. B. Valenca\",\"Michael P. Busch\",\"Myuki A. E. Crispim\",\"Nanci A. Salles\",\"Nelson Fraiji\",\"Nuno R. Faria\",\"Patricia M. Inoue\",\"Rafael F. O. Franca\",\"Rafael H. M. Pereira\",\"Rosenvaldo E. de Souza\",\"Sheila O. G. Mateos\",\"Sonia mara Nunes da Silva\",\"Suzete C. Ferreira\",\"Tassila Salomon\",\"Veridiana Pessoa\",\"Vitor H. Nascimento\"}',\n",
       "       '{\"Jose Claudio Garcia Lira Neto\",\"Jose Wicto Pereira Borges\",\"Marcio Flavio Moura de Araujo\",\"Marta Maria Coelho Damasceno\",\"Mayra de Almeida Xavier\",\"Roberto Wagner Junior Freire de Freitas\"}',\n",
       "       '{\"Jales Fhelipe de Sousa Fernandes Oliveira\",\"JosÃ© ClÃ¡udio Garcia Lira Neto\",\"MÃ¡rcio FlÃ¡vio Moura de AraÃºjo\",\"Maria AmÃ©lia de Souza\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner JÃºnior Freire de Freitas\"}',\n",
       "       '{\"Marcia Gomes Marinheiro Coelho\",\"Maria de Fatima Antero Sousa Machado\",\"Olivia Andrea Alencar Costa Bessa\",\"Sharmenia de Araujo Soares Nuto\"}',\n",
       "       '{\"Machado, Maria de Fátima Antero Sousa\",\"Maia, Evanira Rodrigues\",\"Moreira, Maria Rosilene Cândido\",\"Nuto, Sharmenia de Araujo Soares\",\"Parente, Natália Campos\",\"Pessoa, Vanira Matos\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira Meyer\",\"Roberto Wagner Júnior Freire de Freitas\",\"Sharmênia de Araújo Soares Nuto\"}',\n",
       "       '{\"Carolina Bioni Garcia Teles\",\"Roberto Nicolete\"}',\n",
       "       '{\"Ernesto Raúl Caffarena\",\"João Hermínio Martins da Silva\"}',\n",
       "       '{\"Alex Chapeaurouge\",\"Andreza Silva\",\"Cassandra Marie Modahl\",\"Jonas Perales\",\"Paulo Carvalho\",\"R. Manjunatha Kini\",\"Ryan J. R. Mccleary\",\"Stephen P. Mackessy\"}',\n",
       "       '{\"Anya Pimentel G. F. Vieira-Meyer\",\"Erico Alexandro Vasconcelos de Menezes\",\"Italo Barroso Bezerra\",\"Krishna Andreia Feitosa Petrola\",\"Maria Vieira de lima Saintrain\",\"Paola Calvasina\"}',\n",
       "       '{\"Anderson M. Kayano\",\"Andre L. Fuly\",\"Andrea A. de Moura\",\"Andreimar M. Soares\",\"Auro Nomizo\",\"Carla F. C. Fernandes\",\"George A. Oliveira\",\"Joao G. Ribeiro\",\"Juliana P. Zuliani\",\"Laura A. Moura\",\"Leonardo A. Calderon\",\"Neuza B. Barros\",\"Roberto Nicolete\",\"Rodrigo G. Stabeli\",\"Saulo L. da Silva\",\"Sulamita S. Setubal\"}',\n",
       "       '{\"Ana Lucia Lira Pessoa de Souza\",\"Camila Drumond Muzi\",\"Daniela GuimarÃ£es Ferreira da Silva\",\"Raphael MendonÃ§a GuimarÃ£es\",\"Thais Martins Pedrosa\",\"Thalyta Cassia de Freitas Martins\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Fabiane Do Amaral Gubert\",\"Isaura LetÃ\\xadcia Tavares Palmeira Rolim\",\"Maria Do Socorro Vieira Lopes\",\"Mariana Cavalcante Martins\",\"Rejane Christine de Sousa Queiroz\",\"Renata de Sousa Alves\",\"Valter Cordeiro Barbosa Filho\"}',\n",
       "       '{\"Galba Freire Moita\",\"Galba Freire Moita JÃºnior\"}',\n",
       "       '{\"Alessandra Xavier de Padua\",\"Alvaro de Baptista Neto\",\"Daniel Lopes Branco\",\"Elenira H. M. Mendonca\",\"Luis Henrique Romano\",\"Marcos Roberto Lourenzoni\",\"Nilton Cesar Avanci\",\"Richard John Ward\"}',\n",
       "       '{\"Fabiano Duarte Carvalho\",\"Fernando Braga Stehling Dias\",\"Gabriel Sylvestre Ribeiro\",\"Joao Silveira Moledo Gesto\",\"Julia Peixoto\",\"Luciano Andrade Moreira\",\"Marcele Neves Rocha\",\"Thiago Nunes Pereira\"}',\n",
       "       '{\"Davi Queiroz de Carvalho Rocha\",\"Everton Do Carmo Barbosa\",\"Fernando JosÃ© Herkrath\",\"Maximiliano Loiola Ponte de Souza\"}',\n",
       "       '{\"Pimentel Gomes Fernandes Vieira Meyer, Anya\",\"Vieira de lima Saintrain, Maria\"}',\n",
       "       '{\"AndrÃ© F.A. Xavier\",\"Claudia Pessoa\",\"Daniel P. Pinheiro\",\"Fernando C. Da Silva\",\"Maria F.S. Silva\",\"Mariana F.C. Cardoso\",\"Marilia O.F. Goulart\",\"Thaissa L. Silva\",\"Vitor F. Ferreira\",\"Yen G. De Paiva\"}',\n",
       "       '{\"Anya PGF Vieira-Meyer\",\"Bruna MDF de Carvalho\",\"Camila P FeijÃ£o\",\"George TM Candeiro\",\"Jiovanne R Neri\",\"JosÃ© VM Lemos\",\"Rafael L Avelar\"}',\n",
       "       '{\"Barreto, Ivana Cristina de Holanda Cunha\",\"Evangelista, Aline Luiza de Paulo\",\"Frota, Amanda Cavalcante\",\"Torres, Rafael Bruno Silva\"}',\n",
       "       '{\"C. Pessoa\",\"C. R. A. Maltha\",\"F. W. A. Barros-Nepomuceno\",\"I. S. Bomfim\",\"L. C. A. Barbosa\",\"M. O. Moraes\",\"S. S. Maranhao\",\"T. A. Moreira\",\"U. A. Pereira\"}',\n",
       "       '{\"Alexander L. Silva-Junior\",\"Alfredo Mendrone-Junior\",\"Anna F. Cavalcante\",\"Carlos A. Prete\",\"Cesar de Almeida-Neto\",\"Charles Whittaker\",\"Christopher Dye\",\"Ester C. Sabino\",\"Esther Lopes\",\"Fabio Miyajima\",\"Fernando L. V. Araujo\",\"Gabrielle T. Nunes\",\"Isabel C. G. Moura\",\"Karine A. Fladzinski\",\"Lewis F. Buss\",\"Lilyane A. Xabregas\",\"Luana M de Souza\",\"Lucas Delerino\",\"Luciana M. B. Carlos\",\"Luciane K. Schier\",\"Luiz A. Filho\",\"Maisa A. Ribeiro\",\"Manoel Barral Netto\",\"Marcia C. Castro\",\"Marcio K. Oikawa\",\"Maria I. B. ValenÃ§a\",\"Maria V. da Silva\",\"Michael P. Busch\",\"Myuki A. E. Crispim\",\"Nanci A. Salles\",\"Natalia Machado Tavares\",\"Nelson Fraiji\",\"Nuno R. Faria\",\"Oliver Ratmann\",\"Patricia M. Inoue\",\"Rafael F. O. Franca\",\"Rafael H. M. Pereira\",\"Rosenvaldo E. de Souza\",\"SÃ´nia M. N. da Silva\",\"Sheila O. G. Mateos\",\"Suzete C. Ferreira\",\"Tassila Salomon\",\"VÃ\\xadtor H. Nascimento\",\"Veridiana Pessoa\",\"Viviane Sampaio Boaventura\"}',\n",
       "       '{\"Maia, Lizaldo Andrade\",\"Morais, Ana Patrícia Pereira\",\"Saintrain, Maria Vieira de lima\",\"Soares Nuto, Sharmênia de Araújo\",\"Vieira-Meyer, Anya Pimentel Gomes Fernandes\"}',\n",
       "       '{\"Andrade, Naila Saskia Melo\",\"Bezerra, Maria das Graças Viana\",\"Carneiro, Fernando Ferreira\",\"Lopes, Isabelle Bernardina da Silva\",\"Pessoa, Vanira Matos\",\"Silva, Luiz Rons Caúla\"}',\n",
       "       '{\"Dias, Elizabeth Costa\",\"Fernandes, Luisa da Matta Machado\",\"Gomes, Edinalva Maria\",\"Lacerda E. Silva, Thais\",\"Pessoa, Vanira Matos\"}',\n",
       "       '{\"Lima, Aluísio Ferreira de\",\"Viana, Diego Mendonça\"}',\n",
       "       '{\"Cheila Pires Raquel\",\"Daiana FlÃ¡via Oliveira de Souza\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Kelen Gomes Ribeiro\",\"Luiz Odorico Monteiro de Andrade\",\"Nadyelle Elias Santos Alencar\"}',\n",
       "       '{\"Ana Rafaela Freitas Dotto\",\"Andressa Kelly Ferreira e Silva\",\"Antonio Linkoln Alves Borges Leal\",\"Camila Fonseca Bezerra\",\"Carla Freire Celedonio Fernandes\",\"Emanuelle Machado Marinho\",\"Emmanuel Silva Marinho\",\"Francisco Wagner Almeida-Neto\",\"HÃ©lcio Silva dos Santos\",\"Henrique D. M. Coutinho\",\"Humberto Medeiros Barreto\",\"Lucas Lima Bezerra\",\"Luiz Everson da Silva\",\"Marcia Machado Marinho\",\"Matheus Nunes da Rocha\",\"Pedro de Lima-Neto\",\"Wanderlei do Amaral\"}',\n",
       "       '{\"David F. C. Moura\",\"FabrÃ\\xadcio A. B. Da Silva\",\"Juraci F. Galdino\"}',\n",
       "       '{\"Christiane Schineider Machado\",\"ClÃ¡udia Pessoa\",\"Daiane Finger\",\"FÃ¡tima de Cassia Evangelista de Oliveira\",\"Marta Chagas Monteiro\",\"Thaiana Cristina Dias De Lima\",\"ThaynÃ¡ Modesto\",\"Yohandra Reyes Torres\"}',\n",
       "       '{\"Assuero S. Meira\",\"Bernardo L. Rodrigues\",\"Brenno A. D. Neto\",\"Carlos A. de Simone\",\"Claudia Pessoa\",\"Eufranio N. da Silva Junior\",\"Fabricia R. Ferreira\",\"Gleiston G. Dias\",\"Hallen D. R. Calado\",\"Jarbas M. Resende\",\"Jose R. Correa\",\"Marilia O. F. Goulart\",\"Valter H. C. Silva\"}',\n",
       "       '{\"Carlos Alessandro Fuzo\",\"Lara Aparecida Buffoni de Campos Carneiro\",\"Luana Parras Meleiro\",\"Marcos Roberto Lourenzoni\",\"Marcos Silveira Buckeridge\",\"Matheus Quintana Barreto\",\"Richard John Ward\",\"Sibeli Carli\"}',\n",
       "       '{\"Camila T. M. N. Porfirio\",\"Celso S. Nagano\",\"Cleverson D. T. Freitas\",\"Francisco A. P. Campos\",\"Ghulam Hussain\",\"Gilvan P. Furtado\",\"Joao P. B. Oliveira\",\"Jose S. S. Barbosa\",\"Marcio V. Ramos\",\"Pedro F. N. Souza\",\"Rodolpho G. G. Silva\",\"Samuel F. Freitas\",\"Thalia L. Frota\"}',\n",
       "       '{\"Anne Carolinne Bezerra Perdigao\",\"Carlos Henrique Alencar\",\"Fernanda Montenegro de Carvalho Araujo\",\"Giovanna Rolim Pinheiro Lima\",\"Jose lima de Carvalho Rocha\",\"Luciano Pamplona de goes Cavalcanti\",\"Magda Moura de Almeida\",\"Marcela Helena Gambim Fonseca\",\"Nayara Santos de Oliveira\",\"Pamela de Castro Franca\",\"Paulo Goberlanio Barros Silva\",\"Wanderson Kleber de Oliveira\"}',\n",
       "       '{\"Andre Machado Siqueira\",\"Andre Ricardo Ribas Freitas\",\"Carlos Henrique Alencar\",\"Daniele Rocha Queiroz Lemos\",\"Fabio Miyajima\",\"Fernanda Montenegro de Carvalho Araujo\",\"Francisca Kalline de Almeida Barreto\",\"Isac Lucca Frota Boriz\",\"John Washington Cavalcante\",\"Leticia Queiroz Medeiros\",\"Luciano Pamplona de goes Cavalcanti\",\"Luis Arthur Brasil Gadelha Farias\",\"Marcelo Nunes Pereira Melo\",\"Rhaquel de Morais Alves Barbosa Oliveira\"}',\n",
       "       '{\"Anete Sevciovic Grumach\",\"Francisca Jacinta Feitoza de Oliveira\",\"Leonardo Hunaldo dos Santos\",\"Marcio Flavio Moura de Araujo\",\"Maria Aparecida Alves de Oliveira Serra\",\"Rosemeire Navickas Constantino da Silva\"}',\n",
       "       '{\"Aline Santos Monte\",\"Camila Nayane de Carvalho Lima\",\"Clarissa S Gama\",\"Danielle S Macedo\",\"David Freitas de Lucena\",\"FÃ¡bio Miyajima\",\"Francisco EliclÃ©cio Rodrigues da Silva\",\"Germana Silva Vasconcelos\",\"Mary V Seeman\",\"Nayana Soares Gomes\",\"Silvania Maria Mendes Vasconcelos\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Gideon Borges dos Santos\",\"Katia Mendes de Souza\",\"Virginia Alonso Hortale\"}',\n",
       "       '{\"Ana Fidelina Gomez\",\"Anderson M. Kayano\",\"Andreimar M. Soares\",\"Carla Freire C. Fernandes\",\"Erika A. Bastos-Soares\",\"Fernando B. Zanchi\",\"Jorge Alfonso\",\"Maribel E. Funes-Huacca\",\"Rodrigo G. Stabeli\",\"Rosa Maria O. Sousa\",\"Soraya S. Pereira\"}',\n",
       "       '{\"Aline Souza da Fonseca\",\"Andreimar Martins Soares\",\"Carla Freire Celedonio Fernandes\",\"ClÃ©berson de Freitas Fernandes\",\"FÃ¡bio da Silva Barbieri\",\"Francisco das Chagas Oliveira Freire\",\"JosÃ© Roberto Vieira JÃºnior\",\"Luciana Gatto Brito\",\"Marcos Barros Luiz\",\"Rita de CÃ¡ssia Alves\",\"Rodrigo Barros Rocha\",\"Simone Carvalho Sangi\",\"Soraya dos Santos Pereira\",\"Tamiris Chaves Freire\"}',\n",
       "       '{\"Alberto Pellegrini Filho\",\"Felix Rigoli\",\"Fernanda Natasha Bravo Cruz\",\"Kelen Gomes Ribeiro\",\"Ligia Malagon de Salazar\",\"Luiz Odorico Monteiro de Andrade\",\"Orielle Solar\",\"Pastor Castell-Florit Serrate\",\"Rifat Atun\",\"Theadora Swift Koller\"}',\n",
       "       '{\"Ana Cristina P. J. Costa\",\"Antoninho B. Milhomem\",\"Antonio Uelton A. Silva\",\"Francisca Aline A. S. Santos\",\"Marcio Flavio M. Araujo\",\"Maria Aparecida A. O. Serra\",\"Maria da Conceicao S. O. Cunha\",\"Roberta Araujo E. Silva\",\"Roberto Wagner Junior Freire de Freitas\",\"Samae B. Oliveira\"}',\n",
       "       '{\"Cecilia S. Andreazzi\",\"Emmanuel M. Vilar\",\"Fabiana L. Rocha\",\"Gabriella L. T. Cruz\",\"Gisele R. Winck\",\"Hugo Fernandes-Ferreira\",\"Jose Luis P. Cordeiro\",\"Marina G. Bueno\",\"Martha Macedo de lima Barata\",\"Paulo Sergio D\\'andrea\",\"Rafael L. G. Raimundo\"}',\n",
       "       '{\"Barry J. Campbell\",\"Cameron R. Leiper\",\"Carol L. Roberts\",\"Carrie A. Duckworth\",\"Ellie Trotter\",\"Fabio Miyajima\",\"Hannah L. Simpson\",\"Jonathan M. Rhodes\",\"Louise M. Thompson\",\"Nehana Gittens\",\"Niamh O\\'kennedy\",\"Paul Roberts\",\"Stamatia Papoutsopoulou\"}',\n",
       "       '{\"Agatha Costa\",\"Alessandro Leonardo Alvares Magalhaes\",\"Alex Martins\",\"Andre de lima Corado\",\"Cristiano Fernandes\",\"Danilo Coelho\",\"Debora Duarte\",\"Edson Delatorre\",\"Eduardo Ruback dos Santos\",\"Erika Lopes Rocha Batista\",\"Fabio Miyajima\",\"Fabiola Mendonca Chui\",\"Felipe Gomes Naveca\",\"Fernanda Nascimento\",\"Fernando Braga Stehling Dias\",\"Fernando Fonseca Val\",\"Fernando Vinhal\",\"Gabriel Luz Wallau\",\"George Silva\",\"Gisely Cardoso de Melo\",\"Gonzalo Bello\",\"Joao Hugo Santos\",\"Karina Pessoa\",\"Ligia Abdalla\",\"Lucas Carlos Gomes Pereira\",\"Luciana Goncalves\",\"Marcus Vinicius Lacerda\",\"Maria Julia Brandao\",\"Maria Paula Mourao\",\"Mariana Simao Xavier\",\"Marilda Mendonca Siqueira\",\"Matheus Ferraz\",\"Matilde Contreras Mejia\",\"Michele Jesus\",\"Nathania Dabilla\",\"Paola Cristina Resende\",\"Roberto Lins\",\"Tiago Graf\",\"Tirza Mattos\",\"Valdinete Nascimento\",\"Vanderson de Souza Sampaio\",\"Victor Souza\"}',\n",
       "       '{\"Fabio Solon Tajra\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Luiz Odorico Monteiro de Andrade\",\"Neusa Goya\",\"Ricardo Jose Soares Pontes\"}',\n",
       "       '{\"Aline Luiza de Paulo Evangelista\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Rafael Bruno Silva Torres\",\"Roberto Wagner Junior Freire de Freitas\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Maria de Fatima Antero Sousa Machado\",\"Maria do Socorro de Sousa\",\"Maria Socorro de Araujo Dias\",\"Neiva Francenely Cunha Vieira\"}',\n",
       "       '{\"Antonio Augusto Fidalgo-Neto\",\"Cristina Alves Magalhaes de Souza\",\"Dinarte Neto Moreira Ferreira\",\"Ernesto Raul Caffarena\",\"Joao Herminio Martins da Silva\",\"Luiz Anastacio Alves\",\"Monica Santos de Freitas\",\"Pedro Celso Nogueira Teixeira\"}',\n",
       "       '{\"Bruno Anderson Matias Rocha\",\"João Pedro Fernandes Queiroz\",\"Marcos Roberto Lourenzoni\"}',\n",
       "       '{\"Amauri H. Souza\",\"Carlos A. F. Sales\",\"Carlos H. L. Cavalcante\",\"Emmanuel S. Marinho\",\"Helcio S. Santos\",\"Joao A. L. Marques\",\"Joao H. M. Silva\",\"Joao P. V. Madeiro\",\"Pedro E. O. Primo\",\"Roberto C. Pedrosa\",\"Weslley L. Caldas\"}',\n",
       "       '{\"FÃ¡bio Lima CustÃ³dio\",\"Raphael Trevizani\"}',\n",
       "       '{\"Alcides J. M. da Silva\",\"Arinice M. Costa\",\"Claudia O. Pessoa\",\"Edezio Ferreira Cunha-Junior\",\"Eduardo Caio Torres-Santos\",\"Gardenia C. G. Militao\",\"Leticia V. Costa-Lotufo\",\"Paulo R. R. Costa\",\"sara L. S. Gomes\"}',\n",
       "       '{\"Antonio L. Braga\",\"Bruno C. Cavalcanti\",\"Carlos A. de Simone\",\"Claudia Pessoa\",\"David A. Boothman\",\"Divya K. Nair\",\"Eduardo H. G. da Cruz\",\"Eufranio N. da Silva Junior\",\"Giancarlo V. Botteselle\",\"Guilherme A. M. Jardim\",\"Igor S. Bomfim\",\"Irishi N. N. Namboothiri\",\"Jarbas M. Resende\",\"Molly A. Silvers\"}',\n",
       "       '{\"Adriana A. Carvalho\",\"Andr L. B. S. Barreiros\",\"Claudia Pessoa\",\"Fernanda S. Andrade\",\"Francisco W. A. Barros-Nepomuceno\",\"Jorge M. David\",\"Manoel O. de Moraes\",\"Marcelo A. S. dos Santos\",\"Maria Claudia S. Luciano\",\"Marizeth L. Barreiros\",\"Mauricio M. Victor\"}',\n",
       "       '{\"Aline dos Santos Peixoto\",\"Arnaud Tatibouet\",\"Brijesh Rathi\",\"Claudia do O. Pessoa\",\"Cybele Flavia do Amaral Moura\",\"Heverton Mendes Araujo\",\"Janaina Versiani dos Anjos\",\"Lilian Maria Lapa Montenegro Pimentel\",\"Lindomar Jose Pena\",\"Patrick Rollin\",\"Prem Prakash Sharma\",\"Roberto Nicolete\",\"Ronaldo Nascimento de Oliveira\",\"Valentina Nascimento Melo de Oliveira\",\"Vanessa Pinheiro Goncalves Ferreira\"}',\n",
       "       '{\"Augusto C. A. Oliveira\",\"Bruno C. Cavalcanti\",\"Carlos M. R. Sant\\'anna\",\"Claudia Pessoa\",\"Daniel N. do Amaral\",\"Eliezer J. Barreiro\",\"Harold H. Fokoue\",\"Lidia M. Lima\",\"Maria L. G. Porras\",\"Teiliane R. Carneiro\"}',\n",
       "       '{\"Alexandre M. R. Teixeira\",\"Claudia Pessoa\",\"Daniel P. Pinheiro\",\"Francisco W. A. Barros-Nepomuceno\",\"Helcio S. Santos\",\"Herbert S. Magalhaes\",\"Manoel O. de Moraes Filho\",\"Mylena C. S. de Carvalho\",\"Paulo N. Bandeira\",\"Paulo R. Ribeiro\",\"Telma L. G. Lemos\",\"Tigressa H. S. Rodrigues\"}',\n",
       "       '{\"Claudia Pernencar\",\"Deivith Oliveira\",\"Inga Saboia\",\"Ivana Barreto\",\"Luiz Odorico Monteiro\",\"Paulo Aguilar\",\"Rebecca Theophilo\"}',\n",
       "       '{\"Christine A. Romana\",\"Fernando Braga Stehling Dias\",\"Lileia Diotaiuti\",\"Marion Quartier\",\"Myriam Harry\"}',\n",
       "       '{\"Carla Regina De Souza Teixeira\",\"Gerdane Celene Nunes Carvalho\",\"HÃ©rica Cristina Alves De Vasconcelos\",\"JosÃ© Claudio Garcia Lira Neto\",\"MÃ¡rcio FlÃ¡vio Moura De AraÃºjo\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner JÃºnior Freire De Freitas\"}',\n",
       "       '{\"Alberto Novaes Ramos\",\"Anderson Fuentes Ferreira\",\"Daniel Barros de Castro\",\"Dulciene Maria MagalhÃ£es Queiroz\",\"FÃ¡bio Miyajima\",\"Fernando AntÃ´nio Siqueira Pinheiro\",\"Jorg Heukelbach\",\"Lucia Libanez Bessa Campelo Braga\",\"Tiago Gomes da Silva Benigno\"}',\n",
       "       '{\"Ana Carolina Justino de Araujo\",\"Cicera Laura Roque Paulo\",\"Gustavo Marinho Miranda\",\"Henrique D. M. Coutinho\",\"Jaime Ribeiro Filho\",\"Jonatas Reis Bessa\",\"Jose Bezerra de Araujo Neto\",\"Kaio Jefte Santos de Oliveira Dias\",\"Priscilla Ramos Freitas\",\"Ray Silva de Almeida\"}',\n",
       "       '{\"Afonso Gomes Abreu\",\"Alberto Jorge Oliveira Lopes\",\"Anderson FranÃ§a da Silva\",\"Arthur AndrÃ© Castro da Costa\",\"ClÃ¡udia Quintino da Rocha\",\"Cristina Andrade Monteiro\",\"Elizabeth Soares Fernandes\",\"Elizangela Pestana Motta\",\"Flavia Raquel Fernandes Nascimento\",\"Josivan Regis Farias\",\"Maria do Socorro Sousa CartÃ¡genes\",\"Roberto Nicolete\",\"Rosane Nassar Meireles Guerra\"}',\n",
       "       '{\"Anya P G F Vieira-Meyer\",\"Jamille Barreto Oliveira\",\"Mateus Mota Pontes\",\"Paola Calvasina\",\"Patricia O\\'Campo\"}',\n",
       "       '{\"Alexandre A. Barbosa\",\"Eliseu J. Weber\",\"Francisco B. Pontual\",\"Francisco E. Aquino\",\"Gabriel S. Hofmann\",\"Heinrich Hasenack\",\"Jose L. P. Cordeiro\",\"Leandro de O. Salles\",\"Luiz F. B. de Oliveira\",\"Manoel F. Cardoso\",\"peter M. de Toledo\",\"Ruy J. V. Alves\"}',\n",
       "       '{\"Amanda de Oliveira Matos\",\"Bruno Junior Neves\",\"Carolina Horta Andrade\",\"Geraldo Rodrigues Sartori\",\"Helioswilton Sales-Campos\",\"João Herminio Martins da Silva\",\"Marcelle Silva-Sales\",\"Mike Telemaco Contreras Colmenares\",\"Pedro Henrique dos Santos Dantas\"}',\n",
       "       '{\"Ana Carolina Feldenheimer da Silva\",\"Elisabetta Gioconda Iole Giovanna Recine\",\"Glenn Makuta\",\"InÃªs Rugani Ribeiro de Castro\",\"Janine Giuberti Coutinho\",\"Nayara CortÃªs Rocha\",\"Paula Johns\",\"Raphael Barreto da ConceiÃ§Ã£o Barbosa\"}',\n",
       "       '{\"Adriana S. Pontes\",\"Andreimar M. Soares\",\"Carla F. C. Fernandes\",\"Caroline V. Xavier\",\"Eduardo R. Honda\",\"Fabianne Lacouth-Silva\",\"Fernando B. Zanchi\",\"Izaltina Silva-Jardim\",\"Juliana P. Zuliani\",\"Leonardo A. Calderon\",\"Neriane M. Nery\",\"Onassis Boeri de Castro\",\"Rodrigo G. Stabeli\",\"Sulamita da S. Setubal\",\"Valdir A. Facundo\"}',\n",
       "       '{\"Carolina Maria de lima Carvalho\",\"Edmara Chaves Costa\",\"Lilian Raquel Alexandre Uchoa\",\"Marcio Flavio Moura de Araujo\",\"Maria Aparecida Alves de Oliveira Serra\",\"Maria da Conceicao do Santos Oliveira Cunha\",\"Maria do Livramento de Paula\",\"Maria Wendiane Gueiros Gaspar\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner Junior Freire de Freitas\",\"Thiago Moura de Araujo\",\"Vivian Saraiva Veras\"}',\n",
       "       '{\"Brenda Oliveira Rocha\",\"Eimear Nic Lughadha\",\"Iury Leite Cruz\",\"JosÃ© LuÃ\\xads Passos Cordeiro\",\"Marcelo Freire Moro\",\"Moabe Ferreira Fernandes\",\"Paulo Weslem Portal Gomes\",\"Ravena Santiago Alves\",\"Taynara Rabelo-Costa\",\"TiÃª Rocha de Sousa Oliveira\"}',\n",
       "       '{\"Ã\\x89verton LuÃ\\xads Pereira\",\"BÃ¡rbara Lyrio Ursine\",\"Fernando Ferreira Carneiro\"}',\n",
       "       '{\"Ana Mattos Brito de Almeida\",\"Ana PatrÃ\\xadcia Pereira Morais\",\"Anamaria Cavalcante e Silva\",\"Anya Pimentel Gomes Fernandes Vieira Meyer\",\"EmÃ\\xadlia Soares Chaves\",\"Fabiane do Amaral Gubert\",\"Jocileide Sales Campos\",\"Maria de FÃ¡tima Antero Sousa Machado\",\"Maria Socorro de AraÃºjo Dias\",\"Maristela InÃªs Osawa Chagas\",\"Yana Paula CoÃªlho Correia Sampaio\"}',\n",
       "       '{\"Carlos Andre Moura Arruda\",\"Diego Dewes\",\"Helena eri Shimizu\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Joselia de Souza Trindade\",\"Leonor Maria Pacheco Santos\",\"Vanira Matos Pessoa\",\"Yamila Comes\"}',\n",
       "       '{\"Felipe Arley Costa Pessoa\",\"Marlos de Medeiros Chaves\"}',\n",
       "       '{\"Grecy Kelli Estevam\",\"Ian Carlos Gomes Lima\",\"Maria Sandra Costa Amaral\",\"Marilene Penatti\",\"Najla Benevides Matos\",\"Paula Katharine Pontes Spada\",\"Roger Lafontaine\",\"Yvone Benchimol Gabbay\"}',\n",
       "       '{\"Almeida, Lúcio Hélio Pereira de\",\"Lourenço, Caroline Barbosa\",\"Marques, Paulo Leonardo Ponte\",\"Saintrain, Maria Vieira de lima\",\"Silva, Raimunda Magalhães da\",\"Vieira, Anya Pimentel Gomes Fernandes\"}',\n",
       "       '{\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Diego Gibson Praxedes Martins\",\"Karine MagalhÃ£es Fernandes Vieira\",\"Maria Vieira de Lima Saintrain\",\"RaÃ\\xadsa Lima Silva\"}',\n",
       "       '{\"Carlos Alessandro Fuzo\",\"Davi Serradella Vieira\",\"M. Cristina Nonato\",\"Marcos Roberto Lourenzoni\",\"Matheus Pinto Pinheiro\",\"Richard John Ward\",\"Samuel Reghim Silva\",\"Sérgio Bergamachi Silva\",\"Tatiane Lopes Ferreira\"}',\n",
       "       '{\"Fernando Jose Herkrath\",\"Maximiliano Loiola Ponte de Souza\",\"Nathalia Paz Caranha\"}',\n",
       "       '{\"F. C. Gozzo\",\"M. R. Lourenzoni\",\"N. F. Frota\",\"R. A. S. Pirolla\",\"S. B. Morais\",\"T. A. C. B. Souza\"}',\n",
       "       '{\"AluÃ\\xadsio Marques da Fonseca\",\"Bernardino Joaquim Caluaco\",\"Carla Freire Celedonio Fernandes\",\"Emmanuel Silva Marinho\",\"HÃ©lcio Silva dos Santos\",\"Pedro de Lima-Neto\",\"Regilany Paulo Colares\",\"Sadrack Queque Cabongo\"}',\n",
       "       '{\"Amanda Cavalcante Frota\",\"Ana Ecilda lima Ellery\",\"Francisco Antonio Loiola\",\"Ivana Cristina de Holanda Cunha Barreto\",\"Kelen Gomes Ribeiro\",\"Luiz Odorico Monteiro de Andrade\",\"Raquel de Castro Alves Nepomuceno\"}',\n",
       "       '{\"Diego V. Garreto\",\"Fernando B. da Costa\",\"Flavia R. F. Nascimento\",\"Jessica F. F. de Oliveira\",\"Marcos A. G. Grisotto\",\"Mayara C. P. da Silva\",\"Rejane B. de Oliveira\",\"Roberto Nicolete\",\"Thiare S. Fortes\"}',\n",
       "       '{\"Adriano Lucio Peracchi\",\"Jose Luis Passos Cordeiro\",\"Luiz Flamarion Barbosa de Oliveira\",\"Marcione Brito de Oliveira\",\"Martha Macedo de lima Barata\"}',\n",
       "       '{\"Alice Sampaio Barreto da Rocha\",\"Ana Carolina da Fonseca Mendonca\",\"Anna Carolina Dias Paixao\",\"Cassia Docena\",\"Darcita Buerger Rovaris\",\"Edson Delatorre\",\"Elisa Cavalcante Pereira\",\"Fabio Miyajima\",\"Felicidade Mota Pereira\",\"Felipe Gomes Naveca\",\"Filipe Zimmer Dezordi\",\"Gabriel Luz Wallau\",\"Gonzalo Bello\",\"Joaquim Cesar Sousa\",\"Lais Ceschini Machado\",\"Leticia Garay Martins\",\"Luciana Appolinario\",\"Marcelo Henrique Santos Paiva\",\"Marilda Mendonca Siqueira\",\"Matheus Filgueira Bezerra\",\"Paola Cristina Resende\",\"Renata Serrano Lopes\",\"Richard Steiner Salvato\",\"Rodrigo Ribeiro-Rodrigues\",\"Sandra Bianchini Fernandes\",\"Taina Moreira Martins Venas\",\"Tatiana Schaffer Gregianini\",\"Thais Oliveira Costa\",\"Tiago Graf\",\"Valdinete Alves do Nascimento\",\"Victor Costa de Souza\"}',\n",
       "       '{\"Alan Freihof Tygel\",\"Fernando Ferreira Carneiro\",\"karen Friedrich\",\"Leonardo Melgarejo\",\"Vicente Eduardo Soares de Almeida\"}',\n",
       "       '{\"Bruno Cavalcante Fales de Brito Alves\",\"Carolina Gomes Fernandes\",\"Deborah Nunes Melo\",\"Fernanda Montenegro de Carvalho Araujo\",\"Giovanna Rolim Pinheiro Lima\",\"Jaume Ordi\",\"Luciano Pamplona de goes Cavalcanti\",\"Paulo Hilario do Nascimento Saldiva\",\"Renata Aparecida de Almeida Monteiro\",\"Tania mara Coelho\"}',\n",
       "       '{\"Cícero Deivid Bezerra de Morais\",\"Francisca Stefane do Nascimento Andrade\",\"Francisco Leonardo da Silva Feitosa\",\"Isadora Gislene Lopes de Souza\",\"Jaime Ribeiro Filho\",\"José Leonardo Gomes Coelho\",\"Karine Rocha da Cruz\",\"Linaria Martins Ferreira\",\"Lorena Monte Sousa\",\"Paulo Jefter Marciel Maia\",\"Rejane Cristina Fiorelli de Mendonça\"}',\n",
       "       '{\"Fernando Jose Herkrath\",\"Maximiliano Loiola Ponte de Souza\",\"Priscilla Dias Leite de Lima\"}',\n",
       "       '{\"Beatriz Iandra da Silva Ferreira\",\"Fabio Miyajima\",\"Livia Melo Villar\",\"Luciane Almeida Amado Leon\",\"Marisa Pimentel Amaro\",\"Natalia Lins da Silva Gomes\",\"Otacilio Cruz Moreira\",\"Rafael Lopes Kader\",\"Soniza Vieira Alves-Leon\",\"Vanessa Cristine de Souza Carneiro\",\"Vanessa Duarte da Costa\",\"Vanessa Salete de Paula\",\"Wagner Luis da Costa Nunes Pimentel Coelho\"}',\n",
       "       '{\"Ana Patricia P. Morais\",\"Anya P. G. F. Vieira-Meyer\",\"Drew Cameron\",\"Fabiane A. Gubert\",\"Lia Fernald\",\"Maria de Fatima A. S. Machado\",\"Maria Vieira L. Saintrain\",\"Sarah Reynolds\",\"Tala Katarina Ram\",\"Yana Paula Sampaio\"}',\n",
       "       '{\"Ana PatrÃ\\xadcia Pereira Morais\",\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Isabella Lima Barbosa Campelo\",\"JosÃ© Maria Ximenes GuimarÃ£es\"}',\n",
       "       '{\"Aisha Khizar Yousafzai\",\"Ana Patricia Pereira Morais\",\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Helena Paula Guerra dos Santos\",\"Isabella lima Barbosa Campelo\",\"Jose Maria Ximenes Guimaraes\"}',\n",
       "       '{\"Roberto Wagner Júnior Freire de Freitas\",\"Vanira Matos Pessoa\"}',\n",
       "       '{\"Antonio Marinho da Silva Neto\",\"Cleber Furtado Aksenen\",\"Filipe Zimmer Dezordi\",\"Gabriel Luz Wallau\",\"Pedro Miguel Carneiro Jeronimo\",\"Suzana Porto Almeida\",\"Tulio de lima Campos\"}',\n",
       "       '{\"Gerdane Celene Nunes Carvalho\",\"Marcio Flavio Moura de Araujo\",\"Maria Lucia Zanetti\",\"Marta Maria Coelho Damasceno\",\"Roberto Wagner Junior Freire de Freitas\"}',\n",
       "       '{\"Ana Cristina Pereira de Jesus Costa\",\"Antonio Carlos Vieira Ramos\",\"Claudia Regina de Andrade Arrais Rosa\",\"Floriacy Stabnow Santos\",\"Giana Gislanne da Silva de Sousa\",\"Hamilton Leandro Pinto de Andrade\",\"Iolanda Graepp Fontoura\",\"Jaisane Santos Melo Lobato\",\"Livia Fernanda Siqueira Santos\",\"Livia Maia Pascoal\",\"Marcelino Santos Neto\",\"Marcio Flavio Moura de Araujo\",\"Maria Aparecida Alves de Oliveira Serra\",\"Mellina Yamamura\",\"Ricardo Alexandre Arcencio\"}',\n",
       "       '{\"Ana Mattos Brito de Almeida\",\"Anya Pimentel Gomes Fernandes Vieira-Meyer\",\"Emilia Soares Chaves Rouberte\",\"Lia Fernald\",\"Maria de Fatima Antero Sousa Machado\",\"Maria Socorro de Araujo Dias\",\"Maria Vieira de lima Saintrain\",\"Maristela Ines Osawa Vasconcelos\",\"Sarah Ann Reynolds\",\"Suzanne Dufault\",\"Themis Xavier de Albuquerque Pinheiro\"}',\n",
       "       '{\"Eric Pearce Caragata\",\"Fernando Braga Stehling Dias\",\"Heverton Leandro Carneiro Dutra\",\"Luciano Andrade Moreira\",\"Marcele Neves Rocha\",\"Simone Brutman Mansur\"}'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fioce_2008_2013['Autores '].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>Título</th>\n",
       "      <th>Ano</th>\n",
       "      <th>Resumo</th>\n",
       "      <th>Palavras-chaves do autor</th>\n",
       "      <th>Veículo de publicação</th>\n",
       "      <th>Tipologia documental</th>\n",
       "      <th>Instiuições</th>\n",
       "      <th>Unidades/ Siglas</th>\n",
       "      <th>Autores</th>\n",
       "      <th>Áreas do conhecimento CNPq (lattes do servidor)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(des)controle dos Indicadores Clínicos em Pacientes Atendidos pelo Programa Hiperdia</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"HIPERTENSÃO ARTERIAL\",\"diabetes mellitus\",\"indicadores clínicos\",\"Estratégia Saúde da Família\"}</td>\n",
       "      <td>18º Senpe - Seminário Nacional de Pesquisa em Enfermagem</td>\n",
       "      <td>Comunicação em evento</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Fiocruz/Ceará}</td>\n",
       "      <td>{\"Roberto Wagner Júnior Freire de Freitas\"}</td>\n",
       "      <td>{CIENCIAS_DA_SAUDE,\"Saúde Coletiva\",\"Saúde Pública\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1º Encontro Nordeste de Saúde da Família (1º Enesf)</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{nan}</td>\n",
       "      <td>14º Congresso Internacional da Rede Unida</td>\n",
       "      <td>Comunicação em evento</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Fiocruz/Ceará,Fiocruz/Ceará}</td>\n",
       "      <td>{\"Ivana Cristina de Holanda Cunha Barreto\",\"Luiz Odorico Monteiro de Andrade\"}</td>\n",
       "      <td>{CIENCIAS_DA_SAUDE,\"Saúde Coletiva\",\"Saúde Digital|CIENCIAS_DA_SAUDE\",Medicina,\"Saúde Materno-Infantil\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Análise Estatística como Ferramenta para se Melhorar o Processo de Fabricação de Medicamentos</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"controle de processo\",\"controle de qualidade\",\"processo sob controle estatístico\"}</td>\n",
       "      <td>Seminário Anual Científico e Tecnológico de Biomanguinhos</td>\n",
       "      <td>Comunicação em evento</td>\n",
       "      <td>{}</td>\n",
       "      <td>{Fiocruz/Ceará}</td>\n",
       "      <td>{\"Margareth Borges Coutinho Gallo\"}</td>\n",
       "      <td>{CIENCIAS_BIOLOGICAS,Bioquímica,\"Probabilidade e Estatística Aplicadas\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Título                                                                                             \n",
       "0             (des)controle dos Indicadores Clínicos em Pacientes Atendidos pelo Programa Hiperdia  \\\n",
       "1                                              1º Encontro Nordeste de Saúde da Família (1º Enesf)   \n",
       "2  A Análise Estatística como Ferramenta para se Melhorar o Processo de Fabricação de Medicamentos   \n",
       "\n",
       "   Ano  Resumo   \n",
       "0  2015  NaN    \\\n",
       "1  2020  NaN     \n",
       "2  2015  NaN     \n",
       "\n",
       "  Palavras-chaves do autor                                                                             \n",
       "0  {\"HIPERTENSÃO ARTERIAL\",\"diabetes mellitus\",\"indicadores clínicos\",\"Estratégia Saúde da Família\"}  \\\n",
       "1                                                                                              {nan}   \n",
       "2               {\"controle de processo\",\"controle de qualidade\",\"processo sob controle estatístico\"}   \n",
       "\n",
       "  Veículo de publicação                                        \n",
       "0   18º Senpe - Seminário Nacional de Pesquisa em Enfermagem  \\\n",
       "1                  14º Congresso Internacional da Rede Unida   \n",
       "2  Seminário Anual Científico e Tecnológico de Biomanguinhos   \n",
       "\n",
       "  Tipologia documental   Instiuições Unidades/ Siglas                 \n",
       "0  Comunicação em evento  {}                        {Fiocruz/Ceará}  \\\n",
       "1  Comunicação em evento  {}          {Fiocruz/Ceará,Fiocruz/Ceará}   \n",
       "2  Comunicação em evento  {}                        {Fiocruz/Ceará}   \n",
       "\n",
       "  Autores                                                                           \n",
       "0                                     {\"Roberto Wagner Júnior Freire de Freitas\"}  \\\n",
       "1  {\"Ivana Cristina de Holanda Cunha Barreto\",\"Luiz Odorico Monteiro de Andrade\"}   \n",
       "2                                             {\"Margareth Borges Coutinho Gallo\"}   \n",
       "\n",
       "  Áreas do conhecimento CNPq (lattes do servidor)                                                            \n",
       "0                                                      {CIENCIAS_DA_SAUDE,\"Saúde Coletiva\",\"Saúde Pública\"}  \n",
       "1  {CIENCIAS_DA_SAUDE,\"Saúde Coletiva\",\"Saúde Digital|CIENCIAS_DA_SAUDE\",Medicina,\"Saúde Materno-Infantil\"}  \n",
       "2                                  {CIENCIAS_BIOLOGICAS,Bioquímica,\"Probabilidade e Estatística Aplicadas\"}  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fioce_2008_2013[['Título', 'Ano', 'Resumo', 'Palavras-chaves do autor','Veículo de publicação', 'Tipologia documental', 'Instiuições','Unidades/ Siglas','Autores ','Áreas do conhecimento CNPq (lattes do servidor)']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fiocruz_id', 'Título', 'Ano', 'Resumo', 'Palavras-chaves do autor',\n",
       "       'Veículo de publicação', 'DOI ', 'Tipologia documental', 'Instiuições',\n",
       "       'Unidades/ Siglas', 'Pais da Instiuição ', 'Autores ',\n",
       "       'Áreas do conhecimento CNPq (lattes do servidor)',\n",
       "       'Áreas temáticas identificadas pelo Observatório',\n",
       "       'Área do conhecimento CNPq Nível 1 ',\n",
       "       'Área do conhecimento CNPq Nível 2',\n",
       "       'Área do conhecimento CNPq Nível 3 ',\n",
       "       'Área do conhecimento CNPq Nível 4 ',\n",
       "       'Área do conhecimento CNPq Nível 1 )',\n",
       "       'Área do conhecimento CNPq Nível 2.1',\n",
       "       'Área do conhecimento CNPq Nível 3',\n",
       "       'Área do conhecimento CNPq Nível 4 .1',\n",
       "       'Nível 1 ; Nível 2 ; Nível 3 ; Nível 4               Utilizar ; (ponto e víruga como separador) ',\n",
       "       'Unnamed: 23', 'Unnamed: 24'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiocuz_producao.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>Título</th>\n",
       "      <th>Ano</th>\n",
       "      <th>Resumo</th>\n",
       "      <th>Palavras-chaves do autor</th>\n",
       "      <th>Veículo de publicação</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Tipologia documental</th>\n",
       "      <th>Instiuições</th>\n",
       "      <th>Unidades/ Siglas</th>\n",
       "      <th>Pais da Instiuição</th>\n",
       "      <th>Autores</th>\n",
       "      <th>Áreas do conhecimento CNPq (lattes do servidor)</th>\n",
       "      <th>Áreas temáticas identificadas pelo Observatório</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Democracy is health\": rights, commitments, and the public health project updated</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Democracia', 'Política de Saúde/tendências', 'Saúde Pública/tendências', 'Brasil', 'Direitos Humanos/tendências', 'Humanos']</td>\n",
       "      <td>Cadernos de Saúde Pública</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artigo</td>\n",
       "      <td>['Não identificada', 'Não identificada']</td>\n",
       "      <td>['Fiocruz', 'Fiocruz']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Franco Netto G.', 'Franco Netto, Guilherme', 'Lima, Nísia Trindade', 'lima N. T.']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Não tem essas pessoas especiais na minha área\": saúde e invisibilidade das populações LGBT na perspectiva de agentes comunitários de saúde</td>\n",
       "      <td>2019</td>\n",
       "      <td>El objetivo del estudio aquí presentado fue analizar los sentidos atribuidos por agentes comunitarios de salud acerca del cuidado en salud a la población LGBT. El método se basa en un enfoque de investigación cualitativa, a través de entrevistas semiestructuradas con 15 agentes comunitarios de salud de la Estratégia Saúde da Família (Estrategia Salud de la Familia, programa brasileño de salud) de una ciudad de la Región Nordeste de Brasil. Los datos fueron analizados a partir del método de interpretación de sentidos. Entre los principales resultados, se destacaron dos: (i) Demandas de salud de la población LGBT; y (ii) Actuación profesional ante la población LGBT. La salud de la población LGBT, especialmente en la atención primaria de salud, es una compleja cuestión que no ha estado recibiendo la debida atención por parte de la formación, gestión y atención en salud como un todo. Así que la actuación problematizadora de este trabajo ha reunido relatos, identificado problemas y cuestiones y, consecuentemente, por medio de la percepción de los agentes comunitarios de salud, ha descubiertolas violencias, negaciones y discriminaciones que vivencian algunas personas LGBT en las unidades de salud, espacios que deberián ofrecer cuidado ecuánime e integral.</td>\n",
       "      <td>['Humanos', 'Minorias Sexuais e de Gênero', 'Ativismo Político', 'Identidade de Gênero', 'Relações Interpessoais', 'Comportamento Sexual', 'Sistema Único de Saúde', 'Agentes Comunitários de Saúde', 'Assistência Integral à Saúde', 'Pesquisa Qualitativa']</td>\n",
       "      <td>Revista Eletrônica de Comunicação, Informação &amp; Inovação em Saúde</td>\n",
       "      <td>10.29397/reciis.v13i3.1703</td>\n",
       "      <td>Artigo</td>\n",
       "      <td>['Instituto Federal de Educação do Maranhão. São Luís. BR']</td>\n",
       "      <td>['Fiocruz', 'Fiocruz']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Albuquerque, Ana Rayonara de Sousa', 'Almeira, Maysa Milena E. Silva', 'Ferreira, Breno de Oliveira', 'Nascimento, Elaine Ferreira', 'Pedrosa, José Ivo dos Santos', 'Pereira, Edson Oliveira', 'Rocha, Matheus Barbosa da']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Populações Vulneráveis, Violência e Direitos Humanos']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Quem dá mais, cobra mais\": Uma análise das normas antecedentes do ofício de motorista de ônibus em um contexto específico</td>\n",
       "      <td>2011</td>\n",
       "      <td>The goal of this article is analyze the prescribed work norms and the antecedent norms of the bus drivers work in a specific context. The reported study was inspired in the concepts given respectively for the Ergonomy and the Ergology, and in the observations from another research about bus journeys in Rio de Janeiro (CAIAFA, 2002). It counted also with a qualitative research methodology that sought to analyze the language used by the person responsible for the transmission of prescribed work norms and the antecedent norms of a certain company to its employees. The content for analyze was collected from two situations: an interview held with an inspector, with the assignments to observe, monitor and correct aspects of the bus drivers work and conductors work, and the participant observation of a process of integration for admitted workers in the already mentioned company.</td>\n",
       "      <td>['Humanos', 'Adulto', 'Meios de Transporte/normas', 'Categorias de Trabalhadores', 'Ergonomia']</td>\n",
       "      <td>Estud. pesqui. psicol.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Artigo</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Fiocruz']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Prange, Ana Paula Lobão']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Título                                                                                                                                         \n",
       "0                                                            \"Democracy is health\": rights, commitments, and the public health project updated  \\\n",
       "1  \"Não tem essas pessoas especiais na minha área\": saúde e invisibilidade das populações LGBT na perspectiva de agentes comunitários de saúde   \n",
       "2                   \"Quem dá mais, cobra mais\": Uma análise das normas antecedentes do ofício de motorista de ônibus em um contexto específico   \n",
       "\n",
       "   Ano    \n",
       "0  2018  \\\n",
       "1  2019   \n",
       "2  2011   \n",
       "\n",
       "  Resumo                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    NaN  \\\n",
       "1  El objetivo del estudio aquí presentado fue analizar los sentidos atribuidos por agentes comunitarios de salud acerca del cuidado en salud a la población LGBT. El método se basa en un enfoque de investigación cualitativa, a través de entrevistas semiestructuradas con 15 agentes comunitarios de salud de la Estratégia Saúde da Família (Estrategia Salud de la Familia, programa brasileño de salud) de una ciudad de la Región Nordeste de Brasil. Los datos fueron analizados a partir del método de interpretación de sentidos. Entre los principales resultados, se destacaron dos: (i) Demandas de salud de la población LGBT; y (ii) Actuación profesional ante la población LGBT. La salud de la población LGBT, especialmente en la atención primaria de salud, es una compleja cuestión que no ha estado recibiendo la debida atención por parte de la formación, gestión y atención en salud como un todo. Así que la actuación problematizadora de este trabajo ha reunido relatos, identificado problemas y cuestiones y, consecuentemente, por medio de la percepción de los agentes comunitarios de salud, ha descubiertolas violencias, negaciones y discriminaciones que vivencian algunas personas LGBT en las unidades de salud, espacios que deberián ofrecer cuidado ecuánime e integral.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                 The goal of this article is analyze the prescribed work norms and the antecedent norms of the bus drivers work in a specific context. The reported study was inspired in the concepts given respectively for the Ergonomy and the Ergology, and in the observations from another research about bus journeys in Rio de Janeiro (CAIAFA, 2002). It counted also with a qualitative research methodology that sought to analyze the language used by the person responsible for the transmission of prescribed work norms and the antecedent norms of a certain company to its employees. The content for analyze was collected from two situations: an interview held with an inspector, with the assignments to observe, monitor and correct aspects of the bus drivers work and conductors work, and the participant observation of a process of integration for admitted workers in the already mentioned company.   \n",
       "\n",
       "  Palavras-chaves do autor                                                                                                                                                                                                                                         \n",
       "0                                                                                                                                 ['Democracia', 'Política de Saúde/tendências', 'Saúde Pública/tendências', 'Brasil', 'Direitos Humanos/tendências', 'Humanos']  \\\n",
       "1  ['Humanos', 'Minorias Sexuais e de Gênero', 'Ativismo Político', 'Identidade de Gênero', 'Relações Interpessoais', 'Comportamento Sexual', 'Sistema Único de Saúde', 'Agentes Comunitários de Saúde', 'Assistência Integral à Saúde', 'Pesquisa Qualitativa']   \n",
       "2                                                                                                                                                                ['Humanos', 'Adulto', 'Meios de Transporte/normas', 'Categorias de Trabalhadores', 'Ergonomia']   \n",
       "\n",
       "  Veículo de publicação                                                \n",
       "0                                          Cadernos de Saúde Pública  \\\n",
       "1  Revista Eletrônica de Comunicação, Informação & Inovação em Saúde   \n",
       "2                                            Estud. pesqui. psicol.    \n",
       "\n",
       "  DOI                         Tipologia documental   \n",
       "0                         NaN  Artigo               \\\n",
       "1  10.29397/reciis.v13i3.1703  Artigo                \n",
       "2                         NaN  Artigo                \n",
       "\n",
       "  Instiuições                                                    \n",
       "0                     ['Não identificada', 'Não identificada']  \\\n",
       "1  ['Instituto Federal de Educação do Maranhão. São Luís. BR']   \n",
       "2                                                           []   \n",
       "\n",
       "  Unidades/ Siglas        Pais da Instiuição    \n",
       "0  ['Fiocruz', 'Fiocruz']  []                  \\\n",
       "1  ['Fiocruz', 'Fiocruz']  []                   \n",
       "2             ['Fiocruz']  []                   \n",
       "\n",
       "  Autores                                                                                                                                                                                                                           \n",
       "0                                                                                                                                            ['Franco Netto G.', 'Franco Netto, Guilherme', 'Lima, Nísia Trindade', 'lima N. T.']  \\\n",
       "1  ['Albuquerque, Ana Rayonara de Sousa', 'Almeira, Maysa Milena E. Silva', 'Ferreira, Breno de Oliveira', 'Nascimento, Elaine Ferreira', 'Pedrosa, José Ivo dos Santos', 'Pereira, Edson Oliveira', 'Rocha, Matheus Barbosa da']   \n",
       "2                                                                                                                                                                                                     ['Prange, Ana Paula Lobão']   \n",
       "\n",
       "  Áreas do conhecimento CNPq (lattes do servidor)   \n",
       "0  []                                              \\\n",
       "1  []                                               \n",
       "2  []                                               \n",
       "\n",
       "  Áreas temáticas identificadas pelo Observatório            \n",
       "0                                                        []  \n",
       "1  ['Populações Vulneráveis, Violência e Direitos Humanos']  \n",
       "2                                                        []  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiocuz_producao[['Título', 'Ano', 'Resumo', 'Palavras-chaves do autor',\n",
    "       'Veículo de publicação', 'DOI ', 'Tipologia documental', 'Instiuições',\n",
    "       'Unidades/ Siglas', 'Pais da Instiuição ', 'Autores ',\n",
    "       'Áreas do conhecimento CNPq (lattes do servidor)',\n",
    "       'Áreas temáticas identificadas pelo Observatório',]].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><b>ORGANIZAR DADOS DE PESSOAL</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listar todos colaboradores na Fiocruz Ceará \n",
    "\n",
    "(planilhas de Recursos Humanos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['QUANT', 'STATUS', 'MATRÍCULA', 'Unnamed: 3', 'NOME', 'ÁREA',\n",
       "       'Unnamed: 6', 'CARGO', 'VÍNCULO', 'Unnamed: 9', 'INGRESSO_FIOCE',\n",
       "       'POSSE NA FIOCRUZ', 'ADICIONAL OCUPACIONAL', 'EMPRESA/BOLSA/PROGRAMA',\n",
       "       'GESTOR', 'ADI', 'VIGÊNCIA BOLSA/ENCERRAMENTO DO CONTRATO',\n",
       "       'Unnamed: 17', 'EMAIL INSTITUCIONAL', 'EMAIL PESSOAL', 'GENERO',\n",
       "       'DATA NASCIMENTO', 'Unnamed: 22', 'FORMAÇÃO', 'NÍVEL',\n",
       "       'ENDEREÇO RESIDENCIAL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ler apenas os cabeçalhos do arquivo Excel\n",
    "headers = pd.read_excel(pathzip+'fioce_colaboradores-2023.xls', skiprows=3, header=0, nrows=0).columns\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STATUS',\n",
       " 'MATRÍCULA',\n",
       " 'NOME',\n",
       " 'ÁREA',\n",
       " 'CARGO',\n",
       " 'VÍNCULO',\n",
       " 'INGRESSO_FIOCE',\n",
       " 'NÍVEL']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usar função para indicar quais colunas devem ser eliminadas na leitura\n",
    "def cols_to_keep(col_name):\n",
    "    return col_name not in ['QUANT','Unnamed: 3','Unnamed: 6','Unnamed: 9','ADICIONAL OCUPACIONAL',\n",
    "                            'EMPRESA/BOLSA/PROGRAMA','GESTOR','ADI','POSSE NA FIOCRUZ',\n",
    "                            'VIGÊNCIA BOLSA/ENCERRAMENTO DO CONTRATO','Unnamed: 17',\n",
    "                            'EMAIL INSTITUCIONAL','EMAIL PESSOAL','GENERO','DATA NASCIMENTO',\n",
    "                            'Unnamed: 22','FORMAÇÃO','ENDEREÇO RESIDENCIAL']\n",
    "\n",
    "# Filtrar cabeçalhos com base na função\n",
    "selected_columns = [col for col in headers if cols_to_keep(col)]\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284 nomes de colaboradores no total, todos vínculos e status\n",
      " 10 tipos de vínculos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SERVIDOR',\n",
       " 'COORENAÇÃO GERAL',\n",
       " 'TERCEIRIZADO',\n",
       " 'BOLSISTA',\n",
       " 'ESTÁGIO PEC',\n",
       " 'UNADIG',\n",
       " 'NORMATEL',\n",
       " 'SERVIDOR-CEDIDA PARA CORREGEDORIA ',\n",
       " 'SERVIDOR-CEDIDA PARA FIOCRUZ PE',\n",
       " 'SERVIDOR-CEDIDO PARA AUDITORIA INTERNA']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ler dados do arquivo Excel do Setor de Recursos Humanos\n",
    "pathzip = ''\n",
    "fioce_pessoal = pd.read_excel(pathzip+'fioce_colaboradores-2023.xls', skiprows=3, header=0, usecols=selected_columns)\n",
    "print(f'{len(fioce_pessoal.index)} nomes de colaboradores no total, todos vínculos e status')\n",
    "print(f'{len(fioce_pessoal[\"VÍNCULO\"].unique()):3} tipos de vínculos')\n",
    "list(fioce_pessoal['VÍNCULO'].unique())\n",
    "# fioce_pessoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>MATRÍCULA</th>\n",
       "      <th>NOME</th>\n",
       "      <th>ÁREA</th>\n",
       "      <th>CARGO</th>\n",
       "      <th>VÍNCULO</th>\n",
       "      <th>INGRESSO_FIOCE</th>\n",
       "      <th>NÍVEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>N/I</td>\n",
       "      <td>Antonio Carlile De Holanda Lavor</td>\n",
       "      <td>Coordenação Geral</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>COORENAÇÃO GERAL</td>\n",
       "      <td>2005-06-30</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATUS MATRÍCULA NOME                              ÁREA                  \n",
       "6  ATIVO  N/I       Antonio Carlile De Holanda Lavor  Coordenação Geral   \\\n",
       "\n",
       "  CARGO                         VÍNCULO           INGRESSO_FIOCE NÍVEL       \n",
       "6  Pesquisador em Saúde Pública  COORENAÇÃO GERAL 2005-06-30      DOUTORADO  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fioce_pessoal[fioce_pessoal['VÍNCULO']=='COORENAÇÃO GERAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MESTRADO',\n",
       " 'DOUTORADO',\n",
       " 'ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)',\n",
       " 'PHD ',\n",
       " 'ENSINO MÉDIO',\n",
       " 'ENSINO SUPERIOR',\n",
       " 'TÉCNICO (ENSINO MÉDIO)',\n",
       " nan]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(fioce_pessoal['NÍVEL'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>MATRÍCULA</th>\n",
       "      <th>NOME</th>\n",
       "      <th>ÁREA</th>\n",
       "      <th>CARGO</th>\n",
       "      <th>VÍNCULO</th>\n",
       "      <th>INGRESSO_FIOCE</th>\n",
       "      <th>NÍVEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dayane Alves Costa</td>\n",
       "      <td>Coordenação de Pesquisa e Coleções Biológicas</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2023-07-25</td>\n",
       "      <td>PHD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS MATRÍCULA NOME                  \n",
       "16  ATIVO  NaN       Dayane Alves Costa  \\\n",
       "\n",
       "   ÁREA                                              \n",
       "16  Coordenação de Pesquisa e Coleções Biológicas   \\\n",
       "\n",
       "   CARGO                          VÍNCULO   INGRESSO_FIOCE NÍVEL  \n",
       "16  Tecnologista em Saúde Pública  SERVIDOR 2023-07-25      PHD   "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fioce_pessoal[fioce_pessoal['NÍVEL']=='PHD ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284 colaboradores ao todo, todos vínculos e status\n"
     ]
    }
   ],
   "source": [
    "# Montar lista de nomes de todos colaboradores\n",
    "fioce_pessoal['NOME'] = fioce_pessoal['NOME'].str.strip()\n",
    "lista_colaboradores   = fioce_pessoal['NOME']\n",
    "print(f'{len(lista_colaboradores)} colaboradores ao todo, todos vínculos e status')\n",
    "\n",
    "# for i in lista_colaboradores.sort_values().values:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>MATRÍCULA</th>\n",
       "      <th>NOME</th>\n",
       "      <th>ÁREA</th>\n",
       "      <th>CARGO</th>\n",
       "      <th>VÍNCULO</th>\n",
       "      <th>INGRESSO_FIOCE</th>\n",
       "      <th>NÍVEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2242450</td>\n",
       "      <td>Alice Paula Di Sabatino Guimaraes</td>\n",
       "      <td>Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1165347</td>\n",
       "      <td>Ana Claudia De Araújo Teixeira</td>\n",
       "      <td>Saúde e Ambiente</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2015-08-17</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1014947</td>\n",
       "      <td>Ana Camila Oliveira Alves</td>\n",
       "      <td>Coordenação de Pesquisa e Coleções Biológicas</td>\n",
       "      <td>Técnico em Pesquisa e Investigação Biomédica</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>626325</td>\n",
       "      <td>Angela Christina De Moraes Ostritz</td>\n",
       "      <td>Coordenação Geral</td>\n",
       "      <td>Enfermeira(o)</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2017-06-05</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1896774</td>\n",
       "      <td>Adriana Costa Bacelo</td>\n",
       "      <td>Saúde Digital</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>21819093</td>\n",
       "      <td>Anna Carolina Machado Marinho</td>\n",
       "      <td>Coordenação Geral (QUALIDADE)</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2018-07-06</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>N/I</td>\n",
       "      <td>Antonio Carlile De Holanda Lavor</td>\n",
       "      <td>Coordenação Geral</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>COORENAÇÃO GERAL</td>\n",
       "      <td>2005-06-30</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1683775</td>\n",
       "      <td>Antonio Marcos Aires Barbosa</td>\n",
       "      <td>Coordenação de Pesquisa e Coleções Biológicas</td>\n",
       "      <td>Analista de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2011-11-07</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2904868</td>\n",
       "      <td>Anya Pimentel Gomes Fernandes Vieira Meyer</td>\n",
       "      <td>Saúde da Família</td>\n",
       "      <td>Especialista em C&amp;T Prod. Inov. Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2010-11-05</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1913135</td>\n",
       "      <td>Bruno Bezerra Carvalho</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (COORDENAÇÃO)</td>\n",
       "      <td>Analista de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2018-07-08</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2175249</td>\n",
       "      <td>Carla Freire Celedônio Fernandes</td>\n",
       "      <td>Coordenação Geral</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2018-06-29</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1683295</td>\n",
       "      <td>Carlos Jose Araujo Pinheiro</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)</td>\n",
       "      <td>Técnico em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1538475</td>\n",
       "      <td>Claudia Stutz Zubieta</td>\n",
       "      <td>Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)</td>\n",
       "      <td>Técnico em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2022-06-30</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1613229</td>\n",
       "      <td>Charles Cerqueira De Abreu</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional(ALMOXARIFADO)</td>\n",
       "      <td>Técnico em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2020-09-23</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1993800</td>\n",
       "      <td>Clarice Gomes E Souza Dabés</td>\n",
       "      <td>Coordenação Geral (QUALIDADE)</td>\n",
       "      <td>Analista de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2021-07-11</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2181594</td>\n",
       "      <td>Clarissa Romero Teixeira</td>\n",
       "      <td>Biotecnologia-GR1 (IMUNOPARASITOLOGIA)</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dayane Alves Costa</td>\n",
       "      <td>Coordenação de Pesquisa e Coleções Biológicas</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2023-07-25</td>\n",
       "      <td>PHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1319630</td>\n",
       "      <td>Donat Alexander De Chapeaurouge</td>\n",
       "      <td>Biotecnologia-GR3 (BIOTECNOLOGIA)</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2016-08-08</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2182142</td>\n",
       "      <td>Eduardo Ruback Dos Santos</td>\n",
       "      <td>Coordenação Geral</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>\\t0445970</td>\n",
       "      <td>Ezequiel Valentim De Melo</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (FINANCEIRO)</td>\n",
       "      <td>Analista de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1344058</td>\n",
       "      <td>Fabio Miyajima</td>\n",
       "      <td>Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)</td>\n",
       "      <td>Especialista em C&amp;T Prod. Inov. Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2243169</td>\n",
       "      <td>Fernando Braga Stehling Dias</td>\n",
       "      <td>Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1493522</td>\n",
       "      <td>Fernando Ferreira Carneiro</td>\n",
       "      <td>Saúde e Ambiente</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2014-12-02</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>224946-3</td>\n",
       "      <td>Galba Freire Moita</td>\n",
       "      <td>Coordenação de Produção e  Inovação em Saúde</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1985736</td>\n",
       "      <td>Giovanny Augusto Camacho Antevere Mazzarotto</td>\n",
       "      <td>Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2021-08-05</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2184558</td>\n",
       "      <td>Gilvan Pessoa Furtado</td>\n",
       "      <td>Biotecnologia-GR3 (BIOTECNOLOGIA)</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1350230</td>\n",
       "      <td>Ivana Cristina De Holanda Cunha Barrêto</td>\n",
       "      <td>Saúde Digital</td>\n",
       "      <td>Especialista em C&amp;T Prod. Inov. Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2014-12-18</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1715669</td>\n",
       "      <td>Ivanildo Lopes Farias</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA / SIMAM)</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2017-09-25</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>3121258</td>\n",
       "      <td>Jaime Ribeiro Filho</td>\n",
       "      <td>Coordenação Geral</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1049924</td>\n",
       "      <td>João Baptista Estabile Neto</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (COMUNICAÇÃO)</td>\n",
       "      <td>Assistente Tecnico de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>ENSINO MÉDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1497987</td>\n",
       "      <td>João Hermínio Martins Da Silva</td>\n",
       "      <td>Coordenação de Pesquisa e Coleções Biológicas</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2012-12-13</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AFASTADO</td>\n",
       "      <td>1556031</td>\n",
       "      <td>José Luis Passos Cordeiro</td>\n",
       "      <td>Saúde e Ambiente</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2006-11-09</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2838905</td>\n",
       "      <td>Kamila Matos Albuquerque</td>\n",
       "      <td>Central Analitica - UNADIG</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2020-05-13</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1902167</td>\n",
       "      <td>Luciana Coelho Serafim</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)</td>\n",
       "      <td>Analista de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2022-03-14</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1359804</td>\n",
       "      <td>Luciana Pereira Lindenmeyer</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)</td>\n",
       "      <td>Analista de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2015-12-11</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2079552</td>\n",
       "      <td>Luciana Silvério Alleluia Higino Da Silva</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)</td>\n",
       "      <td>Enfermeira(o)</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2013979</td>\n",
       "      <td>Luciano Pinto Zorzanelli</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (TIC)</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>747225</td>\n",
       "      <td>Luis Fernando Pessoa De Andrade</td>\n",
       "      <td>Coordenação de Produção e  Inovação em Saúde</td>\n",
       "      <td>Analista de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2009-01-20</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1350229</td>\n",
       "      <td>Luiz Odorico Monteiro De Andrade</td>\n",
       "      <td>Coordenação de Produção e  Inovação em Saúde</td>\n",
       "      <td>Especialista em C&amp;T Prod. Inov. Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2012-09-03</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1985995</td>\n",
       "      <td>Marcela Helena Gambim Fonseca</td>\n",
       "      <td>Central Analitica - UNADIG</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2180858</td>\n",
       "      <td>Marcelo Jorge Lopes Coutinho</td>\n",
       "      <td>Biotecnologia-GR3 (BIOTECNOLOGIA)</td>\n",
       "      <td>Técnico em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1952032</td>\n",
       "      <td>Marcos Roberto Lourenzoni</td>\n",
       "      <td>Biotecnologia-GR3 (BIOTECNOLOGIA)</td>\n",
       "      <td>Especialista em C&amp;T Prod. Inov. Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2012-09-14</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1806284</td>\n",
       "      <td>Marcio Flavio Moura De Araujo</td>\n",
       "      <td>Saúde da Família</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>AFASTADO</td>\n",
       "      <td>1901024</td>\n",
       "      <td>Margareth Borges Coutinho Gallo</td>\n",
       "      <td>Saúde e Ambiente</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1188635</td>\n",
       "      <td>Marlos De Medeiros Chaves</td>\n",
       "      <td>Biotecnologia-GR1 (IMUNOPARASITOLOGIA)</td>\n",
       "      <td>Tecnologista em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2015-02-27</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1556258</td>\n",
       "      <td>Maximiliano Loiola Ponte De Souza</td>\n",
       "      <td>Saúde da Família</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>464200</td>\n",
       "      <td>Nilton Luiz Costa Machado</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA / SIMAM)</td>\n",
       "      <td>Assistente Tecnico de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>ENSINO MÉDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1634325</td>\n",
       "      <td>Patricia Maria Ferreira da Silva</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)</td>\n",
       "      <td>Analista de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2180289</td>\n",
       "      <td>Raphael Trevizani</td>\n",
       "      <td>Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2014-11-25</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>2181469</td>\n",
       "      <td>Regis Bernardo Brandim Gomes</td>\n",
       "      <td>Biotecnologia-GR1 (IMUNOPARASITOLOGIA)</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1727289</td>\n",
       "      <td>Renato Caldeira De Souza</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (COMPRAS)</td>\n",
       "      <td>Assistente Tecnico de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2020-08-17</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1985557</td>\n",
       "      <td>Roberto Nicolete</td>\n",
       "      <td>Biotecnologia-GR1 (IMUNOPARASITOLOGIA)</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1581487</td>\n",
       "      <td>Roberto Wagner Junior Freire De Freitas</td>\n",
       "      <td>Saúde da Família</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2014-11-24</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>AFASTADO</td>\n",
       "      <td>1437828</td>\n",
       "      <td>Rodrigo Carvalho Nogueira</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)</td>\n",
       "      <td>Analista de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2014-08-25</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>669534</td>\n",
       "      <td>Sergio Dos Santos Reis</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)</td>\n",
       "      <td>Analista de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2021-09-21</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>EXONERADO</td>\n",
       "      <td>30137403</td>\n",
       "      <td>Sandro Gomes Soares</td>\n",
       "      <td>Biotecnologia</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2019-06-04</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1165326</td>\n",
       "      <td>Sharmenia De Araujo Soares Nuto</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (COORDENAÇÃO)</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2014-11-14</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>1992814</td>\n",
       "      <td>Vanira Matos Pessoa</td>\n",
       "      <td>Coordenação Geral</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>3121915</td>\n",
       "      <td>Venúcia Bruna Magalhães Pereira</td>\n",
       "      <td>Biotecnologia-GR3 (BIOTECNOLOGIA)</td>\n",
       "      <td>Técnico em Saúde Pública</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eliezio Lessa Dos Santos</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)</td>\n",
       "      <td>Técnico de Manutenção Eletrica</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>TÉCNICO (ENSINO MÉDIO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dann Eliézer Guimarães Martins Barbosa</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (TIC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2018-04-27</td>\n",
       "      <td>ENSINO MÉDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mario Italo Coelho Dos Santos</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (TIC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2021-07-07</td>\n",
       "      <td>TÉCNICO (ENSINO MÉDIO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fabio Martins Uchoa</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (TIC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2021-06-14</td>\n",
       "      <td>TÉCNICO (ENSINO MÉDIO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gutemberg Monteiro Regadas</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (TIC)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>ENSINO MÉDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jessiedna Holanda Lemos</td>\n",
       "      <td>Coordenação Geral (SECRETARIA EXECUTIVA)</td>\n",
       "      <td>Assistente Administrativo</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2019-05-23</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paulo Wanderson Rodrigues Viana</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)</td>\n",
       "      <td>Assistente de Gestão Pleno III</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2012-07-05</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wagner Alves De Souza Júnior</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (COMPRAS)</td>\n",
       "      <td>Analista de Gestão Junior I</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2010-05-19</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amanda Cacau De Souza Paixão</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (COMPRAS)</td>\n",
       "      <td>Apoio Logística II</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CONTRATO ENCERRADO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amanda Sobreira Quintino De Castro</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (COMUNICAÇÃO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2019-09-05</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rejane Pereira Da Silva</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)</td>\n",
       "      <td>Apoio Logística II</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2019-09-16</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vanessa Do Nascimento</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)</td>\n",
       "      <td>Apoio Logística I</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>ENSINO MÉDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Romulo Silva Dos Santos</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)</td>\n",
       "      <td>Engenheiro Civil Junior</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antonia Yasmim Da Costa Sales</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)</td>\n",
       "      <td>Técnico de Manutenção Eletrica</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>TÉCNICO (ENSINO MÉDIO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>CONTRATO ENCERRADO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tania Caldeira De Souza</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2020-09-16</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vera Marta Neves Amarante Rabay</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)</td>\n",
       "      <td>Engenheira Eletricista</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paulo Rafael Silva Sousa</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)</td>\n",
       "      <td>Técnico em Equipamentos</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2021-08-12</td>\n",
       "      <td>TÉCNICO (ENSINO MÉDIO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>CONTRATO ENCERRADO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suerda Cristina Pereira Silva</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)</td>\n",
       "      <td>Assistente Administrativo</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amilton Albuquerque Pontes</td>\n",
       "      <td>Bio-Manguinhos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ilana Carneiro Lisboa Magalhães</td>\n",
       "      <td>Bio-Manguinhos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carolina Campos de Oliveira</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (COMUNICAÇÃO)</td>\n",
       "      <td>Jornalista I</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gabriel Coutinho Gonçalves</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)</td>\n",
       "      <td>Apoio Logistico II</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2023-06-02</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elian Matias Da Silva</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (PATRIMÔNIO)</td>\n",
       "      <td>Assistente de Gestão Senior</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>ENSINO MÉDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gabriel De Moura Minarini</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (PATRIMÔNIO)</td>\n",
       "      <td>Assistente de Gestão Senior</td>\n",
       "      <td>TERCEIRIZADO</td>\n",
       "      <td>2020-09-08</td>\n",
       "      <td>TÉCNICO (ENSINO MÉDIO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>CONTRATO ENCERRADO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andreia Vitória Damasceno Calixto</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>TÉCNICO (ENSINO MÉDIO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Camila Victor Vitorino Holanda</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (BIBLIOTECA)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Camilla Do Nascimento Cruz</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-10-20</td>\n",
       "      <td>ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cesarina De Sousa Mendes Da Costa</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (PATRIMÔNIO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2022-02-07</td>\n",
       "      <td>TÉCNICO (ENSINO MÉDIO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carlos Augusto Guimarães Fonseca</td>\n",
       "      <td>Coordenação de Pesquisa e Coleções Biológicas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-08-09</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>CONTRATO ENCERRADO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Derick Rosa De Oliveira</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (LOGÍSTICA)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>TÉCNICO (ENSINO MÉDIO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Derick Carvalho Ribeiro Silva</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional   (ALMOXARIFADO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>ENSINO MÉDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>CONTRATO ENCERRADO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edmilson Santana De Souza</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (PATRIMÔNIO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>TÉCNICO (ENSINO MÉDIO)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Janaina De Oliveira Da Silva</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>CONTRATO ENCERRADO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Letícia Gabriele Saraiva De Farias</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>CONTRATO ENCERRADO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Patricia Fernanda Rocha Dias</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>CONTRATO ENCERRADO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suzy Anne Alves Pinto</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>CONTRATO ENCERRADO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sarah Sant'Anna Maranhão</td>\n",
       "      <td>Coordenação Geral (QUALIDADE)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Daniel Pascolino Pinheiro</td>\n",
       "      <td>Biotecnologia-GR3 (BIOTECNOLOGIA)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suelen Carneiro de Medeiros</td>\n",
       "      <td>Coordenação Geral (QUALIDADE)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maisa de Sales Costa</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Isabela Cristina da Paixão Minarini</td>\n",
       "      <td>Coordenação Geral (SECRETARIA EXECUTIVA)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>ENSINO MÉDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adelaide Souza da Silva Rodrigues</td>\n",
       "      <td>Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>MESTRADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cecilia Katia Ferreira Santos</td>\n",
       "      <td>Coordenação da Gestão e Desenvolvimento Institucional (FINANCEIRO)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2022-10-14</td>\n",
       "      <td>ENSINO MÉDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gustavo Souza Pinto</td>\n",
       "      <td>Coordenação Geral ( EPSJV/FIOCRUZ)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mauricio Fraga Van Tiburg</td>\n",
       "      <td>Coordenação de Pesquisa e Coleções Biológicas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flora Viana Elizeu da Silva</td>\n",
       "      <td>Saúde e Ambiente</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco Eder de Moura Lopes</td>\n",
       "      <td>Coordenação de Pesquisa e Coleções Biológicas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jamille Mara Mendes Bezerra</td>\n",
       "      <td>Coordenação de Pesquisa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Darlyson Tavares Guimarães</td>\n",
       "      <td>Coordenação de Pesquisa e Coleções Biológicas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>ENSINO SUPERIOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ticiane Cavalcante de Souza</td>\n",
       "      <td>Coordenação de Pesquisa e Coleções Biológicas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLSISTA</td>\n",
       "      <td>2023-07-05</td>\n",
       "      <td>DOUTORADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maria Eduarda Guedes Onofre</td>\n",
       "      <td>Coordenação de Pesquisa e Coleções Biológicas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESTÁGIO PEC</td>\n",
       "      <td>2021-08-15</td>\n",
       "      <td>ENSINO MÉDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco Leandro Fernandes Sampaio</td>\n",
       "      <td>Saúde Digital</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESTÁGIO PEC</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>ENSINO MÉDIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42241</td>\n",
       "      <td>Adriana Carvalho De Albuquerque</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alberto Davi Gomes Tavares</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42266</td>\n",
       "      <td>Ana Carolina Matias Dinelly Pinto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42532</td>\n",
       "      <td>Bárbara Cibelle Soares Farias Quintela</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>43083</td>\n",
       "      <td>Carliane Melo Alves Melgarejo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42202</td>\n",
       "      <td>Clarissa Perdigao Mello Ferraz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42383</td>\n",
       "      <td>Eric Ribeiro Da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42550</td>\n",
       "      <td>Fatima Daiana Dias Barroso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42859</td>\n",
       "      <td>Fatima De Cássia Evangelista De Oliveira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fernanda Montenegro De Carvalho Araujo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>43091</td>\n",
       "      <td>Geiciane Silva Maia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42575</td>\n",
       "      <td>Germana Silva Vasconcelos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>43053</td>\n",
       "      <td>Helen Paula Silva Da Costa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>43054</td>\n",
       "      <td>Igor De Sá Carneiro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42531</td>\n",
       "      <td>Júlio César Martins Ximenes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>43164</td>\n",
       "      <td>Katia Danielle Loiola Barbosa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42559</td>\n",
       "      <td>Larisse Tavares Lucetti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42204</td>\n",
       "      <td>Maria Claudia Dos Santos Luciano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42858</td>\n",
       "      <td>Maria Francilene Souza Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>45453</td>\n",
       "      <td>Maria Lucila Do Nascimento</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42857</td>\n",
       "      <td>Max Moreira Lizano Garcia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>44435</td>\n",
       "      <td>Mayara Ferreira De Oliveira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42382</td>\n",
       "      <td>Odirene Braga Chaves Dos Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42293</td>\n",
       "      <td>Ondina Maria Chagas Canuto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42387</td>\n",
       "      <td>Paulo Andre Sousa Da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42576</td>\n",
       "      <td>Pedro Afonso De Oliveira Martins</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>43124</td>\n",
       "      <td>Rosangela Ferreira Da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42496</td>\n",
       "      <td>Vanessa Pio Almeida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>42276</td>\n",
       "      <td>Victor De Lima Pinheiro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNADIG</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ademir da Conceição Araujo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albertina Bezerra  Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albio Pereira Cruz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexandro Procopio Sousa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Almir Marques de Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alvaro Luis  Barbosa de  Oliveira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ana Carolina Sales Vital</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ana Cristina Ricardo da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anderson dos Santos Dias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antonia Angela Alves Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antonia Beatriz Lucio Nunes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antoniel Martins  Felix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antoniele Martins  Felix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antonio Cleiton Pereira Bezerra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antonio Lucilanio Silva de Oliveira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antonio Mauro Rodrigues dos Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antonio Ramos da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Antonio Valdo Souza Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arides Souza  Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ariemily da Silva Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arthur Silva Assuncao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Breno Soares da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bruno Henrique Ribeiro da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bruno Marques Santiago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carla Dariane Freitas Abreu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carla Michelle de Sousa  Vieira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carlos Silva de Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carlos Wilker Castelo Lobo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carolina Oliveira de Menezes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carolina Ramos  Ferreira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cassia da  Silva Feitosa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Claudemir Menezes  Mariano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Claudenir Gomes  Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cleiton Melo dos Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Davi felipe Cavalcante Mendes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Douglas Mateus Bezerra  Fernandes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ednardo Ventura da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edilardo Reinaldo Vitorino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edson Cavalcante  Chagas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edson de Luna Pereira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eduardo Melo dos  Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elivaldo dos Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elizeu da Silva Freitas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eliziano Anastacio da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Emanuel Oliveira dos Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eugenio Andre Nunes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Felipe de Sousa  Araujo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisca Rafahelia da Silva Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco Alexandre Ripardo  Pereira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco Alves da Silva  Junior</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco de Assis da Silva dos  Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco Diogenes Almeida de Aquino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco Edgard  Albuquerque Filho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco Gildevan Santos Gama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco Jairton Nunes da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco joelton da Silva  Nogueira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco jose Candeia Sampaio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco Nelson  Simplicio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco Valdemi Leite da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Francisco Wagner  Rodrigues</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geilson Silva de  Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geisa do Nascimento Soares</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geremias Rodrigues  Moreira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Germano Ferreira  Soares</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gilkaster Barboza  Maciel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Girlene Cabral  Evangelista</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gleison Ferreira da  Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Herikles Wesley Vasconcelos  Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hugo Tavares  Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iara Felix  Tiburcio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iran Lima Facanha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iuri Freitas  Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ivana da Silva Ferreira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Izidio Silvino de Assunção  Neto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jario dos Santos Souza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeovane Ferreira de Sousa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joao Carlos Lima  Tiburcio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joao Neto Felix de Almeida</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joao Paulo Pereira  Ventura</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joao Ricardo de Oliveira  Gomes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jocelio Nascimento de Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jonas dos Santos Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jose Airton Gomes Pereira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jose Alves de Castro Neto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jose Dionizio Rodrigues Pereira Filho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jose Evani Ferreira  Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jose Vilmar Ribeiro Nascimento</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Josimar Ramos Cavalcante</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joyce de Aguiar Loureiro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Julio dos  Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leonardo Sousa  Nascimento</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lucas Leonardo Freitas Matos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lucas Lourenco  Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lucas Santos  Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Luiz Antonio  Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcielle Honorato de Araujo Tiburcio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcos Rogerio da Silva Rocha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maria Cleia Lopes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maria Edineide Rodrigues da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maria Isabele dos Santos Campina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maria Juliana Alves da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maria Milena Silva do Nascimento</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maria Valdenia Tiburcio Tavares Oliveira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marilia Pereira  Inacio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mauricio Pereira Inacio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mileide de Albuquerque Santos  Viegas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mileno Henrique de Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Naiara Silva Gomes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natanael da Silva  Alves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natanael da Silva  Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nathanael Lima de Sousa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paulo Henrique Silva dos Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paulo Marco Nunes da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pedro Guilherme Queiroz e Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raimundo Nonato Xavier Pereira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raphael Sousa  Oliveira</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rayane Reges Fernandes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Renato Reinaldo  Vitorino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roberto de Almeida Facanha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Romildo Lima dos Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ronaldo Almeida de Lima</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rubens Franca Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Saiure Martins do Nascimento</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samia da Silva Souza</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samuel Augusto Falcao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samuel Freitas Gomes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sebastiao do Carmo Braz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stevenson Janvier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tailane Soares  Alves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tiago Matos  Sappi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tyago da Silva Severo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valdenia Pereira  Tavares</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vanderson Costa da Silva</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wagner Lucio de Sousa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Weslei de Almeida Abreu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Maria ivanilda Conceição Carmo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Igor Bezerra  Farias</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jean Carlos Ferreira Santos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valdemir de Sousa  Machado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>ATIVO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thiago Silva de França</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMATEL</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>APOSENTADA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rose Mary Faria Torres de Oliveira</td>\n",
       "      <td>Coordenação Geral</td>\n",
       "      <td>Assistente Tecnico de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR</td>\n",
       "      <td>2009-06-22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>REMOÇÃO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geisa Francisco da Silva</td>\n",
       "      <td>Coordenação Geral</td>\n",
       "      <td>Assistente Tecnico de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR-CEDIDA PARA CORREGEDORIA</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>REMOÇÃO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aline do Monte Gurgel</td>\n",
       "      <td>Coordenação Geral</td>\n",
       "      <td>Pesquisador em Saúde Pública</td>\n",
       "      <td>SERVIDOR-CEDIDA PARA FIOCRUZ PE</td>\n",
       "      <td>2015-07-27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>REMOÇÃO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gilberto Santiago Araujo</td>\n",
       "      <td>Coordenação Geral</td>\n",
       "      <td>Analista de Gestão em Saúde</td>\n",
       "      <td>SERVIDOR-CEDIDO PARA AUDITORIA INTERNA</td>\n",
       "      <td>2012-09-14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    STATUS              MATRÍCULA    \n",
       "0                 ATIVO    2242450  \\\n",
       "1                 ATIVO    1165347   \n",
       "2                 ATIVO    1014947   \n",
       "3                 ATIVO     626325   \n",
       "4                 ATIVO    1896774   \n",
       "5                 ATIVO   21819093   \n",
       "6                 ATIVO        N/I   \n",
       "7                 ATIVO    1683775   \n",
       "8                 ATIVO    2904868   \n",
       "9                 ATIVO    1913135   \n",
       "10                ATIVO    2175249   \n",
       "11                ATIVO    1683295   \n",
       "12                ATIVO    1538475   \n",
       "13                ATIVO    1613229   \n",
       "14                ATIVO    1993800   \n",
       "15                ATIVO    2181594   \n",
       "16                ATIVO        NaN   \n",
       "17                ATIVO    1319630   \n",
       "18                ATIVO    2182142   \n",
       "19                ATIVO  \\t0445970   \n",
       "20                ATIVO    1344058   \n",
       "21                ATIVO    2243169   \n",
       "22                ATIVO    1493522   \n",
       "23                ATIVO   224946-3   \n",
       "24                ATIVO    1985736   \n",
       "25                ATIVO    2184558   \n",
       "26                ATIVO    1350230   \n",
       "27                ATIVO    1715669   \n",
       "28                ATIVO    3121258   \n",
       "29                ATIVO    1049924   \n",
       "30                ATIVO    1497987   \n",
       "31             AFASTADO    1556031   \n",
       "32                ATIVO    2838905   \n",
       "33                ATIVO    1902167   \n",
       "34                ATIVO    1359804   \n",
       "35                ATIVO    2079552   \n",
       "36                ATIVO    2013979   \n",
       "37                ATIVO     747225   \n",
       "38                ATIVO    1350229   \n",
       "39                ATIVO    1985995   \n",
       "40                ATIVO    2180858   \n",
       "41                ATIVO    1952032   \n",
       "42                ATIVO    1806284   \n",
       "43             AFASTADO    1901024   \n",
       "44                ATIVO    1188635   \n",
       "45                ATIVO    1556258   \n",
       "46                ATIVO     464200   \n",
       "47                ATIVO    1634325   \n",
       "48                ATIVO    2180289   \n",
       "49                ATIVO    2181469   \n",
       "50                ATIVO    1727289   \n",
       "51                ATIVO    1985557   \n",
       "52                ATIVO    1581487   \n",
       "53             AFASTADO    1437828   \n",
       "54                ATIVO     669534   \n",
       "55            EXONERADO   30137403   \n",
       "56                ATIVO    1165326   \n",
       "57                ATIVO    1992814   \n",
       "58                ATIVO    3121915   \n",
       "59                ATIVO        NaN   \n",
       "60                ATIVO        NaN   \n",
       "61                ATIVO        NaN   \n",
       "62                ATIVO        NaN   \n",
       "63                ATIVO        NaN   \n",
       "64                ATIVO        NaN   \n",
       "65                ATIVO        NaN   \n",
       "66                ATIVO        NaN   \n",
       "67                ATIVO        NaN   \n",
       "68   CONTRATO ENCERRADO        NaN   \n",
       "69                ATIVO        NaN   \n",
       "70                ATIVO        NaN   \n",
       "71                ATIVO        NaN   \n",
       "72                ATIVO        NaN   \n",
       "73   CONTRATO ENCERRADO        NaN   \n",
       "74                ATIVO        NaN   \n",
       "75                ATIVO        NaN   \n",
       "76   CONTRATO ENCERRADO        NaN   \n",
       "77                ATIVO        NaN   \n",
       "78                ATIVO        NaN   \n",
       "79                ATIVO        NaN   \n",
       "80                ATIVO        NaN   \n",
       "81                ATIVO        NaN   \n",
       "82                ATIVO        NaN   \n",
       "83   CONTRATO ENCERRADO        NaN   \n",
       "84                ATIVO        NaN   \n",
       "85                ATIVO        NaN   \n",
       "86                ATIVO        NaN   \n",
       "87                ATIVO        NaN   \n",
       "88   CONTRATO ENCERRADO        NaN   \n",
       "89                ATIVO        NaN   \n",
       "90   CONTRATO ENCERRADO        NaN   \n",
       "91                ATIVO        NaN   \n",
       "92   CONTRATO ENCERRADO        NaN   \n",
       "93   CONTRATO ENCERRADO        NaN   \n",
       "94   CONTRATO ENCERRADO        NaN   \n",
       "95   CONTRATO ENCERRADO        NaN   \n",
       "96                ATIVO        NaN   \n",
       "97                ATIVO        NaN   \n",
       "98                ATIVO        NaN   \n",
       "99                ATIVO        NaN   \n",
       "100               ATIVO        NaN   \n",
       "101               ATIVO        NaN   \n",
       "102               ATIVO        NaN   \n",
       "103               ATIVO        NaN   \n",
       "104               ATIVO        NaN   \n",
       "105               ATIVO        NaN   \n",
       "106               ATIVO        NaN   \n",
       "107               ATIVO        NaN   \n",
       "108               ATIVO        NaN   \n",
       "109               ATIVO        NaN   \n",
       "110               ATIVO        NaN   \n",
       "111               ATIVO      42241   \n",
       "112               ATIVO        NaN   \n",
       "113               ATIVO      42266   \n",
       "114               ATIVO      42532   \n",
       "115               ATIVO      43083   \n",
       "116               ATIVO      42202   \n",
       "117               ATIVO      42383   \n",
       "118               ATIVO      42550   \n",
       "119               ATIVO      42859   \n",
       "120               ATIVO        NaN   \n",
       "121               ATIVO      43091   \n",
       "122               ATIVO      42575   \n",
       "123               ATIVO      43053   \n",
       "124               ATIVO      43054   \n",
       "125               ATIVO      42531   \n",
       "126               ATIVO      43164   \n",
       "127               ATIVO      42559   \n",
       "128               ATIVO      42204   \n",
       "129               ATIVO      42858   \n",
       "130               ATIVO      45453   \n",
       "131               ATIVO      42857   \n",
       "132               ATIVO      44435   \n",
       "133               ATIVO      42382   \n",
       "134               ATIVO      42293   \n",
       "135               ATIVO      42387   \n",
       "136               ATIVO      42576   \n",
       "137               ATIVO      43124   \n",
       "138               ATIVO      42496   \n",
       "139               ATIVO      42276   \n",
       "140               ATIVO        NaN   \n",
       "141               ATIVO        NaN   \n",
       "142               ATIVO        NaN   \n",
       "143               ATIVO        NaN   \n",
       "144               ATIVO        NaN   \n",
       "145               ATIVO        NaN   \n",
       "146               ATIVO        NaN   \n",
       "147               ATIVO        NaN   \n",
       "148               ATIVO        NaN   \n",
       "149               ATIVO        NaN   \n",
       "150               ATIVO        NaN   \n",
       "151               ATIVO        NaN   \n",
       "152               ATIVO        NaN   \n",
       "153               ATIVO        NaN   \n",
       "154               ATIVO        NaN   \n",
       "155               ATIVO        NaN   \n",
       "156               ATIVO        NaN   \n",
       "157               ATIVO        NaN   \n",
       "158               ATIVO        NaN   \n",
       "159               ATIVO        NaN   \n",
       "160               ATIVO        NaN   \n",
       "161               ATIVO        NaN   \n",
       "162               ATIVO        NaN   \n",
       "163               ATIVO        NaN   \n",
       "164               ATIVO        NaN   \n",
       "165               ATIVO        NaN   \n",
       "166               ATIVO        NaN   \n",
       "167               ATIVO        NaN   \n",
       "168               ATIVO        NaN   \n",
       "169               ATIVO        NaN   \n",
       "170               ATIVO        NaN   \n",
       "171               ATIVO        NaN   \n",
       "172               ATIVO        NaN   \n",
       "173               ATIVO        NaN   \n",
       "174               ATIVO        NaN   \n",
       "175               ATIVO        NaN   \n",
       "176               ATIVO        NaN   \n",
       "177               ATIVO        NaN   \n",
       "178               ATIVO        NaN   \n",
       "179               ATIVO        NaN   \n",
       "180               ATIVO        NaN   \n",
       "181               ATIVO        NaN   \n",
       "182               ATIVO        NaN   \n",
       "183               ATIVO        NaN   \n",
       "184               ATIVO        NaN   \n",
       "185               ATIVO        NaN   \n",
       "186               ATIVO        NaN   \n",
       "187               ATIVO        NaN   \n",
       "188               ATIVO        NaN   \n",
       "189               ATIVO        NaN   \n",
       "190               ATIVO        NaN   \n",
       "191               ATIVO        NaN   \n",
       "192               ATIVO        NaN   \n",
       "193               ATIVO        NaN   \n",
       "194               ATIVO        NaN   \n",
       "195               ATIVO        NaN   \n",
       "196               ATIVO        NaN   \n",
       "197               ATIVO        NaN   \n",
       "198               ATIVO        NaN   \n",
       "199               ATIVO        NaN   \n",
       "200               ATIVO        NaN   \n",
       "201               ATIVO        NaN   \n",
       "202               ATIVO        NaN   \n",
       "203               ATIVO        NaN   \n",
       "204               ATIVO        NaN   \n",
       "205               ATIVO        NaN   \n",
       "206               ATIVO        NaN   \n",
       "207               ATIVO        NaN   \n",
       "208               ATIVO        NaN   \n",
       "209               ATIVO        NaN   \n",
       "210               ATIVO        NaN   \n",
       "211               ATIVO        NaN   \n",
       "212               ATIVO        NaN   \n",
       "213               ATIVO        NaN   \n",
       "214               ATIVO        NaN   \n",
       "215               ATIVO        NaN   \n",
       "216               ATIVO        NaN   \n",
       "217               ATIVO        NaN   \n",
       "218               ATIVO        NaN   \n",
       "219               ATIVO        NaN   \n",
       "220               ATIVO        NaN   \n",
       "221               ATIVO        NaN   \n",
       "222               ATIVO        NaN   \n",
       "223               ATIVO        NaN   \n",
       "224               ATIVO        NaN   \n",
       "225               ATIVO        NaN   \n",
       "226               ATIVO        NaN   \n",
       "227               ATIVO        NaN   \n",
       "228               ATIVO        NaN   \n",
       "229               ATIVO        NaN   \n",
       "230               ATIVO        NaN   \n",
       "231               ATIVO        NaN   \n",
       "232               ATIVO        NaN   \n",
       "233               ATIVO        NaN   \n",
       "234               ATIVO        NaN   \n",
       "235               ATIVO        NaN   \n",
       "236               ATIVO        NaN   \n",
       "237               ATIVO        NaN   \n",
       "238               ATIVO        NaN   \n",
       "239               ATIVO        NaN   \n",
       "240               ATIVO        NaN   \n",
       "241               ATIVO        NaN   \n",
       "242               ATIVO        NaN   \n",
       "243               ATIVO        NaN   \n",
       "244               ATIVO        NaN   \n",
       "245               ATIVO        NaN   \n",
       "246               ATIVO        NaN   \n",
       "247               ATIVO        NaN   \n",
       "248               ATIVO        NaN   \n",
       "249               ATIVO        NaN   \n",
       "250               ATIVO        NaN   \n",
       "251               ATIVO        NaN   \n",
       "252               ATIVO        NaN   \n",
       "253               ATIVO        NaN   \n",
       "254               ATIVO        NaN   \n",
       "255               ATIVO        NaN   \n",
       "256               ATIVO        NaN   \n",
       "257               ATIVO        NaN   \n",
       "258               ATIVO        NaN   \n",
       "259               ATIVO        NaN   \n",
       "260               ATIVO        NaN   \n",
       "261               ATIVO        NaN   \n",
       "262               ATIVO        NaN   \n",
       "263               ATIVO        NaN   \n",
       "264               ATIVO        NaN   \n",
       "265               ATIVO        NaN   \n",
       "266               ATIVO        NaN   \n",
       "267               ATIVO        NaN   \n",
       "268               ATIVO        NaN   \n",
       "269               ATIVO        NaN   \n",
       "270               ATIVO        NaN   \n",
       "271               ATIVO        NaN   \n",
       "272               ATIVO        NaN   \n",
       "273               ATIVO        NaN   \n",
       "274               ATIVO        NaN   \n",
       "275               ATIVO        NaN   \n",
       "276               ATIVO        NaN   \n",
       "277               ATIVO        NaN   \n",
       "278               ATIVO        NaN   \n",
       "279               ATIVO        NaN   \n",
       "280          APOSENTADA        NaN   \n",
       "281             REMOÇÃO        NaN   \n",
       "282             REMOÇÃO        NaN   \n",
       "283             REMOÇÃO        NaN   \n",
       "\n",
       "    NOME                                            \n",
       "0               Alice Paula Di Sabatino Guimaraes  \\\n",
       "1                  Ana Claudia De Araújo Teixeira   \n",
       "2                       Ana Camila Oliveira Alves   \n",
       "3              Angela Christina De Moraes Ostritz   \n",
       "4                            Adriana Costa Bacelo   \n",
       "5                   Anna Carolina Machado Marinho   \n",
       "6                Antonio Carlile De Holanda Lavor   \n",
       "7                    Antonio Marcos Aires Barbosa   \n",
       "8      Anya Pimentel Gomes Fernandes Vieira Meyer   \n",
       "9                          Bruno Bezerra Carvalho   \n",
       "10               Carla Freire Celedônio Fernandes   \n",
       "11                    Carlos Jose Araujo Pinheiro   \n",
       "12                          Claudia Stutz Zubieta   \n",
       "13                     Charles Cerqueira De Abreu   \n",
       "14                    Clarice Gomes E Souza Dabés   \n",
       "15                       Clarissa Romero Teixeira   \n",
       "16                             Dayane Alves Costa   \n",
       "17                Donat Alexander De Chapeaurouge   \n",
       "18                      Eduardo Ruback Dos Santos   \n",
       "19                      Ezequiel Valentim De Melo   \n",
       "20                                 Fabio Miyajima   \n",
       "21                   Fernando Braga Stehling Dias   \n",
       "22                     Fernando Ferreira Carneiro   \n",
       "23                             Galba Freire Moita   \n",
       "24   Giovanny Augusto Camacho Antevere Mazzarotto   \n",
       "25                          Gilvan Pessoa Furtado   \n",
       "26        Ivana Cristina De Holanda Cunha Barrêto   \n",
       "27                          Ivanildo Lopes Farias   \n",
       "28                            Jaime Ribeiro Filho   \n",
       "29                    João Baptista Estabile Neto   \n",
       "30                 João Hermínio Martins Da Silva   \n",
       "31                      José Luis Passos Cordeiro   \n",
       "32                       Kamila Matos Albuquerque   \n",
       "33                         Luciana Coelho Serafim   \n",
       "34                    Luciana Pereira Lindenmeyer   \n",
       "35      Luciana Silvério Alleluia Higino Da Silva   \n",
       "36                       Luciano Pinto Zorzanelli   \n",
       "37                Luis Fernando Pessoa De Andrade   \n",
       "38               Luiz Odorico Monteiro De Andrade   \n",
       "39                  Marcela Helena Gambim Fonseca   \n",
       "40                   Marcelo Jorge Lopes Coutinho   \n",
       "41                      Marcos Roberto Lourenzoni   \n",
       "42                  Marcio Flavio Moura De Araujo   \n",
       "43                Margareth Borges Coutinho Gallo   \n",
       "44                      Marlos De Medeiros Chaves   \n",
       "45              Maximiliano Loiola Ponte De Souza   \n",
       "46                      Nilton Luiz Costa Machado   \n",
       "47               Patricia Maria Ferreira da Silva   \n",
       "48                              Raphael Trevizani   \n",
       "49                   Regis Bernardo Brandim Gomes   \n",
       "50                       Renato Caldeira De Souza   \n",
       "51                               Roberto Nicolete   \n",
       "52        Roberto Wagner Junior Freire De Freitas   \n",
       "53                      Rodrigo Carvalho Nogueira   \n",
       "54                         Sergio Dos Santos Reis   \n",
       "55                            Sandro Gomes Soares   \n",
       "56                Sharmenia De Araujo Soares Nuto   \n",
       "57                            Vanira Matos Pessoa   \n",
       "58                Venúcia Bruna Magalhães Pereira   \n",
       "59                       Eliezio Lessa Dos Santos   \n",
       "60         Dann Eliézer Guimarães Martins Barbosa   \n",
       "61                  Mario Italo Coelho Dos Santos   \n",
       "62                            Fabio Martins Uchoa   \n",
       "63                     Gutemberg Monteiro Regadas   \n",
       "64                        Jessiedna Holanda Lemos   \n",
       "65                Paulo Wanderson Rodrigues Viana   \n",
       "66                   Wagner Alves De Souza Júnior   \n",
       "67                   Amanda Cacau De Souza Paixão   \n",
       "68             Amanda Sobreira Quintino De Castro   \n",
       "69                        Rejane Pereira Da Silva   \n",
       "70                          Vanessa Do Nascimento   \n",
       "71                        Romulo Silva Dos Santos   \n",
       "72                  Antonia Yasmim Da Costa Sales   \n",
       "73                        Tania Caldeira De Souza   \n",
       "74                Vera Marta Neves Amarante Rabay   \n",
       "75                       Paulo Rafael Silva Sousa   \n",
       "76                  Suerda Cristina Pereira Silva   \n",
       "77                     Amilton Albuquerque Pontes   \n",
       "78                Ilana Carneiro Lisboa Magalhães   \n",
       "79                    Carolina Campos de Oliveira   \n",
       "80                     Gabriel Coutinho Gonçalves   \n",
       "81                          Elian Matias Da Silva   \n",
       "82                      Gabriel De Moura Minarini   \n",
       "83              Andreia Vitória Damasceno Calixto   \n",
       "84                 Camila Victor Vitorino Holanda   \n",
       "85                     Camilla Do Nascimento Cruz   \n",
       "86              Cesarina De Sousa Mendes Da Costa   \n",
       "87               Carlos Augusto Guimarães Fonseca   \n",
       "88                        Derick Rosa De Oliveira   \n",
       "89                  Derick Carvalho Ribeiro Silva   \n",
       "90                      Edmilson Santana De Souza   \n",
       "91                   Janaina De Oliveira Da Silva   \n",
       "92             Letícia Gabriele Saraiva De Farias   \n",
       "93                   Patricia Fernanda Rocha Dias   \n",
       "94                          Suzy Anne Alves Pinto   \n",
       "95                       Sarah Sant'Anna Maranhão   \n",
       "96                      Daniel Pascolino Pinheiro   \n",
       "97                    Suelen Carneiro de Medeiros   \n",
       "98                           Maisa de Sales Costa   \n",
       "99            Isabela Cristina da Paixão Minarini   \n",
       "100             Adelaide Souza da Silva Rodrigues   \n",
       "101                 Cecilia Katia Ferreira Santos   \n",
       "102                           Gustavo Souza Pinto   \n",
       "103                     Mauricio Fraga Van Tiburg   \n",
       "104                   Flora Viana Elizeu da Silva   \n",
       "105                 Francisco Eder de Moura Lopes   \n",
       "106                   Jamille Mara Mendes Bezerra   \n",
       "107                    Darlyson Tavares Guimarães   \n",
       "108                   Ticiane Cavalcante de Souza   \n",
       "109                   Maria Eduarda Guedes Onofre   \n",
       "110           Francisco Leandro Fernandes Sampaio   \n",
       "111               Adriana Carvalho De Albuquerque   \n",
       "112                    Alberto Davi Gomes Tavares   \n",
       "113             Ana Carolina Matias Dinelly Pinto   \n",
       "114        Bárbara Cibelle Soares Farias Quintela   \n",
       "115                 Carliane Melo Alves Melgarejo   \n",
       "116                Clarissa Perdigao Mello Ferraz   \n",
       "117                         Eric Ribeiro Da Silva   \n",
       "118                    Fatima Daiana Dias Barroso   \n",
       "119      Fatima De Cássia Evangelista De Oliveira   \n",
       "120        Fernanda Montenegro De Carvalho Araujo   \n",
       "121                           Geiciane Silva Maia   \n",
       "122                     Germana Silva Vasconcelos   \n",
       "123                    Helen Paula Silva Da Costa   \n",
       "124                           Igor De Sá Carneiro   \n",
       "125                   Júlio César Martins Ximenes   \n",
       "126                 Katia Danielle Loiola Barbosa   \n",
       "127                       Larisse Tavares Lucetti   \n",
       "128              Maria Claudia Dos Santos Luciano   \n",
       "129                  Maria Francilene Souza Silva   \n",
       "130                    Maria Lucila Do Nascimento   \n",
       "131                     Max Moreira Lizano Garcia   \n",
       "132                   Mayara Ferreira De Oliveira   \n",
       "133               Odirene Braga Chaves Dos Santos   \n",
       "134                    Ondina Maria Chagas Canuto   \n",
       "135                    Paulo Andre Sousa Da Silva   \n",
       "136              Pedro Afonso De Oliveira Martins   \n",
       "137                   Rosangela Ferreira Da Silva   \n",
       "138                           Vanessa Pio Almeida   \n",
       "139                       Victor De Lima Pinheiro   \n",
       "140                    Ademir da Conceição Araujo   \n",
       "141                      Albertina Bezerra  Silva   \n",
       "142                            Albio Pereira Cruz   \n",
       "143                      Alexandro Procopio Sousa   \n",
       "144                         Almir Marques de Lima   \n",
       "145             Alvaro Luis  Barbosa de  Oliveira   \n",
       "146                      Ana Carolina Sales Vital   \n",
       "147                 Ana Cristina Ricardo da Silva   \n",
       "148                      Anderson dos Santos Dias   \n",
       "149                     Antonia Angela Alves Lima   \n",
       "150                   Antonia Beatriz Lucio Nunes   \n",
       "151                       Antoniel Martins  Felix   \n",
       "152                      Antoniele Martins  Felix   \n",
       "153               Antonio Cleiton Pereira Bezerra   \n",
       "154           Antonio Lucilanio Silva de Oliveira   \n",
       "155            Antonio Mauro Rodrigues dos Santos   \n",
       "156                        Antonio Ramos da Silva   \n",
       "157                     Antonio Valdo Souza Silva   \n",
       "158                            Arides Souza  Lima   \n",
       "159                        Ariemily da Silva Lima   \n",
       "160                         Arthur Silva Assuncao   \n",
       "161                         Breno Soares da Silva   \n",
       "162               Bruno Henrique Ribeiro da Silva   \n",
       "163                        Bruno Marques Santiago   \n",
       "164                   Carla Dariane Freitas Abreu   \n",
       "165               Carla Michelle de Sousa  Vieira   \n",
       "166                          Carlos Silva de Lima   \n",
       "167                    Carlos Wilker Castelo Lobo   \n",
       "168                  Carolina Oliveira de Menezes   \n",
       "169                      Carolina Ramos  Ferreira   \n",
       "170                      Cassia da  Silva Feitosa   \n",
       "171                    Claudemir Menezes  Mariano   \n",
       "172                        Claudenir Gomes  Silva   \n",
       "173                       Cleiton Melo dos Santos   \n",
       "174                 Davi felipe Cavalcante Mendes   \n",
       "175             Douglas Mateus Bezerra  Fernandes   \n",
       "176                      Ednardo Ventura da Silva   \n",
       "177                    Edilardo Reinaldo Vitorino   \n",
       "178                      Edson Cavalcante  Chagas   \n",
       "179                         Edson de Luna Pereira   \n",
       "180                      Eduardo Melo dos  Santos   \n",
       "181                           Elivaldo dos Santos   \n",
       "182                       Elizeu da Silva Freitas   \n",
       "183                   Eliziano Anastacio da Silva   \n",
       "184                   Emanuel Oliveira dos Santos   \n",
       "185                           Eugenio Andre Nunes   \n",
       "186                       Felipe de Sousa  Araujo   \n",
       "187             Francisca Rafahelia da Silva Lima   \n",
       "188          Francisco Alexandre Ripardo  Pereira   \n",
       "189              Francisco Alves da Silva  Junior   \n",
       "190       Francisco de Assis da Silva dos  Santos   \n",
       "191          Francisco Diogenes Almeida de Aquino   \n",
       "192           Francisco Edgard  Albuquerque Filho   \n",
       "193                Francisco Gildevan Santos Gama   \n",
       "194              Francisco Jairton Nunes da Silva   \n",
       "195          Francisco joelton da Silva  Nogueira   \n",
       "196                Francisco jose Candeia Sampaio   \n",
       "197                   Francisco Nelson  Simplicio   \n",
       "198              Francisco Valdemi Leite da Silva   \n",
       "199                   Francisco Wagner  Rodrigues   \n",
       "200                        Geilson Silva de  Lima   \n",
       "201                    Geisa do Nascimento Soares   \n",
       "202                   Geremias Rodrigues  Moreira   \n",
       "203                      Germano Ferreira  Soares   \n",
       "204                     Gilkaster Barboza  Maciel   \n",
       "205                   Girlene Cabral  Evangelista   \n",
       "206                    Gleison Ferreira da  Silva   \n",
       "207            Herikles Wesley Vasconcelos  Silva   \n",
       "208                            Hugo Tavares  Lima   \n",
       "209                          Iara Felix  Tiburcio   \n",
       "210                             Iran Lima Facanha   \n",
       "211                          Iuri Freitas  Santos   \n",
       "212                       Ivana da Silva Ferreira   \n",
       "213              Izidio Silvino de Assunção  Neto   \n",
       "214                        Jario dos Santos Souza   \n",
       "215                     Jeovane Ferreira de Sousa   \n",
       "216                    Joao Carlos Lima  Tiburcio   \n",
       "217                    Joao Neto Felix de Almeida   \n",
       "218                   Joao Paulo Pereira  Ventura   \n",
       "219               Joao Ricardo de Oliveira  Gomes   \n",
       "220                    Jocelio Nascimento de Lima   \n",
       "221                        Jonas dos Santos Silva   \n",
       "222                     Jose Airton Gomes Pereira   \n",
       "223                     Jose Alves de Castro Neto   \n",
       "224         Jose Dionizio Rodrigues Pereira Filho   \n",
       "225                   Jose Evani Ferreira  Santos   \n",
       "226                Jose Vilmar Ribeiro Nascimento   \n",
       "227                      Josimar Ramos Cavalcante   \n",
       "228                      Joyce de Aguiar Loureiro   \n",
       "229                             Julio dos  Santos   \n",
       "230                    Leonardo Sousa  Nascimento   \n",
       "231                  Lucas Leonardo Freitas Matos   \n",
       "232                         Lucas Lourenco  Silva   \n",
       "233                           Lucas Santos  Silva   \n",
       "234                           Luiz Antonio  Silva   \n",
       "235         Marcielle Honorato de Araujo Tiburcio   \n",
       "236                 Marcos Rogerio da Silva Rocha   \n",
       "237                             Maria Cleia Lopes   \n",
       "238             Maria Edineide Rodrigues da Silva   \n",
       "239              Maria Isabele dos Santos Campina   \n",
       "240                  Maria Juliana Alves da Silva   \n",
       "241              Maria Milena Silva do Nascimento   \n",
       "242      Maria Valdenia Tiburcio Tavares Oliveira   \n",
       "243                       Marilia Pereira  Inacio   \n",
       "244                       Mauricio Pereira Inacio   \n",
       "245         Mileide de Albuquerque Santos  Viegas   \n",
       "246                       Mileno Henrique de Lima   \n",
       "247                            Naiara Silva Gomes   \n",
       "248                      Natanael da Silva  Alves   \n",
       "249                       Natanael da Silva  Lima   \n",
       "250                       Nathanael Lima de Sousa   \n",
       "251               Paulo Henrique Silva dos Santos   \n",
       "252                    Paulo Marco Nunes da Silva   \n",
       "253               Pedro Guilherme Queiroz e Silva   \n",
       "254                Raimundo Nonato Xavier Pereira   \n",
       "255                       Raphael Sousa  Oliveira   \n",
       "256                        Rayane Reges Fernandes   \n",
       "257                     Renato Reinaldo  Vitorino   \n",
       "258                    Roberto de Almeida Facanha   \n",
       "259                       Romildo Lima dos Santos   \n",
       "260                       Ronaldo Almeida de Lima   \n",
       "261                           Rubens Franca Silva   \n",
       "262                  Saiure Martins do Nascimento   \n",
       "263                          Samia da Silva Souza   \n",
       "264                         Samuel Augusto Falcao   \n",
       "265                          Samuel Freitas Gomes   \n",
       "266                       Sebastiao do Carmo Braz   \n",
       "267                             Stevenson Janvier   \n",
       "268                         Tailane Soares  Alves   \n",
       "269                            Tiago Matos  Sappi   \n",
       "270                         Tyago da Silva Severo   \n",
       "271                     Valdenia Pereira  Tavares   \n",
       "272                      Vanderson Costa da Silva   \n",
       "273                         Wagner Lucio de Sousa   \n",
       "274                       Weslei de Almeida Abreu   \n",
       "275                Maria ivanilda Conceição Carmo   \n",
       "276                          Igor Bezerra  Farias   \n",
       "277                   Jean Carlos Ferreira Santos   \n",
       "278                    Valdemir de Sousa  Machado   \n",
       "279                        Thiago Silva de França   \n",
       "280            Rose Mary Faria Torres de Oliveira   \n",
       "281                      Geisa Francisco da Silva   \n",
       "282                         Aline do Monte Gurgel   \n",
       "283                      Gilberto Santiago Araujo   \n",
       "\n",
       "    ÁREA                                                                              \n",
       "0                                           Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)  \\\n",
       "1                                                                  Saúde e Ambiente   \n",
       "2                                    Coordenação de Pesquisa e Coleções Biológicas    \n",
       "3                                                                 Coordenação Geral   \n",
       "4                                                                     Saúde Digital   \n",
       "5                                                     Coordenação Geral (QUALIDADE)   \n",
       "6                                                                Coordenação Geral    \n",
       "7                                    Coordenação de Pesquisa e Coleções Biológicas    \n",
       "8                                                                  Saúde da Família   \n",
       "9              Coordenação da Gestão e Desenvolvimento Institucional (COORDENAÇÃO)    \n",
       "10                                                                Coordenação Geral   \n",
       "11         Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)   \n",
       "12                                          Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)   \n",
       "13              Coordenação da Gestão e Desenvolvimento Institucional(ALMOXARIFADO)   \n",
       "14                                                    Coordenação Geral (QUALIDADE)   \n",
       "15                                           Biotecnologia-GR1 (IMUNOPARASITOLOGIA)   \n",
       "16                                   Coordenação de Pesquisa e Coleções Biológicas    \n",
       "17                                                Biotecnologia-GR3 (BIOTECNOLOGIA)   \n",
       "18                                                                Coordenação Geral   \n",
       "19               Coordenação da Gestão e Desenvolvimento Institucional (FINANCEIRO)   \n",
       "20                                          Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)   \n",
       "21                                          Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)   \n",
       "22                                                                 Saúde e Ambiente   \n",
       "23                                    Coordenação de Produção e  Inovação em Saúde    \n",
       "24                                          Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)   \n",
       "25                                                Biotecnologia-GR3 (BIOTECNOLOGIA)   \n",
       "26                                                                    Saúde Digital   \n",
       "27   Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA / SIMAM)   \n",
       "28                                                               Coordenação Geral    \n",
       "29                  Coordenação de Educação, Informação e Comunicação (COMUNICAÇÃO)   \n",
       "30                                   Coordenação de Pesquisa e Coleções Biológicas    \n",
       "31                                                                 Saúde e Ambiente   \n",
       "32                                                       Central Analitica - UNADIG   \n",
       "33             Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)   \n",
       "34         Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)   \n",
       "35                 Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)   \n",
       "36                      Coordenação da Gestão e Desenvolvimento Institucional (TIC)   \n",
       "37                                    Coordenação de Produção e  Inovação em Saúde    \n",
       "38                                    Coordenação de Produção e  Inovação em Saúde    \n",
       "39                                                       Central Analitica - UNADIG   \n",
       "40                                                Biotecnologia-GR3 (BIOTECNOLOGIA)   \n",
       "41                                                Biotecnologia-GR3 (BIOTECNOLOGIA)   \n",
       "42                                                                 Saúde da Família   \n",
       "43                                                                 Saúde e Ambiente   \n",
       "44                                           Biotecnologia-GR1 (IMUNOPARASITOLOGIA)   \n",
       "45                                                                 Saúde da Família   \n",
       "46   Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA / SIMAM)   \n",
       "47             Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)   \n",
       "48                                          Biotecnologia-GR2 (VIGILÂNCIA GENÔMICA)   \n",
       "49                                           Biotecnologia-GR1 (IMUNOPARASITOLOGIA)   \n",
       "50                  Coordenação da Gestão e Desenvolvimento Institucional (COMPRAS)   \n",
       "51                                           Biotecnologia-GR1 (IMUNOPARASITOLOGIA)   \n",
       "52                                                                 Saúde da Família   \n",
       "53             Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)   \n",
       "54                 Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)   \n",
       "55                                                                    Biotecnologia   \n",
       "56                  Coordenação de Educação, Informação e Comunicação (COORDENAÇÃO)   \n",
       "57                                                                Coordenação Geral   \n",
       "58                                                Biotecnologia-GR3 (BIOTECNOLOGIA)   \n",
       "59           Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)   \n",
       "60                      Coordenação da Gestão e Desenvolvimento Institucional (TIC)   \n",
       "61                      Coordenação da Gestão e Desenvolvimento Institucional (TIC)   \n",
       "62                      Coordenação da Gestão e Desenvolvimento Institucional (TIC)   \n",
       "63                      Coordenação da Gestão e Desenvolvimento Institucional (TIC)   \n",
       "64                                         Coordenação Geral (SECRETARIA EXECUTIVA)   \n",
       "65         Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)   \n",
       "66                  Coordenação da Gestão e Desenvolvimento Institucional (COMPRAS)   \n",
       "67                  Coordenação da Gestão e Desenvolvimento Institucional (COMPRAS)   \n",
       "68                  Coordenação de Educação, Informação e Comunicação (COMUNICAÇÃO)   \n",
       "69             Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)   \n",
       "70         Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)   \n",
       "71           Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)   \n",
       "72           Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)   \n",
       "73             Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)   \n",
       "74           Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)   \n",
       "75           Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)   \n",
       "76         Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)   \n",
       "77                                                                   Bio-Manguinhos   \n",
       "78                                                                   Bio-Manguinhos   \n",
       "79                  Coordenação de Educação, Informação e Comunicação (COMUNICAÇÃO)   \n",
       "80             Coordenação da Gestão e Desenvolvimento Institucional (PLANEJAMENTO)   \n",
       "81               Coordenação da Gestão e Desenvolvimento Institucional (PATRIMÔNIO)   \n",
       "82               Coordenação da Gestão e Desenvolvimento Institucional (PATRIMÔNIO)   \n",
       "83                 Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)   \n",
       "84                   Coordenação de Educação, Informação e Comunicação (BIBLIOTECA)   \n",
       "85                 Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)   \n",
       "86               Coordenação da Gestão e Desenvolvimento Institucional (PATRIMÔNIO)   \n",
       "87                                   Coordenação de Pesquisa e Coleções Biológicas    \n",
       "88                Coordenação da Gestão e Desenvolvimento Institucional (LOGÍSTICA)   \n",
       "89           Coordenação da Gestão e Desenvolvimento Institucional   (ALMOXARIFADO)   \n",
       "90               Coordenação da Gestão e Desenvolvimento Institucional (PATRIMÔNIO)   \n",
       "91                 Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)   \n",
       "92                 Coordenação da Gestão e Desenvolvimento Institucional (SGP / ST)   \n",
       "93                           Coordenação da Gestão e Desenvolvimento Institucional    \n",
       "94           Coordenação da Gestão e Desenvolvimento Institucional (INFRAESTRUTURA)   \n",
       "95                                                    Coordenação Geral (QUALIDADE)   \n",
       "96                                                Biotecnologia-GR3 (BIOTECNOLOGIA)   \n",
       "97                                                    Coordenação Geral (QUALIDADE)   \n",
       "98         Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)   \n",
       "99                                         Coordenação Geral (SECRETARIA EXECUTIVA)   \n",
       "100        Coordenação de Educação, Informação e Comunicação (SECRETARIA ACADÊMICA)   \n",
       "101              Coordenação da Gestão e Desenvolvimento Institucional (FINANCEIRO)   \n",
       "102                                              Coordenação Geral ( EPSJV/FIOCRUZ)   \n",
       "103                                  Coordenação de Pesquisa e Coleções Biológicas    \n",
       "104                                                                Saúde e Ambiente   \n",
       "105                                  Coordenação de Pesquisa e Coleções Biológicas    \n",
       "106                                                         Coordenação de Pesquisa   \n",
       "107                                  Coordenação de Pesquisa e Coleções Biológicas    \n",
       "108                                  Coordenação de Pesquisa e Coleções Biológicas    \n",
       "109                                  Coordenação de Pesquisa e Coleções Biológicas    \n",
       "110                                                                   Saúde Digital   \n",
       "111                                                                             NaN   \n",
       "112                                                                             NaN   \n",
       "113                                                                             NaN   \n",
       "114                                                                             NaN   \n",
       "115                                                                             NaN   \n",
       "116                                                                             NaN   \n",
       "117                                                                             NaN   \n",
       "118                                                                             NaN   \n",
       "119                                                                             NaN   \n",
       "120                                                                             NaN   \n",
       "121                                                                             NaN   \n",
       "122                                                                             NaN   \n",
       "123                                                                             NaN   \n",
       "124                                                                             NaN   \n",
       "125                                                                             NaN   \n",
       "126                                                                             NaN   \n",
       "127                                                                             NaN   \n",
       "128                                                                             NaN   \n",
       "129                                                                             NaN   \n",
       "130                                                                             NaN   \n",
       "131                                                                             NaN   \n",
       "132                                                                             NaN   \n",
       "133                                                                             NaN   \n",
       "134                                                                             NaN   \n",
       "135                                                                             NaN   \n",
       "136                                                                             NaN   \n",
       "137                                                                             NaN   \n",
       "138                                                                             NaN   \n",
       "139                                                                             NaN   \n",
       "140                                                                             NaN   \n",
       "141                                                                             NaN   \n",
       "142                                                                             NaN   \n",
       "143                                                                             NaN   \n",
       "144                                                                             NaN   \n",
       "145                                                                             NaN   \n",
       "146                                                                             NaN   \n",
       "147                                                                             NaN   \n",
       "148                                                                             NaN   \n",
       "149                                                                             NaN   \n",
       "150                                                                             NaN   \n",
       "151                                                                             NaN   \n",
       "152                                                                             NaN   \n",
       "153                                                                             NaN   \n",
       "154                                                                             NaN   \n",
       "155                                                                             NaN   \n",
       "156                                                                             NaN   \n",
       "157                                                                             NaN   \n",
       "158                                                                             NaN   \n",
       "159                                                                             NaN   \n",
       "160                                                                             NaN   \n",
       "161                                                                             NaN   \n",
       "162                                                                             NaN   \n",
       "163                                                                             NaN   \n",
       "164                                                                             NaN   \n",
       "165                                                                             NaN   \n",
       "166                                                                             NaN   \n",
       "167                                                                             NaN   \n",
       "168                                                                             NaN   \n",
       "169                                                                             NaN   \n",
       "170                                                                             NaN   \n",
       "171                                                                             NaN   \n",
       "172                                                                             NaN   \n",
       "173                                                                             NaN   \n",
       "174                                                                             NaN   \n",
       "175                                                                             NaN   \n",
       "176                                                                             NaN   \n",
       "177                                                                             NaN   \n",
       "178                                                                             NaN   \n",
       "179                                                                             NaN   \n",
       "180                                                                             NaN   \n",
       "181                                                                             NaN   \n",
       "182                                                                             NaN   \n",
       "183                                                                             NaN   \n",
       "184                                                                             NaN   \n",
       "185                                                                             NaN   \n",
       "186                                                                             NaN   \n",
       "187                                                                             NaN   \n",
       "188                                                                             NaN   \n",
       "189                                                                             NaN   \n",
       "190                                                                             NaN   \n",
       "191                                                                             NaN   \n",
       "192                                                                             NaN   \n",
       "193                                                                             NaN   \n",
       "194                                                                             NaN   \n",
       "195                                                                             NaN   \n",
       "196                                                                             NaN   \n",
       "197                                                                             NaN   \n",
       "198                                                                             NaN   \n",
       "199                                                                             NaN   \n",
       "200                                                                             NaN   \n",
       "201                                                                             NaN   \n",
       "202                                                                             NaN   \n",
       "203                                                                             NaN   \n",
       "204                                                                             NaN   \n",
       "205                                                                             NaN   \n",
       "206                                                                             NaN   \n",
       "207                                                                             NaN   \n",
       "208                                                                             NaN   \n",
       "209                                                                             NaN   \n",
       "210                                                                             NaN   \n",
       "211                                                                             NaN   \n",
       "212                                                                             NaN   \n",
       "213                                                                             NaN   \n",
       "214                                                                             NaN   \n",
       "215                                                                             NaN   \n",
       "216                                                                             NaN   \n",
       "217                                                                             NaN   \n",
       "218                                                                             NaN   \n",
       "219                                                                             NaN   \n",
       "220                                                                             NaN   \n",
       "221                                                                             NaN   \n",
       "222                                                                             NaN   \n",
       "223                                                                             NaN   \n",
       "224                                                                             NaN   \n",
       "225                                                                             NaN   \n",
       "226                                                                             NaN   \n",
       "227                                                                             NaN   \n",
       "228                                                                             NaN   \n",
       "229                                                                             NaN   \n",
       "230                                                                             NaN   \n",
       "231                                                                             NaN   \n",
       "232                                                                             NaN   \n",
       "233                                                                             NaN   \n",
       "234                                                                             NaN   \n",
       "235                                                                             NaN   \n",
       "236                                                                             NaN   \n",
       "237                                                                             NaN   \n",
       "238                                                                             NaN   \n",
       "239                                                                             NaN   \n",
       "240                                                                             NaN   \n",
       "241                                                                             NaN   \n",
       "242                                                                             NaN   \n",
       "243                                                                             NaN   \n",
       "244                                                                             NaN   \n",
       "245                                                                             NaN   \n",
       "246                                                                             NaN   \n",
       "247                                                                             NaN   \n",
       "248                                                                             NaN   \n",
       "249                                                                             NaN   \n",
       "250                                                                             NaN   \n",
       "251                                                                             NaN   \n",
       "252                                                                             NaN   \n",
       "253                                                                             NaN   \n",
       "254                                                                             NaN   \n",
       "255                                                                             NaN   \n",
       "256                                                                             NaN   \n",
       "257                                                                             NaN   \n",
       "258                                                                             NaN   \n",
       "259                                                                             NaN   \n",
       "260                                                                             NaN   \n",
       "261                                                                             NaN   \n",
       "262                                                                             NaN   \n",
       "263                                                                             NaN   \n",
       "264                                                                             NaN   \n",
       "265                                                                             NaN   \n",
       "266                                                                             NaN   \n",
       "267                                                                             NaN   \n",
       "268                                                                             NaN   \n",
       "269                                                                             NaN   \n",
       "270                                                                             NaN   \n",
       "271                                                                             NaN   \n",
       "272                                                                             NaN   \n",
       "273                                                                             NaN   \n",
       "274                                                                             NaN   \n",
       "275                                                                             NaN   \n",
       "276                                                                             NaN   \n",
       "277                                                                             NaN   \n",
       "278                                                                             NaN   \n",
       "279                                                                             NaN   \n",
       "280                                                               Coordenação Geral   \n",
       "281                                                               Coordenação Geral   \n",
       "282                                                               Coordenação Geral   \n",
       "283                                                               Coordenação Geral   \n",
       "\n",
       "    CARGO                                            \n",
       "0                    Tecnologista em Saúde Pública  \\\n",
       "1                     Pesquisador em Saúde Pública   \n",
       "2     Técnico em Pesquisa e Investigação Biomédica   \n",
       "3                                    Enfermeira(o)   \n",
       "4                    Tecnologista em Saúde Pública   \n",
       "5                     Pesquisador em Saúde Pública   \n",
       "6                     Pesquisador em Saúde Pública   \n",
       "7                      Analista de Gestão em Saúde   \n",
       "8    Especialista em C&T Prod. Inov. Saúde Pública   \n",
       "9                      Analista de Gestão em Saúde   \n",
       "10                    Pesquisador em Saúde Pública   \n",
       "11                        Técnico em Saúde Pública   \n",
       "12                        Técnico em Saúde Pública   \n",
       "13                        Técnico em Saúde Pública   \n",
       "14                     Analista de Gestão em Saúde   \n",
       "15                    Pesquisador em Saúde Pública   \n",
       "16                   Tecnologista em Saúde Pública   \n",
       "17                    Pesquisador em Saúde Pública   \n",
       "18                    Pesquisador em Saúde Pública   \n",
       "19                     Analista de Gestão em Saúde   \n",
       "20   Especialista em C&T Prod. Inov. Saúde Pública   \n",
       "21                    Pesquisador em Saúde Pública   \n",
       "22                    Pesquisador em Saúde Pública   \n",
       "23                   Tecnologista em Saúde Pública   \n",
       "24                   Tecnologista em Saúde Pública   \n",
       "25                    Pesquisador em Saúde Pública   \n",
       "26   Especialista em C&T Prod. Inov. Saúde Pública   \n",
       "27                   Tecnologista em Saúde Pública   \n",
       "28                    Pesquisador em Saúde Pública   \n",
       "29           Assistente Tecnico de Gestão em Saúde   \n",
       "30                    Pesquisador em Saúde Pública   \n",
       "31                    Pesquisador em Saúde Pública   \n",
       "32                   Tecnologista em Saúde Pública   \n",
       "33                     Analista de Gestão em Saúde   \n",
       "34                     Analista de Gestão em Saúde   \n",
       "35                                   Enfermeira(o)   \n",
       "36                   Tecnologista em Saúde Pública   \n",
       "37                     Analista de Gestão em Saúde   \n",
       "38   Especialista em C&T Prod. Inov. Saúde Pública   \n",
       "39                   Tecnologista em Saúde Pública   \n",
       "40                        Técnico em Saúde Pública   \n",
       "41   Especialista em C&T Prod. Inov. Saúde Pública   \n",
       "42                    Pesquisador em Saúde Pública   \n",
       "43                   Tecnologista em Saúde Pública   \n",
       "44                   Tecnologista em Saúde Pública   \n",
       "45                    Pesquisador em Saúde Pública   \n",
       "46           Assistente Tecnico de Gestão em Saúde   \n",
       "47                     Analista de Gestão em Saúde   \n",
       "48                    Pesquisador em Saúde Pública   \n",
       "49                    Pesquisador em Saúde Pública   \n",
       "50           Assistente Tecnico de Gestão em Saúde   \n",
       "51                    Pesquisador em Saúde Pública   \n",
       "52                    Pesquisador em Saúde Pública   \n",
       "53                     Analista de Gestão em Saúde   \n",
       "54                     Analista de Gestão em Saúde   \n",
       "55                    Pesquisador em Saúde Pública   \n",
       "56                    Pesquisador em Saúde Pública   \n",
       "57                    Pesquisador em Saúde Pública   \n",
       "58                        Técnico em Saúde Pública   \n",
       "59                 Técnico de Manutenção Eletrica    \n",
       "60                                             NaN   \n",
       "61                                             NaN   \n",
       "62                                             NaN   \n",
       "63                                             NaN   \n",
       "64                       Assistente Administrativo   \n",
       "65                  Assistente de Gestão Pleno III   \n",
       "66                     Analista de Gestão Junior I   \n",
       "67                              Apoio Logística II   \n",
       "68                                             NaN   \n",
       "69                              Apoio Logística II   \n",
       "70                               Apoio Logística I   \n",
       "71                         Engenheiro Civil Junior   \n",
       "72                 Técnico de Manutenção Eletrica    \n",
       "73                                             NaN   \n",
       "74                          Engenheira Eletricista   \n",
       "75                         Técnico em Equipamentos   \n",
       "76                       Assistente Administrativo   \n",
       "77                                             NaN   \n",
       "78                                             NaN   \n",
       "79                                    Jornalista I   \n",
       "80                              Apoio Logistico II   \n",
       "81                    Assistente de Gestão Senior    \n",
       "82                    Assistente de Gestão Senior    \n",
       "83                                             NaN   \n",
       "84                                             NaN   \n",
       "85                                             NaN   \n",
       "86                                             NaN   \n",
       "87                                             NaN   \n",
       "88                                             NaN   \n",
       "89                                             NaN   \n",
       "90                                             NaN   \n",
       "91                                             NaN   \n",
       "92                                             NaN   \n",
       "93                                             NaN   \n",
       "94                                             NaN   \n",
       "95                                             NaN   \n",
       "96                                             NaN   \n",
       "97                                             NaN   \n",
       "98                                             NaN   \n",
       "99                                             NaN   \n",
       "100                                            NaN   \n",
       "101                                            NaN   \n",
       "102                                            NaN   \n",
       "103                                            NaN   \n",
       "104                                            NaN   \n",
       "105                                            NaN   \n",
       "106                                            NaN   \n",
       "107                                            NaN   \n",
       "108                                            NaN   \n",
       "109                                            NaN   \n",
       "110                                            NaN   \n",
       "111                                            NaN   \n",
       "112                                            NaN   \n",
       "113                                            NaN   \n",
       "114                                            NaN   \n",
       "115                                            NaN   \n",
       "116                                            NaN   \n",
       "117                                            NaN   \n",
       "118                                            NaN   \n",
       "119                                            NaN   \n",
       "120                                            NaN   \n",
       "121                                            NaN   \n",
       "122                                            NaN   \n",
       "123                                            NaN   \n",
       "124                                            NaN   \n",
       "125                                            NaN   \n",
       "126                                            NaN   \n",
       "127                                            NaN   \n",
       "128                                            NaN   \n",
       "129                                            NaN   \n",
       "130                                            NaN   \n",
       "131                                            NaN   \n",
       "132                                            NaN   \n",
       "133                                            NaN   \n",
       "134                                            NaN   \n",
       "135                                            NaN   \n",
       "136                                            NaN   \n",
       "137                                            NaN   \n",
       "138                                            NaN   \n",
       "139                                            NaN   \n",
       "140                                            NaN   \n",
       "141                                            NaN   \n",
       "142                                            NaN   \n",
       "143                                            NaN   \n",
       "144                                            NaN   \n",
       "145                                            NaN   \n",
       "146                                            NaN   \n",
       "147                                            NaN   \n",
       "148                                            NaN   \n",
       "149                                            NaN   \n",
       "150                                            NaN   \n",
       "151                                            NaN   \n",
       "152                                            NaN   \n",
       "153                                            NaN   \n",
       "154                                            NaN   \n",
       "155                                            NaN   \n",
       "156                                            NaN   \n",
       "157                                            NaN   \n",
       "158                                            NaN   \n",
       "159                                            NaN   \n",
       "160                                            NaN   \n",
       "161                                            NaN   \n",
       "162                                            NaN   \n",
       "163                                            NaN   \n",
       "164                                            NaN   \n",
       "165                                            NaN   \n",
       "166                                            NaN   \n",
       "167                                            NaN   \n",
       "168                                            NaN   \n",
       "169                                            NaN   \n",
       "170                                            NaN   \n",
       "171                                            NaN   \n",
       "172                                            NaN   \n",
       "173                                            NaN   \n",
       "174                                            NaN   \n",
       "175                                            NaN   \n",
       "176                                            NaN   \n",
       "177                                            NaN   \n",
       "178                                            NaN   \n",
       "179                                            NaN   \n",
       "180                                            NaN   \n",
       "181                                            NaN   \n",
       "182                                            NaN   \n",
       "183                                            NaN   \n",
       "184                                            NaN   \n",
       "185                                            NaN   \n",
       "186                                            NaN   \n",
       "187                                            NaN   \n",
       "188                                            NaN   \n",
       "189                                            NaN   \n",
       "190                                            NaN   \n",
       "191                                            NaN   \n",
       "192                                            NaN   \n",
       "193                                            NaN   \n",
       "194                                            NaN   \n",
       "195                                            NaN   \n",
       "196                                            NaN   \n",
       "197                                            NaN   \n",
       "198                                            NaN   \n",
       "199                                            NaN   \n",
       "200                                            NaN   \n",
       "201                                            NaN   \n",
       "202                                            NaN   \n",
       "203                                            NaN   \n",
       "204                                            NaN   \n",
       "205                                            NaN   \n",
       "206                                            NaN   \n",
       "207                                            NaN   \n",
       "208                                            NaN   \n",
       "209                                            NaN   \n",
       "210                                            NaN   \n",
       "211                                            NaN   \n",
       "212                                            NaN   \n",
       "213                                            NaN   \n",
       "214                                            NaN   \n",
       "215                                            NaN   \n",
       "216                                            NaN   \n",
       "217                                            NaN   \n",
       "218                                            NaN   \n",
       "219                                            NaN   \n",
       "220                                            NaN   \n",
       "221                                            NaN   \n",
       "222                                            NaN   \n",
       "223                                            NaN   \n",
       "224                                            NaN   \n",
       "225                                            NaN   \n",
       "226                                            NaN   \n",
       "227                                            NaN   \n",
       "228                                            NaN   \n",
       "229                                            NaN   \n",
       "230                                            NaN   \n",
       "231                                            NaN   \n",
       "232                                            NaN   \n",
       "233                                            NaN   \n",
       "234                                            NaN   \n",
       "235                                            NaN   \n",
       "236                                            NaN   \n",
       "237                                            NaN   \n",
       "238                                            NaN   \n",
       "239                                            NaN   \n",
       "240                                            NaN   \n",
       "241                                            NaN   \n",
       "242                                            NaN   \n",
       "243                                            NaN   \n",
       "244                                            NaN   \n",
       "245                                            NaN   \n",
       "246                                            NaN   \n",
       "247                                            NaN   \n",
       "248                                            NaN   \n",
       "249                                            NaN   \n",
       "250                                            NaN   \n",
       "251                                            NaN   \n",
       "252                                            NaN   \n",
       "253                                            NaN   \n",
       "254                                            NaN   \n",
       "255                                            NaN   \n",
       "256                                            NaN   \n",
       "257                                            NaN   \n",
       "258                                            NaN   \n",
       "259                                            NaN   \n",
       "260                                            NaN   \n",
       "261                                            NaN   \n",
       "262                                            NaN   \n",
       "263                                            NaN   \n",
       "264                                            NaN   \n",
       "265                                            NaN   \n",
       "266                                            NaN   \n",
       "267                                            NaN   \n",
       "268                                            NaN   \n",
       "269                                            NaN   \n",
       "270                                            NaN   \n",
       "271                                            NaN   \n",
       "272                                            NaN   \n",
       "273                                            NaN   \n",
       "274                                            NaN   \n",
       "275                                            NaN   \n",
       "276                                            NaN   \n",
       "277                                            NaN   \n",
       "278                                            NaN   \n",
       "279                                            NaN   \n",
       "280          Assistente Tecnico de Gestão em Saúde   \n",
       "281          Assistente Tecnico de Gestão em Saúde   \n",
       "282                   Pesquisador em Saúde Pública   \n",
       "283                    Analista de Gestão em Saúde   \n",
       "\n",
       "    VÍNCULO                                 INGRESSO_FIOCE   \n",
       "0                                  SERVIDOR 2022-01-03      \\\n",
       "1                                  SERVIDOR 2015-08-17       \n",
       "2                                  SERVIDOR 2019-08-26       \n",
       "3                                  SERVIDOR 2017-06-05       \n",
       "4                                  SERVIDOR 2021-07-01       \n",
       "5                                  SERVIDOR 2018-07-06       \n",
       "6                          COORENAÇÃO GERAL 2005-06-30       \n",
       "7                                  SERVIDOR 2011-11-07       \n",
       "8                                  SERVIDOR 2010-11-05       \n",
       "9                                  SERVIDOR 2018-07-08       \n",
       "10                                 SERVIDOR 2018-06-29       \n",
       "11                                 SERVIDOR 2019-04-22       \n",
       "12                                 SERVIDOR 2022-06-30       \n",
       "13                                 SERVIDOR 2020-09-23       \n",
       "14                                 SERVIDOR 2021-07-11       \n",
       "15                                 SERVIDOR 2019-04-01       \n",
       "16                                 SERVIDOR 2023-07-25       \n",
       "17                                 SERVIDOR 2016-08-08       \n",
       "18                                 SERVIDOR 2020-08-04       \n",
       "19                                 SERVIDOR 2012-01-03       \n",
       "20                                 SERVIDOR 2018-01-12       \n",
       "21                                 SERVIDOR 2021-01-05       \n",
       "22                                 SERVIDOR 2014-12-02       \n",
       "23                                 SERVIDOR 2018-06-01       \n",
       "24                                 SERVIDOR 2021-08-05       \n",
       "25                                 SERVIDOR 2015-01-06       \n",
       "26                                 SERVIDOR 2014-12-18       \n",
       "27                                 SERVIDOR 2017-09-25       \n",
       "28                                 SERVIDOR 2022-06-20       \n",
       "29                                 SERVIDOR 2021-09-20       \n",
       "30                                 SERVIDOR 2012-12-13       \n",
       "31                                 SERVIDOR 2006-11-09       \n",
       "32                                 SERVIDOR 2020-05-13       \n",
       "33                                 SERVIDOR 2022-03-14       \n",
       "34                                 SERVIDOR 2015-12-11       \n",
       "35                                 SERVIDOR 2021-10-06       \n",
       "36                                 SERVIDOR 2019-09-29       \n",
       "37                                 SERVIDOR 2009-01-20       \n",
       "38                                 SERVIDOR 2012-09-03       \n",
       "39                                 SERVIDOR 2013-01-07       \n",
       "40                                 SERVIDOR 2021-05-05       \n",
       "41                                 SERVIDOR 2012-09-14       \n",
       "42                                 SERVIDOR 2019-04-26       \n",
       "43                                 SERVIDOR 2017-09-01       \n",
       "44                                 SERVIDOR 2015-02-27       \n",
       "45                                 SERVIDOR 2017-07-03       \n",
       "46                                 SERVIDOR 2021-09-01       \n",
       "47                                 SERVIDOR 2022-11-01       \n",
       "48                                 SERVIDOR 2014-11-25       \n",
       "49                                 SERVIDOR 2019-04-01       \n",
       "50                                 SERVIDOR 2020-08-17       \n",
       "51                                 SERVIDOR 2012-12-19       \n",
       "52                                 SERVIDOR 2014-11-24       \n",
       "53                                 SERVIDOR 2014-08-25       \n",
       "54                                 SERVIDOR 2021-09-21       \n",
       "55                                 SERVIDOR 2019-06-04       \n",
       "56                                 SERVIDOR 2014-11-14       \n",
       "57                                 SERVIDOR 2013-01-15       \n",
       "58                                 SERVIDOR 2019-04-22       \n",
       "59                             TERCEIRIZADO 2018-03-01       \n",
       "60                             TERCEIRIZADO 2018-04-27       \n",
       "61                             TERCEIRIZADO 2021-07-07       \n",
       "62                             TERCEIRIZADO 2021-06-14       \n",
       "63                             TERCEIRIZADO 2022-01-17       \n",
       "64                             TERCEIRIZADO 2019-05-23       \n",
       "65                             TERCEIRIZADO 2012-07-05       \n",
       "66                             TERCEIRIZADO 2010-05-19       \n",
       "67                             TERCEIRIZADO 2020-10-19       \n",
       "68                             TERCEIRIZADO 2019-09-05       \n",
       "69                             TERCEIRIZADO 2019-09-16       \n",
       "70                             TERCEIRIZADO 2019-10-14       \n",
       "71                             TERCEIRIZADO 2020-10-13       \n",
       "72                             TERCEIRIZADO 2020-08-20       \n",
       "73                             TERCEIRIZADO 2020-09-16       \n",
       "74                             TERCEIRIZADO 2020-08-04       \n",
       "75                             TERCEIRIZADO 2021-08-12       \n",
       "76                             TERCEIRIZADO 2019-10-21       \n",
       "77                             TERCEIRIZADO 2019-04-01       \n",
       "78                             TERCEIRIZADO 2022-01-10       \n",
       "79                             TERCEIRIZADO 2022-09-19       \n",
       "80                             TERCEIRIZADO 2023-06-02       \n",
       "81                             TERCEIRIZADO 2021-07-19       \n",
       "82                             TERCEIRIZADO 2020-09-08       \n",
       "83                                 BOLSISTA 2022-02-01       \n",
       "84                                 BOLSISTA 2022-02-01       \n",
       "85                                 BOLSISTA 2021-10-20       \n",
       "86                                 BOLSISTA 2022-02-07       \n",
       "87                                 BOLSISTA 2021-08-09       \n",
       "88                                 BOLSISTA 2020-12-01       \n",
       "89                                 BOLSISTA 2021-08-20       \n",
       "90                                 BOLSISTA 2020-12-01       \n",
       "91                                 BOLSISTA 2020-12-01       \n",
       "92                                 BOLSISTA 2022-02-01       \n",
       "93                                 BOLSISTA 2021-10-04       \n",
       "94                                 BOLSISTA 2021-07-15       \n",
       "95                                 BOLSISTA 2022-01-10       \n",
       "96                                 BOLSISTA 2021-05-31       \n",
       "97                                 BOLSISTA 2021-05-31       \n",
       "98                                 BOLSISTA 2021-12-01       \n",
       "99                                 BOLSISTA 2022-05-25       \n",
       "100                                BOLSISTA 2022-08-04       \n",
       "101                                BOLSISTA 2022-10-14       \n",
       "102                                BOLSISTA 2022-11-07       \n",
       "103                                BOLSISTA 2021-05-31       \n",
       "104                                BOLSISTA 2021-06-01       \n",
       "105                                BOLSISTA 2021-05-27       \n",
       "106                                BOLSISTA 2021-05-31       \n",
       "107                                BOLSISTA 2022-09-28       \n",
       "108                                BOLSISTA 2023-07-05       \n",
       "109                             ESTÁGIO PEC 2021-08-15       \n",
       "110                             ESTÁGIO PEC 2022-11-01       \n",
       "111                                  UNADIG        NaT       \n",
       "112                                  UNADIG        NaT       \n",
       "113                                  UNADIG        NaT       \n",
       "114                                  UNADIG        NaT       \n",
       "115                                  UNADIG        NaT       \n",
       "116                                  UNADIG        NaT       \n",
       "117                                  UNADIG        NaT       \n",
       "118                                  UNADIG        NaT       \n",
       "119                                  UNADIG        NaT       \n",
       "120                                  UNADIG        NaT       \n",
       "121                                  UNADIG        NaT       \n",
       "122                                  UNADIG        NaT       \n",
       "123                                  UNADIG        NaT       \n",
       "124                                  UNADIG        NaT       \n",
       "125                                  UNADIG        NaT       \n",
       "126                                  UNADIG        NaT       \n",
       "127                                  UNADIG        NaT       \n",
       "128                                  UNADIG        NaT       \n",
       "129                                  UNADIG        NaT       \n",
       "130                                  UNADIG        NaT       \n",
       "131                                  UNADIG        NaT       \n",
       "132                                  UNADIG        NaT       \n",
       "133                                  UNADIG        NaT       \n",
       "134                                  UNADIG        NaT       \n",
       "135                                  UNADIG        NaT       \n",
       "136                                  UNADIG        NaT       \n",
       "137                                  UNADIG        NaT       \n",
       "138                                  UNADIG        NaT       \n",
       "139                                  UNADIG        NaT       \n",
       "140                                NORMATEL        NaT       \n",
       "141                                NORMATEL        NaT       \n",
       "142                                NORMATEL        NaT       \n",
       "143                                NORMATEL        NaT       \n",
       "144                                NORMATEL        NaT       \n",
       "145                                NORMATEL        NaT       \n",
       "146                                NORMATEL        NaT       \n",
       "147                                NORMATEL        NaT       \n",
       "148                                NORMATEL        NaT       \n",
       "149                                NORMATEL        NaT       \n",
       "150                                NORMATEL        NaT       \n",
       "151                                NORMATEL        NaT       \n",
       "152                                NORMATEL        NaT       \n",
       "153                                NORMATEL        NaT       \n",
       "154                                NORMATEL        NaT       \n",
       "155                                NORMATEL        NaT       \n",
       "156                                NORMATEL        NaT       \n",
       "157                                NORMATEL        NaT       \n",
       "158                                NORMATEL        NaT       \n",
       "159                                NORMATEL        NaT       \n",
       "160                                NORMATEL        NaT       \n",
       "161                                NORMATEL        NaT       \n",
       "162                                NORMATEL        NaT       \n",
       "163                                NORMATEL        NaT       \n",
       "164                                NORMATEL        NaT       \n",
       "165                                NORMATEL        NaT       \n",
       "166                                NORMATEL        NaT       \n",
       "167                                NORMATEL        NaT       \n",
       "168                                NORMATEL        NaT       \n",
       "169                                NORMATEL        NaT       \n",
       "170                                NORMATEL        NaT       \n",
       "171                                NORMATEL        NaT       \n",
       "172                                NORMATEL        NaT       \n",
       "173                                NORMATEL        NaT       \n",
       "174                                NORMATEL        NaT       \n",
       "175                                NORMATEL        NaT       \n",
       "176                                NORMATEL        NaT       \n",
       "177                                NORMATEL        NaT       \n",
       "178                                NORMATEL        NaT       \n",
       "179                                NORMATEL        NaT       \n",
       "180                                NORMATEL        NaT       \n",
       "181                                NORMATEL        NaT       \n",
       "182                                NORMATEL        NaT       \n",
       "183                                NORMATEL        NaT       \n",
       "184                                NORMATEL        NaT       \n",
       "185                                NORMATEL        NaT       \n",
       "186                                NORMATEL        NaT       \n",
       "187                                NORMATEL        NaT       \n",
       "188                                NORMATEL        NaT       \n",
       "189                                NORMATEL        NaT       \n",
       "190                                NORMATEL        NaT       \n",
       "191                                NORMATEL        NaT       \n",
       "192                                NORMATEL        NaT       \n",
       "193                                NORMATEL        NaT       \n",
       "194                                NORMATEL        NaT       \n",
       "195                                NORMATEL        NaT       \n",
       "196                                NORMATEL        NaT       \n",
       "197                                NORMATEL        NaT       \n",
       "198                                NORMATEL        NaT       \n",
       "199                                NORMATEL        NaT       \n",
       "200                                NORMATEL        NaT       \n",
       "201                                NORMATEL        NaT       \n",
       "202                                NORMATEL        NaT       \n",
       "203                                NORMATEL        NaT       \n",
       "204                                NORMATEL        NaT       \n",
       "205                                NORMATEL        NaT       \n",
       "206                                NORMATEL        NaT       \n",
       "207                                NORMATEL        NaT       \n",
       "208                                NORMATEL        NaT       \n",
       "209                                NORMATEL        NaT       \n",
       "210                                NORMATEL        NaT       \n",
       "211                                NORMATEL        NaT       \n",
       "212                                NORMATEL        NaT       \n",
       "213                                NORMATEL        NaT       \n",
       "214                                NORMATEL        NaT       \n",
       "215                                NORMATEL        NaT       \n",
       "216                                NORMATEL        NaT       \n",
       "217                                NORMATEL        NaT       \n",
       "218                                NORMATEL        NaT       \n",
       "219                                NORMATEL        NaT       \n",
       "220                                NORMATEL        NaT       \n",
       "221                                NORMATEL        NaT       \n",
       "222                                NORMATEL        NaT       \n",
       "223                                NORMATEL        NaT       \n",
       "224                                NORMATEL        NaT       \n",
       "225                                NORMATEL        NaT       \n",
       "226                                NORMATEL        NaT       \n",
       "227                                NORMATEL        NaT       \n",
       "228                                NORMATEL        NaT       \n",
       "229                                NORMATEL        NaT       \n",
       "230                                NORMATEL        NaT       \n",
       "231                                NORMATEL        NaT       \n",
       "232                                NORMATEL        NaT       \n",
       "233                                NORMATEL        NaT       \n",
       "234                                NORMATEL        NaT       \n",
       "235                                NORMATEL        NaT       \n",
       "236                                NORMATEL        NaT       \n",
       "237                                NORMATEL        NaT       \n",
       "238                                NORMATEL        NaT       \n",
       "239                                NORMATEL        NaT       \n",
       "240                                NORMATEL        NaT       \n",
       "241                                NORMATEL        NaT       \n",
       "242                                NORMATEL        NaT       \n",
       "243                                NORMATEL        NaT       \n",
       "244                                NORMATEL        NaT       \n",
       "245                                NORMATEL        NaT       \n",
       "246                                NORMATEL        NaT       \n",
       "247                                NORMATEL        NaT       \n",
       "248                                NORMATEL        NaT       \n",
       "249                                NORMATEL        NaT       \n",
       "250                                NORMATEL        NaT       \n",
       "251                                NORMATEL        NaT       \n",
       "252                                NORMATEL        NaT       \n",
       "253                                NORMATEL        NaT       \n",
       "254                                NORMATEL        NaT       \n",
       "255                                NORMATEL        NaT       \n",
       "256                                NORMATEL        NaT       \n",
       "257                                NORMATEL        NaT       \n",
       "258                                NORMATEL        NaT       \n",
       "259                                NORMATEL        NaT       \n",
       "260                                NORMATEL        NaT       \n",
       "261                                NORMATEL        NaT       \n",
       "262                                NORMATEL        NaT       \n",
       "263                                NORMATEL        NaT       \n",
       "264                                NORMATEL        NaT       \n",
       "265                                NORMATEL        NaT       \n",
       "266                                NORMATEL        NaT       \n",
       "267                                NORMATEL        NaT       \n",
       "268                                NORMATEL        NaT       \n",
       "269                                NORMATEL        NaT       \n",
       "270                                NORMATEL        NaT       \n",
       "271                                NORMATEL        NaT       \n",
       "272                                NORMATEL        NaT       \n",
       "273                                NORMATEL        NaT       \n",
       "274                                NORMATEL        NaT       \n",
       "275                                NORMATEL        NaT       \n",
       "276                                NORMATEL        NaT       \n",
       "277                                NORMATEL        NaT       \n",
       "278                                NORMATEL        NaT       \n",
       "279                                NORMATEL        NaT       \n",
       "280                                SERVIDOR 2009-06-22       \n",
       "281      SERVIDOR-CEDIDA PARA CORREGEDORIA  2011-02-02       \n",
       "282         SERVIDOR-CEDIDA PARA FIOCRUZ PE 2015-07-27       \n",
       "283  SERVIDOR-CEDIDO PARA AUDITORIA INTERNA 2012-09-14       \n",
       "\n",
       "    NÍVEL                            \n",
       "0                          MESTRADO  \n",
       "1                         DOUTORADO  \n",
       "2                          MESTRADO  \n",
       "3    ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "4                         DOUTORADO  \n",
       "5                          MESTRADO  \n",
       "6                         DOUTORADO  \n",
       "7                          MESTRADO  \n",
       "8                         DOUTORADO  \n",
       "9                          MESTRADO  \n",
       "10                        DOUTORADO  \n",
       "11   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "12   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "13   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "14                         MESTRADO  \n",
       "15                        DOUTORADO  \n",
       "16                             PHD   \n",
       "17                        DOUTORADO  \n",
       "18                        DOUTORADO  \n",
       "19   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "20                        DOUTORADO  \n",
       "21                        DOUTORADO  \n",
       "22                        DOUTORADO  \n",
       "23                        DOUTORADO  \n",
       "24                        DOUTORADO  \n",
       "25                        DOUTORADO  \n",
       "26                        DOUTORADO  \n",
       "27   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "28                        DOUTORADO  \n",
       "29                     ENSINO MÉDIO  \n",
       "30                        DOUTORADO  \n",
       "31                        DOUTORADO  \n",
       "32                         MESTRADO  \n",
       "33                        DOUTORADO  \n",
       "34                         MESTRADO  \n",
       "35                         MESTRADO  \n",
       "36   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "37                         MESTRADO  \n",
       "38                        DOUTORADO  \n",
       "39                        DOUTORADO  \n",
       "40   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "41                        DOUTORADO  \n",
       "42                        DOUTORADO  \n",
       "43                        DOUTORADO  \n",
       "44                         MESTRADO  \n",
       "45                        DOUTORADO  \n",
       "46                     ENSINO MÉDIO  \n",
       "47   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "48                        DOUTORADO  \n",
       "49                        DOUTORADO  \n",
       "50   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "51                        DOUTORADO  \n",
       "52                        DOUTORADO  \n",
       "53                         MESTRADO  \n",
       "54   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "55                  ENSINO SUPERIOR  \n",
       "56                        DOUTORADO  \n",
       "57                        DOUTORADO  \n",
       "58                        DOUTORADO  \n",
       "59           TÉCNICO (ENSINO MÉDIO)  \n",
       "60                     ENSINO MÉDIO  \n",
       "61           TÉCNICO (ENSINO MÉDIO)  \n",
       "62           TÉCNICO (ENSINO MÉDIO)  \n",
       "63                     ENSINO MÉDIO  \n",
       "64   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "65                  ENSINO SUPERIOR  \n",
       "66   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "67   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "68   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "69   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "70                     ENSINO MÉDIO  \n",
       "71   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "72           TÉCNICO (ENSINO MÉDIO)  \n",
       "73                  ENSINO SUPERIOR  \n",
       "74   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "75           TÉCNICO (ENSINO MÉDIO)  \n",
       "76                  ENSINO SUPERIOR  \n",
       "77                  ENSINO SUPERIOR  \n",
       "78                        DOUTORADO  \n",
       "79                  ENSINO SUPERIOR  \n",
       "80                         MESTRADO  \n",
       "81                     ENSINO MÉDIO  \n",
       "82           TÉCNICO (ENSINO MÉDIO)  \n",
       "83           TÉCNICO (ENSINO MÉDIO)  \n",
       "84   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "85   ESPECIALIZAÇÃO (PÓS-GRADUAÇÃO)  \n",
       "86           TÉCNICO (ENSINO MÉDIO)  \n",
       "87                  ENSINO SUPERIOR  \n",
       "88           TÉCNICO (ENSINO MÉDIO)  \n",
       "89                     ENSINO MÉDIO  \n",
       "90           TÉCNICO (ENSINO MÉDIO)  \n",
       "91                         MESTRADO  \n",
       "92                  ENSINO SUPERIOR  \n",
       "93                         MESTRADO  \n",
       "94                         MESTRADO  \n",
       "95                        DOUTORADO  \n",
       "96                        DOUTORADO  \n",
       "97                        DOUTORADO  \n",
       "98                  ENSINO SUPERIOR  \n",
       "99                     ENSINO MÉDIO  \n",
       "100                        MESTRADO  \n",
       "101                    ENSINO MÉDIO  \n",
       "102                 ENSINO SUPERIOR  \n",
       "103                       DOUTORADO  \n",
       "104                 ENSINO SUPERIOR  \n",
       "105                       DOUTORADO  \n",
       "106                 ENSINO SUPERIOR  \n",
       "107                 ENSINO SUPERIOR  \n",
       "108                       DOUTORADO  \n",
       "109                    ENSINO MÉDIO  \n",
       "110                    ENSINO MÉDIO  \n",
       "111                             NaN  \n",
       "112                             NaN  \n",
       "113                             NaN  \n",
       "114                             NaN  \n",
       "115                             NaN  \n",
       "116                             NaN  \n",
       "117                             NaN  \n",
       "118                             NaN  \n",
       "119                             NaN  \n",
       "120                             NaN  \n",
       "121                             NaN  \n",
       "122                             NaN  \n",
       "123                             NaN  \n",
       "124                             NaN  \n",
       "125                             NaN  \n",
       "126                             NaN  \n",
       "127                             NaN  \n",
       "128                             NaN  \n",
       "129                             NaN  \n",
       "130                             NaN  \n",
       "131                             NaN  \n",
       "132                             NaN  \n",
       "133                             NaN  \n",
       "134                             NaN  \n",
       "135                             NaN  \n",
       "136                             NaN  \n",
       "137                             NaN  \n",
       "138                             NaN  \n",
       "139                             NaN  \n",
       "140                             NaN  \n",
       "141                             NaN  \n",
       "142                             NaN  \n",
       "143                             NaN  \n",
       "144                             NaN  \n",
       "145                             NaN  \n",
       "146                             NaN  \n",
       "147                             NaN  \n",
       "148                             NaN  \n",
       "149                             NaN  \n",
       "150                             NaN  \n",
       "151                             NaN  \n",
       "152                             NaN  \n",
       "153                             NaN  \n",
       "154                             NaN  \n",
       "155                             NaN  \n",
       "156                             NaN  \n",
       "157                             NaN  \n",
       "158                             NaN  \n",
       "159                             NaN  \n",
       "160                             NaN  \n",
       "161                             NaN  \n",
       "162                             NaN  \n",
       "163                             NaN  \n",
       "164                             NaN  \n",
       "165                             NaN  \n",
       "166                             NaN  \n",
       "167                             NaN  \n",
       "168                             NaN  \n",
       "169                             NaN  \n",
       "170                             NaN  \n",
       "171                             NaN  \n",
       "172                             NaN  \n",
       "173                             NaN  \n",
       "174                             NaN  \n",
       "175                             NaN  \n",
       "176                             NaN  \n",
       "177                             NaN  \n",
       "178                             NaN  \n",
       "179                             NaN  \n",
       "180                             NaN  \n",
       "181                             NaN  \n",
       "182                             NaN  \n",
       "183                             NaN  \n",
       "184                             NaN  \n",
       "185                             NaN  \n",
       "186                             NaN  \n",
       "187                             NaN  \n",
       "188                             NaN  \n",
       "189                             NaN  \n",
       "190                             NaN  \n",
       "191                             NaN  \n",
       "192                             NaN  \n",
       "193                             NaN  \n",
       "194                             NaN  \n",
       "195                             NaN  \n",
       "196                             NaN  \n",
       "197                             NaN  \n",
       "198                             NaN  \n",
       "199                             NaN  \n",
       "200                             NaN  \n",
       "201                             NaN  \n",
       "202                             NaN  \n",
       "203                             NaN  \n",
       "204                             NaN  \n",
       "205                             NaN  \n",
       "206                             NaN  \n",
       "207                             NaN  \n",
       "208                             NaN  \n",
       "209                             NaN  \n",
       "210                             NaN  \n",
       "211                             NaN  \n",
       "212                             NaN  \n",
       "213                             NaN  \n",
       "214                             NaN  \n",
       "215                             NaN  \n",
       "216                             NaN  \n",
       "217                             NaN  \n",
       "218                             NaN  \n",
       "219                             NaN  \n",
       "220                             NaN  \n",
       "221                             NaN  \n",
       "222                             NaN  \n",
       "223                             NaN  \n",
       "224                             NaN  \n",
       "225                             NaN  \n",
       "226                             NaN  \n",
       "227                             NaN  \n",
       "228                             NaN  \n",
       "229                             NaN  \n",
       "230                             NaN  \n",
       "231                             NaN  \n",
       "232                             NaN  \n",
       "233                             NaN  \n",
       "234                             NaN  \n",
       "235                             NaN  \n",
       "236                             NaN  \n",
       "237                             NaN  \n",
       "238                             NaN  \n",
       "239                             NaN  \n",
       "240                             NaN  \n",
       "241                             NaN  \n",
       "242                             NaN  \n",
       "243                             NaN  \n",
       "244                             NaN  \n",
       "245                             NaN  \n",
       "246                             NaN  \n",
       "247                             NaN  \n",
       "248                             NaN  \n",
       "249                             NaN  \n",
       "250                             NaN  \n",
       "251                             NaN  \n",
       "252                             NaN  \n",
       "253                             NaN  \n",
       "254                             NaN  \n",
       "255                             NaN  \n",
       "256                             NaN  \n",
       "257                             NaN  \n",
       "258                             NaN  \n",
       "259                             NaN  \n",
       "260                             NaN  \n",
       "261                             NaN  \n",
       "262                             NaN  \n",
       "263                             NaN  \n",
       "264                             NaN  \n",
       "265                             NaN  \n",
       "266                             NaN  \n",
       "267                             NaN  \n",
       "268                             NaN  \n",
       "269                             NaN  \n",
       "270                             NaN  \n",
       "271                             NaN  \n",
       "272                             NaN  \n",
       "273                             NaN  \n",
       "274                             NaN  \n",
       "275                             NaN  \n",
       "276                             NaN  \n",
       "277                             NaN  \n",
       "278                             NaN  \n",
       "279                             NaN  \n",
       "280                             NaN  \n",
       "281                             NaN  \n",
       "282                             NaN  \n",
       "283                             NaN  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fioce_pessoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fioce_pessoal.sort_values(by='ÁREA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_data = df_artigosperiodo.groupby(['ANO_PUB', 'CURRICULO']).size().reset_index(name='count')\n",
    "# df_areas = fioce_pessoal.groupby(by='ÁREA').size().reset_index(name='SERVIDORES')\n",
    "# df_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fioce_pessoal[fioce_pessoal.ÁREA=='Coordenação da Gestão e Desenvolvimento Institucional (COMPRAS)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extrair currículos da Plataforma Lattes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir grupo de indivíduos para análise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Montar lista de todos servidores ativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_servidores_doutores = []\n",
    "lista_servidores_mestrado = []\n",
    "\n",
    "# Ler o arquivo Excel usando apenas as colunas selecionadas\n",
    "fioce_pessoal = pd.read_excel(pathzip+'fioce_colaboradores-2023.xls', skiprows=3, header=0, usecols=selected_columns)\n",
    "fioce_pessoal['NOME'] = fioce_pessoal['NOME'].str.strip()\n",
    "\n",
    "filtro1=fioce_pessoal.VÍNCULO=='SERVIDOR'\n",
    "fioce_pessoal = fioce_pessoal[filtro1]\n",
    "\n",
    "filtro2=fioce_pessoal.STATUS=='ATIVO'\n",
    "fioce_pessoal = fioce_pessoal[filtro2]\n",
    "lista_servidores = fioce_pessoal['NOME']\n",
    "lista_servidores.sort_values()\n",
    "\n",
    "filtro3=fioce_pessoal.NÍVEL=='MESTRADO'\n",
    "fioce_pessoal_mestrado = fioce_pessoal[filtro3]\n",
    "lista_servidores_mestrado = fioce_pessoal_mestrado['NOME']\n",
    "lista_servidores_mestrado.sort_values()\n",
    "\n",
    "filtro4=fioce_pessoal.NÍVEL=='DOUTORADO'\n",
    "fioce_pessoal_doutorado = fioce_pessoal[filtro4]\n",
    "lista_servidores_doutorado = fioce_pessoal_doutorado['NOME']\n",
    "lista_servidores_doutorado.sort_values()\n",
    "\n",
    "print(f'{len(lista_servidores)} servidores com qualquer nível de formação')\n",
    "print(f'{len(lista_servidores_mestrado)} servidores, {len(lista_servidores_mestrado)/len(lista_servidores)*100:.2f}% com formação máxima a nível de mestrado')\n",
    "print(f'{len(lista_servidores_doutorado)} servidores, {len(lista_servidores_doutorado)/len(lista_servidores)*100:.2f}% com formação a nível de doutorado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_servidores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efetuar requisições à página do CNPq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t_ini=time.time()\n",
    "df_secoes_servidores, sucesso_servidores, json_data = extrair_dados(lista_servidores, mestres=True, assunto=False)\n",
    "\n",
    "print('-'*50)\n",
    "print(tempo(t_ini,time.time()), 'Tempo extração dados do currículo')\n",
    "print(f'{len(sucesso_servidores)} currículos encontrados e extraído')\n",
    "print(f'{len(sucesso_servidores)/len(lista_servidores)*100:.2f}% do total de servidores com currículos na plataforma Lattes do CNPq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total de linhas de dados extraídas: {len(df_secoes_servidores)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Servidores currículo Lattes não encontrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lista_servidores:\n",
    "    if i not in sucesso_servidores:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar Resultados em Arquivo de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_secoes_servidores.to_csv(pathout+'df_secoes_servidores.csv', sep=\";\", index=False)\n",
    "len(df_secoes_servidores[df_secoes_servidores['ROTULOS']=='Nome'].index)\n",
    "\n",
    "for n,i in enumerate(df_secoes_servidores['CURRICULO'].unique()):\n",
    "    print(f'{n+1:2} {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementar funções para contar artigos e citações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listar_idlattes(df_secoes):\n",
    "    df_idlattes = df_secoes[df_secoes['ROTULOS']=='ID Lattes:']\n",
    "    if 'SOMA_CITACOES' in df_idlattes.columns:\n",
    "        df_idlattes.drop('SOMA_CITACOES', axis=1, inplace=True)\n",
    "    return df_idlattes\n",
    "\n",
    "def listar_artigos(df_secoes):\n",
    "    df_idlattes = df_secoes[df_secoes['ROTULOS']=='Artigos completos publicados em periódicos']\n",
    "    return df_idlattes\n",
    "\n",
    "def sum_citations(text):\n",
    "    pattern = r\"Citações:((?:\\d+\\|)*\\d+)\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    total_sum = 0\n",
    "    \n",
    "    for match in matches:\n",
    "        numbers = map(int, match.split(\"|\"))\n",
    "        total_sum += sum(numbers)\n",
    "        \n",
    "    return total_sum\n",
    "\n",
    "def contar_artigos(df_secoes):\n",
    "    def count_year_occurrences(content):\n",
    "        \"\"\"Count the number of occurrences of four-digit years followed by a period in the given string.\"\"\" \n",
    "        if not isinstance(content, (str, bytes)):\n",
    "            content = ' '.join(map(str, content))\n",
    "        pattern = r'\\b\\d{4}\\.'\n",
    "        return len(re.findall(pattern, content))\n",
    "\n",
    "    def extract_citations(content):\n",
    "        content_utf8 = [x.replace('CitaÃ§Ãµes:','Citações:') for x in content]\n",
    "        if not isinstance(content_utf8, (str, bytes)):\n",
    "            content = ' '.join(map(str, content_utf8))\n",
    "        citation_pattern = r\"Citações:((?:\\d+\\|)*\\d+)\"\n",
    "        all_citations = re.findall(citation_pattern, content)\n",
    "        total_citations = 0\n",
    "        for citation_group in all_citations:\n",
    "            numbers = map(int, citation_group.split('|'))\n",
    "            total_citations += sum(numbers)\n",
    "        return total_citations\n",
    "\n",
    "    ds_linhas_conteudos = df_secoes[df_secoes['ROTULOS'] == 'Artigos completos publicados em periódicos'].CONTEUDOS\n",
    "    ds_linhas_conteudos = ds_linhas_conteudos.apply(lambda lista: [x.replace('CitaÃ§Ãµes:', 'Citações:') if isinstance(x, str) else x for x in lista] if isinstance(lista, list) else lista)\n",
    "    ds_qte_artigos      = ds_linhas_conteudos.apply(count_year_occurrences)\n",
    "    ds_qte_citacoes     = ds_linhas_conteudos.apply(extract_citations)\n",
    "    df_secoes_contadas  = df_secoes[df_secoes['ROTULOS'] == 'Artigos completos publicados em periódicos']\n",
    "    df_secoes_contadas['CONTEUDOS']     = ds_linhas_conteudos\n",
    "    df_secoes_contadas.drop('CONTEUDOS', axis=1, inplace=True)\n",
    "    df_secoes_contadas['QTE_ARTIGOS']   = ds_qte_artigos\n",
    "    df_secoes_contadas['SOMA_CITACOES'] = ds_qte_citacoes\n",
    "\n",
    "    return df_secoes_contadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_secoes = df_secoes_servidores\n",
    "df_idlattes = listar_idlattes(df_secoes)\n",
    "df_idlattes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qte_artigos = contar_artigos(df_secoes)\n",
    "print(df_qte_artigos.QTE_ARTIGOS.sum())\n",
    "df_qte_artigos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementar funções montar áreas de pesquisa CNPq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "pasta_arquivo = pathzip \n",
    "arquivo = 'cnpq_tabela-areas-conhecimento.pdf'\n",
    "caminho = pasta_arquivo+arquivo\n",
    "\n",
    "def verifica_ponto_virgula(df):\n",
    "    return df[df['Descricao'].str.contains(';', regex=False)]\n",
    "\n",
    "def verifica_virgula(df):\n",
    "    return df[df['Descricao'].str.contains(',', regex=False)]\n",
    "\n",
    "def verifica_formato_descricao(descricao):\n",
    "    excecoes = [\"de\", \"do\", \"da\", \"dos\", \"das\", \"a\", \"o\", \"e\", \"em\", \"com\", \"para\", \"por\", \"sem\"]\n",
    "    palavras = descricao.split()\n",
    "    \n",
    "    for i, palavra in enumerate(palavras):\n",
    "        if palavra.lower() in excecoes or palavra[0]==\"(\":\n",
    "            continue\n",
    "        if not palavra[0].isupper() or (palavra==palavras[-1] and palavra in excecoes):\n",
    "            return False, i  # Retornar False e o índice da palavra problemática\n",
    "    return True, None\n",
    "\n",
    "    # for idx, word in enumerate(palavras):\n",
    "    #     # Se a palavra inicia com letra minúscula e não é uma preposição ou artigo\n",
    "    #     if word[0].islower() and word not in excecoes:\n",
    "    #         # Aqui verificamos se a palavra anterior termina com uma letra e a palavra atual é uma preposição ou artigo\n",
    "    #         if idx > 0 and palavras[idx - 1][-1].isalpha() and word in excecoes:\n",
    "    #             return (False, idx)\n",
    "    #         # Ou apenas a condição de começar com minúscula e não ser preposição ou artigo\n",
    "    #         elif idx == 0 or (idx > 0 and not palavras[idx - 1][-1].isalpha()):\n",
    "    #             return (False, idx)    \n",
    "\n",
    "def corrigir_descricao(descricao, word_index):\n",
    "    excecoes = [\"de\", \"do\", \"da\", \"dos\", \"das\", \"a\", \"o\", \"e\", \"em\", \"com\", \"para\", \"por\", \"sem\"]\n",
    "    palavras = descricao.split()\n",
    "\n",
    "    # Se o índice anterior existir e a palavra atual começa com minúscula\n",
    "    if word_index > 0 and palavras[word_index][0].islower():\n",
    "        # Checar se a palavra é uma preposição ou artigo e se a anterior termina com uma letra\n",
    "        if palavras[word_index] in excecoes:\n",
    "            palavras[word_index - 1] += palavras[word_index]\n",
    "            del palavras[word_index]\n",
    "        else:\n",
    "            # Juntar palavra atual com a palavra anterior\n",
    "            palavras[word_index - 1] += palavras[word_index]\n",
    "            del palavras[word_index]\n",
    "\n",
    "    # Após as correções, juntamos as palavras de volta em uma única string\n",
    "    nova_descricao = ' '.join(palavras)\n",
    "\n",
    "    # Imprimindo para debug\n",
    "    # print(f\"Descrição ruim: {descricao}\")\n",
    "    # print(f\"Correção feita: {palavra_anterior} + {palavra_incorreta} = {correcao}\")\n",
    "    # print(f\"Nova descrição: {nova_descricao}\\n\")\n",
    "    \n",
    "    return nova_descricao\n",
    "\n",
    "\n",
    "def extrair_areas(caminho):\n",
    "    texto_completo = \"\"\n",
    "\n",
    "    reader = PdfReader(caminho)\n",
    "    \n",
    "    for npag, p in tqdm(enumerate(reader.pages), total=len(reader.pages), desc=\"Processando páginas do PDF das Áreas de pesquisa do CNPq..\"):\n",
    "        texto_completo += p.extract_text()\n",
    "\n",
    "    texto_completo = texto_completo.replace('\\n', ' ').replace(\" -\",\"-\").replace(\" ,\",\",\").strip().replace(\"ã o\",\"ão\")\n",
    "    texto_completo = re.sub(r'\\s?(\\d)\\s?(\\.)\\s?(\\d{2})\\s?(\\.)\\s?(\\d{2})\\s?(\\.)\\s?(\\d{2})\\s?(-)\\s?(\\d)\\s?', r'\\1\\2\\3\\4\\5\\6\\7\\8\\9', texto_completo)\n",
    "\n",
    "    pattern = r'(\\d\\.\\d{2}\\.\\d{2}\\.\\d{2}-\\d)([^0-9]+)'\n",
    "    matches = re.findall(pattern, texto_completo)\n",
    "\n",
    "    codigos = [match[0] for match in matches]\n",
    "    descricoes = [match[1].strip() for match in matches]\n",
    "\n",
    "    print(f'Total dos códigos   identificados: {len(codigos)}')\n",
    "    print(f'Total de descrições identificadas: {len(descricoes)}')\n",
    "\n",
    "    df_linhas = pd.DataFrame({'Codigo': codigos, 'Descricao': descricoes})\n",
    "\n",
    "    # Verificação da divisão correta dos códigos/descrições\n",
    "    descricoes_com_numeros = df_linhas[df_linhas['Descricao'].str.contains(r'\\d')]\n",
    "    if not descricoes_com_numeros.empty:\n",
    "        print(f\"Conferência: {len(descricoes_com_numeros)} descrições contêm números!\")\n",
    "    else:\n",
    "        print(f\"Nenhum erro de códigos em descrições!\")\n",
    "\n",
    "    # Identificando e printando a quantidade de possíveis erros\n",
    "    erros = sum(1 for descricao in descricoes if not verifica_formato_descricao(descricao)[0])\n",
    "    print(f\"{erros} possíveis erros de descrição detectados.\")\n",
    "\n",
    "    # Barra de progresso para correção das descrições\n",
    "    with tqdm(total=df_linhas.shape[0], desc=\"Corrigindo descrições...\") as pbar:\n",
    "        for index, row in df_linhas.iterrows():\n",
    "            is_valid, word_index = verifica_formato_descricao(row['Descricao'])\n",
    "            loop_count = 0\n",
    "            while not is_valid and loop_count < 10:\n",
    "                row['Descricao'] = corrigir_descricao(row['Descricao'], word_index)\n",
    "                is_valid, word_index = verifica_formato_descricao(row['Descricao'])\n",
    "                loop_count += 1\n",
    "            if loop_count == 10:\n",
    "                print(f\"Problema corrigindo descrição: {row['Descricao']}\")\n",
    "            pbar.update(1)\n",
    "\n",
    "    return df_linhas\n",
    "\n",
    "df_areas = extrair_areas(caminho)\n",
    "\n",
    "def count_unique_for_level(level: int):\n",
    "    return df_areas['Codigo'].str.split('.', expand=True)[level].nunique()\n",
    "\n",
    "# Remover o sufixo após o hífen\n",
    "def count_unique_for_last_level():\n",
    "    return df_areas['Codigo'].str.split('.', expand=True).iloc[:, -1].str.split('-').str[0].nunique()\n",
    "\n",
    "levels = df_areas['Codigo'].str.count(\"\\.\").iloc[0]  # conta a quantidade de pontos, para determinar o número de níveis\n",
    "\n",
    "unique_counts = [count_unique_for_level(i) for i in range(levels)]\n",
    "unique_counts.append(count_unique_for_last_level())\n",
    "\n",
    "# qte_grandeareas, qte_areas, qte_subareas, qte_especialidades = unique_counts\n",
    "# print(f'Quantidades de codigos:')\n",
    "# print(f'  Grande_Área: {qte_grandeareas:2}')\n",
    "# print(f'         Área: {qte_areas:2}')\n",
    "# print(f'      Subárea: {qte_subareas:2}')\n",
    "# print(f'Especialidade: {qte_especialidades:2}')\n",
    "\n",
    "# Dividir a coluna 'Codigo' em várias colunas\n",
    "df_split = df_areas['Codigo'].str.split('.', expand=True)\n",
    "\n",
    "# Remover o último hífen e dígito das colunas \n",
    "df_split.iloc[:, -1] = df_split.iloc[:, -1].str.split('-').str[0]\n",
    "\n",
    "def count_sublevels(df, level):\n",
    "    if level == 0:\n",
    "        return df[0].nunique()\n",
    "    else:\n",
    "        return df.groupby(list(range(level)))[level].nunique().reset_index(name=\"count\")[\"count\"].to_list()\n",
    "\n",
    "sublevels_counts = [count_sublevels(df_split, i) for i in range(df_split.shape[1])]\n",
    "\n",
    "# Criar uma coluna para armazenar a contagem de subníveis\n",
    "# df_areas['SublevelCount'] = df_split.apply(lambda row: [sublevels_counts[col][row[:col].astype(str).tolist().index(row[col-1]) if row[col-1] in row[:col].astype(str).tolist() else -1] if col > 0 else sublevels_counts[col] for col in df_split.columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_areas[:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir por nível de classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_areas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\marco\\fioce\\source\\adapters\\input\\jupyter_notebooks\\extrair_lattes.ipynb Célula 108\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marco/fioce/source/adapters/input/jupyter_notebooks/extrair_lattes.ipynb#Y211sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m cat_areas\u001b[39m=\u001b[39m[]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marco/fioce/source/adapters/input/jupyter_notebooks/extrair_lattes.ipynb#Y211sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m cat_especialidades\u001b[39m=\u001b[39m[]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/marco/fioce/source/adapters/input/jupyter_notebooks/extrair_lattes.ipynb#Y211sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m cod,des \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(df_areas[\u001b[39m'\u001b[39m\u001b[39mCodigo\u001b[39m\u001b[39m'\u001b[39m],df_areas[\u001b[39m'\u001b[39m\u001b[39mDescricao\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marco/fioce/source/adapters/input/jupyter_notebooks/extrair_lattes.ipynb#Y211sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     k \u001b[39m=\u001b[39m contar_marcadores(cod)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/marco/fioce/source/adapters/input/jupyter_notebooks/extrair_lattes.ipynb#Y211sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mif\u001b[39;00m k\u001b[39m==\u001b[39m\u001b[39m3\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_areas' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def contar_marcadores(texto):\n",
    "    padrao = r'\\.00'\n",
    "    ocorrencias = re.findall(padrao, texto)\n",
    "    return len(ocorrencias)\n",
    "\n",
    "cat_grandeareas=[]\n",
    "cat_subareas=[]\n",
    "cat_areas=[]\n",
    "cat_especialidades=[]\n",
    "\n",
    "for cod,des in zip(df_areas['Codigo'],df_areas['Descricao']):\n",
    "    k = contar_marcadores(cod)\n",
    "    if k==3:\n",
    "        cat_grandeareas.append((cod,des))\n",
    "    elif k==2:\n",
    "        cat_subareas.append((cod,des))\n",
    "    elif k==1:\n",
    "        cat_areas.append((cod,des))\n",
    "    elif k==0:\n",
    "        cat_especialidades.append((cod,des))\n",
    "    else:\n",
    "        print('Erro na separação')\n",
    "        print(f'{k} {cod}{des}')\n",
    "\n",
    "print(f'{len(cat_grandeareas):4} Grandes Áreas')\n",
    "print(f'{len(cat_subareas):4} Subáreas')\n",
    "print(f'{len(cat_areas):4} Áreas')\n",
    "print(f'{len(cat_especialidades):4} Especialidades')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_grandeareas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_subareas[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_areas[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_especialidades[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_areas.to_csv(pathout+'cnpq_areas-pesquisa.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela de Áreas de Conhecimento CNPQ\n",
    "\n",
    "http://lattes.cnpq.br/documents/11871/24930/TabeladeAreasdoConhecimento.pdf/d192ff6b-3e0a-4074-a74d-c280521bd5f7\n",
    "\n",
    "http://lattes.cnpq.br/web/dgp/arvore-do-conhecimento\n",
    "\n",
    "<b> Árvore do conhecimento </b>\n",
    "\n",
    "    Ciências Agrárias.\n",
    "    Ciências Biológicas.\n",
    "    Ciências da Saúde.\n",
    "    Ciências Exatas e da Terra.\n",
    "    Engenharias.\n",
    "    Ciências Humanas.\n",
    "    Ciências Sociais Aplicadas.\n",
    "    Lingüística, Letras e Artes.\n",
    "\n",
    "<b> Setores de Aplicação </b>\n",
    "\n",
    "https://lattes.cnpq.br/web/dgp/setores-de-aplicacao-2002-2010 (Link Quebrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><b>ESTUDAR COMO CLASSIFICAR ATIVIDADES DE PESQUISA</b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atividades econômicas na CNAE 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação nacional de atividades econômicas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fonte:\n",
    "https://concla.ibge.gov.br/classificacoes/por-tema/atividades-economicas/classificacao-nacional-de-atividades-economicas.html\n",
    "\n",
    "Estrutura: \n",
    "\n",
    "    1º nível: 21 Seções\n",
    "    2º nível: 87 Divisões\n",
    "    3° nível: 285 Grupos\n",
    "    4º nível: 673 Classes\n",
    "    5º nível: 1301 Subclasses\n",
    "\n",
    "Descrição: A Classificação Nacional de Atividades Econômicas-CNAE é a classificação oficialmente adotada pelo Sistema Estatístico Nacional e pelos órgãos federais gestores de registros administrativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fonte:\n",
    "https://concla.ibge.gov.br/busca-online-cnae.html?view=estrutura\n",
    "\n",
    "Seções:\n",
    "\n",
    "    A\t01 .. 03\tAGRICULTURA, PECUÁRIA, PRODUÇÃO FLORESTAL, PESCA E AQÜICULTURA\n",
    "    B\t05 .. 09\tINDÚSTRIAS EXTRATIVAS\n",
    "    C\t10 .. 33\tINDÚSTRIAS DE TRANSFORMAÇÃO\n",
    "    D\t35 .. 35\tELETRICIDADE E GÁS\n",
    "    E\t36 .. 39\tÁGUA, ESGOTO, ATIVIDADES DE GESTÃO DE RESÍDUOS E DESCONTAMINAÇÃO\n",
    "    F\t41 .. 43\tCONSTRUÇÃO\n",
    "    G\t45 .. 47\tCOMÉRCIO; REPARAÇÃO DE VEÍCULOS AUTOMOTORES E MOTOCICLETAS\n",
    "    H\t49 .. 53\tTRANSPORTE, ARMAZENAGEM E CORREIO\n",
    "    I\t55 .. 56\tALOJAMENTO E ALIMENTAÇÃO\n",
    "    J\t58 .. 63\tINFORMAÇÃO E COMUNICAÇÃO\n",
    "    K\t64 .. 66\tATIVIDADES FINANCEIRAS, DE SEGUROS E SERVIÇOS RELACIONADOS\n",
    "    L\t68 .. 68\tATIVIDADES IMOBILIÁRIAS\n",
    "    M\t69 .. 75\tATIVIDADES PROFISSIONAIS, CIENTÍFICAS E TÉCNICAS\n",
    "    N\t77 .. 82\tATIVIDADES ADMINISTRATIVAS E SERVIÇOS COMPLEMENTARES\n",
    "    O\t84 .. 84\tADMINISTRAÇÃO PÚBLICA, DEFESA E SEGURIDADE SOCIAL\n",
    "    P\t85 .. 85\tEDUCAÇÃO\n",
    "    Q\t86 .. 88\tSAÚDE HUMANA E SERVIÇOS SOCIAIS\n",
    "    R\t90 .. 93\tARTES, CULTURA, ESPORTE E RECREAÇÃO\n",
    "    S\t94 .. 96\tOUTRAS ATIVIDADES DE SERVIÇOS\n",
    "    T\t97 .. 97\tSERVIÇOS DOMÉSTICOS\n",
    "    U\t99 .. 99\tORGANISMOS INTERNACIONAIS E OUTRAS INSTITUIÇÕES EXTRATERRITORIAIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca em atividades econômicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sintaxe para busca\n",
    "\n",
    "O mecanismo de busca da CNAE aceita consultas a partir de palavra, palavras completas e incompletas e texto. Os resultados serão exibidos ordenados inicialmente pelo código podendo o usuário optar pelo tipo de ordenação (código ou descrição).\n",
    "\n",
    "Uma dica importante é usar apenas palavras chaves na sua busca. Ao invés de buscar, por exemplo, Gado de Corte, busque por Gado Corte. O uso de preposições pode levar a resultados indesejados ou de pouca relevância para sua busca. O mecanismo de busca não faz distinção entre maiúscula e minúscula e acentuação.\n",
    "\n",
    "<b> Hierarquia </b>\n",
    "\n",
    "    Seção:\t    M\tATIVIDADES PROFISSIONAIS, CIENTÍFICAS E TÉCNICAS\n",
    "    Divisão:\t72 PESQUISA E DESENVOLVIMENTO CIENTÍFICO\n",
    "    Grupo:              72.1 Pesquisa e desenvolvimento experimental em ciências físicas e naturais\n",
    "                        72.2 Pesquisa e desenvolvimento experimental em ciências sociais e humanas\n",
    "\n",
    "\n",
    "    Seção:\t    M\tATIVIDADES PROFISSIONAIS, CIENTÍFICAS E TÉCNICAS\n",
    "    Divisão: \t72 PESQUISA E DESENVOLVIMENTO CIENTÍFICO\n",
    "    Grupo:\t            72.1 Pesquisa e desenvolvimento experimental em ciências físicas e naturais\n",
    "    Classe:\t                72.10-0 Pesquisa e desenvolvimento experimental em ciências físicas e naturais\n",
    "    Subclasse:                  7210-0/00 Pesquisa e desenvolvimento experimental em ciências físicas e naturais\n",
    "\n",
    "Notas Explicativas:\n",
    "Esta classe compreende:\n",
    "\n",
    "    - as atividades de pesquisa e desenvolvimento realizadas no âmbito das ciências da vida, tais como: medicina, biologia, bioquímica, farmácia, agronomia e conexas\n",
    "\n",
    "    - as atividades de pesquisa e desenvolvimento realizadas no âmbito das ciências físicas e de engenharia, tais como: matemática, física, astronomia, química, geociências e conexas\n",
    "\n",
    "Lista de Descritores\n",
    "Registros encontrados: 16\n",
    "\n",
    "    Código\tDescrição\n",
    "    7210-0\tAGRONOMIA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7210-0\tBIOQUÍMICA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7210-0\tFARMÁCIA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7210-0\tFAZENDA EXPERIMENTAL; PESQUISA\n",
    "    7210-0\tLABORATÓRIO DE PESQUISA FÍSICA, COMERCIAL E NÃO COMERCIAL\n",
    "    7210-0\tLABORATÓRIO DE PESQUISA QUÍMICA, COMERCIAL E NÃO COMERCIAL\n",
    "    7210-0\tLABORATÓRIO INDUSTRIAL; PESQUISA\n",
    "    7210-0\tMEDICINA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7210-0\tPESQUISA BIOGENÉTICA\n",
    "    7210-0\tPESQUISA BIOLÓGICA\n",
    "    7210-0\tPESQUISA E DESENVOLVIMENTO COM ACESSO A PATRIMÔNIO GENÉTICO EXISTENTE NO TERRITÓRIO NACIONAL; ATIVIDADES DE\n",
    "    7210-0\tPESQUISA E DESENVOLVIMENTO DAS CIÊNCIAS FÍSICAS E NATURAIS\n",
    "    7210-0\tPESQUISA E DESENVOLVIMENTO EXPERIMENTAL EM CIÊNCIAS FÍSICAS E NATURAIS; ATIVIDADES DE\n",
    "    7210-0\tPESQUISA MATEMÁTICA, FÍSICA, ASTRONOMIA; DESENVOLVIMENTO DE\n",
    "    7210-0\tPESQUISA MÉDICA NÃO COMERCIAL\n",
    "    7210-0\tQUÍMICA; PESQUISA E DESENVOLVIMENTO EM\n",
    "\n",
    "<b> Exemplo de atividades relacionadas ao termo \"Pesquisa\" no CNAE 2.0 </b>\n",
    "\n",
    "Classes encontradas: 45\n",
    "\n",
    "    Código\tDescrição\n",
    "    0159-8\tANIMAIS PARA PESQUISA; CRIAÇÃO DE\n",
    "    0159-8\tBIOTÉRIO; CRIAÇÃO DE ANIMAIS PARA PESQUISA\n",
    "    0170-9\tCAPTURA DE ANIMAIS, MORTOS OU VIVOS, PARA PESQUISA, UTILIZAÇÃO EM ZOOLÓGICOS; SERVIÇOS DE\n",
    "    2651-5\tAPARELHOS E EQUIPAMENTOS PARA LABORATÓRIOS DE PESQUISA CIENTÍFICA; FABRICAÇÃO DE\n",
    "    2651-5\tAPARELHOS E EQUIPAMENTOS PARA LABORATÓRIOS DE PESQUISA E DESENVOLVIMENTO; FABRICAÇÃO DE\n",
    "    2829-1\tCENTRIFUGADOR PARA LABORATÓRIO DE ANÁLISE. ENSAIO OU PESQUISA CIENTÍFICA; FABRICAÇÃO DE\n",
    "    3011-3\tNAVIOS-HOSPITAIS, NAVIOS DE GUERRA, EMBARCAÇÕES PARA PESQUISA CIENTÍFICA E OUTRAS EMBARCAÇÕES SEMELHANTES; FABRICAÇÃO DE\n",
    "    3312-1\tAPARELHOS E EQUIPAMENTOS PARA LABORATÓRIOS DE PESQUISA CIENTÍFICA, MANUTENÇAO E REPARACAO DE\n",
    "    3312-1\tAPARELHOS E EQUIPAMENTOS PARA LABORATÓRIOS DE PESQUISA E DESENVOLVIMENTO, MANUTENÇAO E REPARACAO DE\n",
    "    5030-1\tTRANSPORTE DE MERCADORIAS E PESSOAS PARA SUPRIMENTO E APOIO A PLATAFORMAS DE PESQUISA\n",
    "    6319-4\tBANCO DE INFORMAÇÃO PARA PESQUISA E ANÁLISE; SERVIÇOS DE\n",
    "    7119-7\tPROSPECÇÃO, PESQUISA MINERAL; SERVIÇOS DE\n",
    "    7210-0\tAGRONOMIA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7210-0\tBIOQUÍMICA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7210-0\tFARMÁCIA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7210-0\tFAZENDA EXPERIMENTAL; PESQUISA\n",
    "    7210-0\tLABORATÓRIO DE PESQUISA FÍSICA, COMERCIAL E NÃO COMERCIAL\n",
    "    7210-0\tLABORATÓRIO DE PESQUISA QUÍMICA, COMERCIAL E NÃO COMERCIAL\n",
    "    7210-0\tLABORATÓRIO INDUSTRIAL; PESQUISA\n",
    "    7210-0\tMEDICINA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7210-0\tPESQUISA BIOGENÉTICA\n",
    "    7210-0\tPESQUISA BIOLÓGICA\n",
    "    7210-0\tPESQUISA E DESENVOLVIMENTO COM ACESSO A PATRIMÔNIO GENÉTICO EXISTENTE NO TERRITÓRIO NACIONAL; ATIVIDADES DE\n",
    "    7210-0\tPESQUISA E DESENVOLVIMENTO DAS CIÊNCIAS FÍSICAS E NATURAIS\n",
    "    7210-0\tPESQUISA E DESENVOLVIMENTO EXPERIMENTAL EM CIÊNCIAS FÍSICAS E NATURAIS; ATIVIDADES DE\n",
    "    7210-0\tPESQUISA MATEMÁTICA, FÍSICA, ASTRONOMIA; DESENVOLVIMENTO DE\n",
    "    7210-0\tPESQUISA MÉDICA NÃO COMERCIAL\n",
    "    7210-0\tQUÍMICA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7220-7\tARQUEOLOGIA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7220-7\tARTES; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7220-7\tDIREITO; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7220-7\tECONOMIA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7220-7\tLINGÜÍSTICA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7220-7\tPESQUISA E DESENVOLVIMENTO EM CIÊNCIAS SOCIAIS E HUMANAS\n",
    "    7220-7\tPESQUISA ECONÔMICA, COMERCIAL E NÃO COMERCIAL\n",
    "    7220-7\tPESQUISA EDUCACIONAL\n",
    "    7220-7\tSOCIOLOGIA; PESQUISA E DESENVOLVIMENTO EM\n",
    "    7320-3\tPESQUISA DE MERCADO E DE OPINIÃO PÚBLICA\n",
    "    7320-3\tPESQUISA DE OPINIÃO PÚBLICA\n",
    "    7320-3\tPESQUISA E COLETA DE DADOS PARA PESQUISAS DE MERCADO E OPINIÃO\n",
    "    7320-3\tPESQUISA MERCADOLÓGICA\n",
    "    7320-3\tPESQUISA POLÍTICA; SERVIÇOS DE\n",
    "    8411-6\tFUNDAÇÃO DE APOIO À PESQUISA E EXTENSÃO\n",
    "    8650-0\tCONSULTORIA EM BIOMEDICINA, EXCETO PARA PESQUISA E DESENVOLVIMENTO; ATIVIDADES DE\n",
    "    9101-5\tDOCUMENTAÇÃO E PESQUISA BIBLIOGRÁFICA; ATIVIDADE DE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Áreas de avaliação da CAPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Áreas do Conhecimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gov.br/capes/pt-br/acesso-a-informacao/acoes-e-programas/avaliacao/instrumentos/documentos-de-apoio-1/tabela-de-areas-de-conhecimento-avaliacao\n",
    "\n",
    "Fonte: www.gov.br, publicado em 19/09/2020 19h38 Atualizado em 24/10/2022 18h03\n",
    "\n",
    "A classificação das Áreas do Conhecimento tem finalidade eminentemente prática, objetivando proporcionar às Instituições de ensino, pesquisa e inovação uma maneira ágil e funcional de sistematizar e prestar informações concernentes a projetos de pesquisa e recursos humanos aos órgãos gestores da área de ciência e tecnologia.\n",
    "\n",
    "A organização das Áreas do Conhecimento na tabela apresenta uma hierarquização em quatro níveis, do mais geral ao mais específico, abrangendo nove grandes áreas nas quais se distribuem as 49 áreas de avaliação da CAPES. Estas áreas de avaliação, por sua vez, agrupam áreas básicas (ou áreas do conhecimento), subdivididas em subáreas e especialidades:\n",
    "\n",
    "1º nível - Grande Área: aglomeração de diversas áreas do conhecimento, em virtude da afinidade de seus objetos, métodos cognitivos e recursos instrumentais refletindo contextos sociopolíticos específicos;\n",
    "\n",
    "2º nível – Área do Conhecimento (Área Básica): conjunto de conhecimentos inter-relacionados, coletivamente construído, reunido segundo a natureza do objeto de investigação com finalidades de ensino, pesquisa e aplicações práticas;\n",
    "\n",
    "3º nível - Subárea: segmentação da área do conhecimento (ou área básica) estabelecida em função do objeto de estudo e de procedimentos metodológicos reconhecidos e amplamente utilizados;\n",
    "\n",
    "4º nível - Especialidade: caracterização temática da atividade de pesquisa e ensino. Uma mesma especialidade pode ser enquadrada em diferentes grandes áreas, áreas básicas e subáreas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorias do Periodicos Capes\n",
    "\n",
    "https://buscador-periodicos-capes-gov-br.ez68.periodicos.capes.gov.br/V/QB984FN2Y5SQTN9JQMSD3BEF1LYT9I6UP1Q51GN5L4YC6JV1EX-14773?func=find-db-info&doc_num=000002739"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_capes = pd.read_csv(pathcsv+'categorias_capes.txt', header=None, sep=';')\n",
    "class_capes.columns = ['CATEGORIAS_SUBCATEGORIAS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_capes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoria=[]\n",
    "subcategoria=[]\n",
    "\n",
    "for i in class_capes['CATEGORIAS_SUBCATEGORIAS'].values:\n",
    "    try:\n",
    "        cat, subcat = i.split('/ ')\n",
    "    except:\n",
    "        print(f'Erro ao dividir: {i}')\n",
    "    categoria.append(cat.strip())\n",
    "    subcategoria.append(subcat.strip())\n",
    "\n",
    "qte_cat = len(pd.Series(categoria).unique())\n",
    "qte_subcat = len(pd.Series(subcategoria).unique())\n",
    "\n",
    "desc_grandeareas = [tupla[-1] for tupla in cat_grandeareas]\n",
    "desc_subareas = [tupla[-1] for tupla in cat_subareas]\n",
    "desc_areas = [tupla[-1] for tupla in cat_areas]\n",
    "desc_especialidades = [tupla[-1] for tupla in cat_especialidades]\n",
    "\n",
    "print('ANÁLISE DA CLASSIFICAÇÃO EXTRAÍDA DO PORTAL DE PERIÓDICOS DA CAPES')\n",
    "\n",
    "print(f'\\n=>CATEGORIAS CAPES: Contém {qte_cat} Categorias no total, podendo ser:')\n",
    "for i in pd.Series(categoria).unique():\n",
    "    if i in desc_grandeareas:\n",
    "        print(f'  É uma das     Áreas do CNPq: \"{i}\"')\n",
    "    elif i in desc_subareas:\n",
    "        print(f'  É uma das  Subáreas do CNPq: \"{i}\"')\n",
    "    elif i in desc_areas:\n",
    "        print(f'  É uma Especialidade do CNPq: \"{i}\"')\n",
    "    elif i in desc_especialidades:\n",
    "        print(f'  É uma Especialidade do CNPq: \"{i}\"')\n",
    "    else:\n",
    "        print(f'Classificação ausente no CNPq: \"{i}\"')\n",
    "\n",
    "print(f'\\n=>SUBCATEGORIAS CAPES: Contém {qte_subcat} Subcategorias no total, podendo ser:')\n",
    "for i in pd.Series(subcategoria).unique():\n",
    "    if i in desc_grandeareas:\n",
    "        print(f'  É uma das     Áreas do CNPq: \"{i}\"')\n",
    "    elif i in desc_subareas:\n",
    "        print(f'  É uma das  Subáreas do CNPq: \"{i}\"')\n",
    "    elif i in desc_areas:\n",
    "        print(f'  É uma Especialidade do CNPq: \"{i}\"')\n",
    "    elif i in desc_especialidades:\n",
    "        print(f'  É uma Especialidade do CNPq: \"{i}\"')\n",
    "    else:\n",
    "        print(f'Classificação ausente no CNPq: \"{i}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Valores possíveis de k: {list(range(len(df_areas.index)//600+1))}')\n",
    "k=0\n",
    "n=600\n",
    "df_areas[n*k:(k+1)*n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_areas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compatibilizar CNPq com Áreas de Avaliação CAPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gov.br/capes/pt-br/acesso-a-informacao/acoes-e-programas/avaliacao/sobre-a-avaliacao/areas-avaliacao/sobre-as-areas-de-avaliacao/sobre-as-areas-de-avaliacao\n",
    "\n",
    "Atualizado em 04/08/2023 12h20 (Acesso em Agosto de 2023)\n",
    "\n",
    "Áreas da Avaliação\n",
    "Com o intuito de facilitar o desenvolvimento das atividades de avaliação, as 49 áreas de avaliação são agregadas, por critério de afinidade, em dois níveis:\n",
    "\n",
    "    • Primeiro nível: Colégios (COLÉGIO DE CIÊNCIAS DA VIDA | COLÉGIO DE HUMANIDADES | COLÉGIO DE CIÊNCIAS EXATAS, TECNOLÓGICAS E MULTIDISCIPLINAR)\n",
    "    • Segundo nível: Grandes Áreas."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://www.gov.br/capes/pt-br/acesso-a-informacao/acoes-e-programas/avaliacao/sobre-a-avaliacao/areas-avaliacao/sobre-as-areas-de-avaliacao/sobre-as-areas-de-avaliacao#areas\n",
    "\n",
    "ÁREAS DE AVALIAÇÃO\n",
    "\n",
    "COLÉGIO DE CIÊNCIAS DA VIDA\n",
    "    Ciências Agrárias\n",
    "        Ciências Agrárias I\n",
    "        Ciência de Alimentos\n",
    "        Medicina Veterinária\n",
    "        Zootecnia/Recursos Pesqueiros\n",
    "\n",
    "    Ciências Biológicas\n",
    "        Biodiversidade\n",
    "        Ciências Biológicas I\n",
    "        Ciências Biológicas II\n",
    "        Ciências Biológicas III\n",
    "\n",
    "    Ciências da Saúde\n",
    "        Educação Física\n",
    "        Enfermagem\n",
    "        Farmácia\n",
    "        Medicina I\n",
    "        Medicina II\n",
    "        Medicina III\n",
    "        Nutrição\n",
    "        Odontologia\n",
    "        Saúde Coletiva\n",
    "\n",
    "COLÉGIO DE HUMANIDADES\n",
    "    CIÊNCIAS HUMANAS\t \t\n",
    "        Antropologia / Arqueologia\n",
    "        Ciência Política e Relações Internacionais\n",
    "        Ciências da Religião e Teologia\n",
    "        Educação\n",
    "        Filosofia\n",
    "        Geografia\n",
    "        História\n",
    "        Psicologia\n",
    "        Sociologia\n",
    "\n",
    "    CIÊNCIAS SOCIAIS APLICADAS\t \t\n",
    "        Administração Pública e de Empresas, Ciências Contábeis e Turismo\n",
    "        Arquitetura, Urbanismo e Design\n",
    "        Comunicação e Informação\n",
    "        Direito\n",
    "        Economia\n",
    "        Planejamento Urbano e Regional / Demografia\n",
    "        Serviço Social\n",
    "\n",
    "    LINGUÍSTICA, LETRAS E ARTES\n",
    "\t \t Artes\n",
    "\t \t Linguística e Literatura\n",
    "\n",
    "\n",
    "COLÉGIO DE CIÊNCIAS EXATAS, TECNOLÓGICAS E MULTIDISCIPLINAR\n",
    "    CIÊNCIAS EXATAS E DA TERRA\n",
    "        Astronomia / Física\n",
    "        Ciência da Computação\n",
    "        Geociências\n",
    "        Matemática / Probabilidade e Estatística\n",
    "        Química\n",
    "\n",
    "    ENGENHARIAS\n",
    "        Engenharias I\n",
    "        Engenharias II\n",
    "        Engenharias III\n",
    "        Engenharias IV\n",
    "\n",
    "    MULTIDISCIPLINAR\n",
    "        Biotecnologia\n",
    "        Ciências Ambientais\n",
    "        Ensino\n",
    "        Interdisciplinar\n",
    "        Materiais"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Montar a interação com as áras de avaliação da CAPES\n",
    "\n",
    "    1.00.00.00-3        Ciências exatas e da Terra\n",
    "        ÁREA DE AVALIAÇÃO: MATEMÁTICA / PROBABILIDADE E ESTATÍSTICA\n",
    "            1.01.00.00-8    Matemática\n",
    "            1.02.00.00-2    Probabilidade e Estatística\n",
    "\n",
    "        ÁREA DE AVALIAÇÃO: CIÊNCIA DA COMPUTAÇÃO\n",
    "            1.03.00.00-7    Ciência da Computação\n",
    "        \n",
    "        ÁREA DE AVALIAÇÃO: ASTRONOMIA / FÍSICA \n",
    "            1.04.00.00-1    Astronomia\n",
    "            1.05.00.00-6\tFísica\n",
    "\n",
    "        ÁREA DE AVALIAÇÃO: QUÍMICA\n",
    "            1.06.00.00-0\tQuímica\n",
    "\n",
    "        ÁREA DE AVALIAÇÃO: GEOCIÊNCIAS\n",
    "            1.07.00.00-5\tGeoCiências\n",
    "\n",
    "    2.00.00.00-6\tCiências Biológicas\n",
    "        ÁREA DE AVALIAÇÃO: CIÊNCIAS BIOLÓGICAS I\n",
    "            1.08.00.00-0\tOceanografia\n",
    "            \n",
    "            2.01.00.00-0\tBiologia Geral\n",
    "        \n",
    "            2.02.00.00-5\tGenética\n",
    "\n",
    "            2.03.00.00-0\tBotânica    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Estudar recortes de grupos de pessoas para análise</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listar/extrair dados servidores doutores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ler o arquivo Excel usando apenas as colunas selecionadas\n",
    "fioce_pessoal = pd.read_excel(pathzip+'fioce_colaboradores-2023.xls', skiprows=3, header=0, usecols=selected_columns)\n",
    "fioce_pessoal['NOME'] = fioce_pessoal['NOME'].str.strip()\n",
    "\n",
    "filtro1=fioce_pessoal.VÍNCULO=='SERVIDOR'\n",
    "fioce_pessoal = fioce_pessoal[filtro1]\n",
    "\n",
    "filtro2=fioce_pessoal.STATUS=='ATIVO'\n",
    "fioce_pessoal = fioce_pessoal[filtro2]\n",
    "\n",
    "filtro_combinado = (fioce_pessoal['NÍVEL'] == 'DOUTORADO') | (fioce_pessoal['NÍVEL'] == 'PHD ')\n",
    "fioce_pessoal_doutores = fioce_pessoal[filtro_combinado]\n",
    "\n",
    "lista_servidores_doutores = fioce_pessoal_doutores['NOME']\n",
    "lista_servidores_doutores.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Retirar os currículos que não tem artigos publicados\n",
    "# retirar_doutores  = ['Dayane Alves Costa']\n",
    "\n",
    "# ## Montar lista que será buscada no Lattes\n",
    "# lista_servidores_doutores = [item for item in lista_servidores_doutores if item not in retirar_doutores]\n",
    "# print(f'{len(lista_servidores_doutores)} servidores com doutorado a extrair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# t_ini=time.time()\n",
    "# df_secoes_doutores, sucesso_doutores, json_data = extrair_dados(lista_servidores_doutores, mestres=False, assunto=False)\n",
    "\n",
    "# print('-'*50)\n",
    "# print(tempo(t_ini,time.time()), 'Tempo extração dados do currículo')\n",
    "# print(f'{len(sucesso_doutores)/len(lista_servidores_doutores)*100:.2f}% de sucesso na extração dos servidores com doutorado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_secoes_doutores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos_doutores = listar_artigos(df_secoes_doutores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos_doutores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_contagem_artigos = contar_artigos(df_artigos_doutores)\n",
    "# df_contagem_artigos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listar/extrair servidores ativos, nível mestrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ler o arquivo Excel usando apenas as colunas selecionadas\n",
    "# fioce_pessoal = pd.read_excel(pathzip+'fioce_colaboradores-2023.xls', skiprows=3, header=0, usecols=selected_columns)\n",
    "# fioce_pessoal['NOME'] = fioce_pessoal['NOME'].str.strip()\n",
    "\n",
    "# filtro1=fioce_pessoal.VÍNCULO=='SERVIDOR'\n",
    "# fioce_pessoal = fioce_pessoal[filtro1]\n",
    "\n",
    "# filtro2=fioce_pessoal.STATUS=='ATIVO'\n",
    "# fioce_pessoal = fioce_pessoal[filtro2]\n",
    "\n",
    "# filtro3=fioce_pessoal.NÍVEL=='MESTRADO'\n",
    "# fioce_pessoal = fioce_pessoal[filtro3]\n",
    "\n",
    "# lista_servidores_mestres = fioce_pessoal['NOME']\n",
    "# lista_servidores_mestres.sort_values()\n",
    "\n",
    "# print(f'{len(lista_servidores_mestres)} servidores com, no máximo, mestrado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Retirar os currículos que não tem artigos publicados\n",
    "# retirar_mestres = ['Bruno Bezerra Carvalho',\n",
    "#                    'Luis Fernando Pessoa De Andrade']\n",
    "\n",
    "# lista_servidores_mestres = [item for item in lista_servidores_mestres if item not in retirar_mestres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'{len(lista_servidores_mestres)} currículos de mestres associados à Fiocruz Ceará em 2023')\n",
    "# for n,i in enumerate(lista_servidores_mestres):\n",
    "#     print(f'{n:2}: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# t_ini=time.time()\n",
    "# df_secoes_mestres, sucesso_mestres, json_data = extrair_dados(lista_servidores_mestres, mestres=True, assunto=False)\n",
    "\n",
    "# print('-'*50)\n",
    "# print(tempo(t_ini,time.time()), 'Tempo extração dados do currículo')\n",
    "# print(f'{len(sucesso_mestres)/len(lista_servidores_mestres)*100:.2f}% de sucesso na extração dos servidores com mestrado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos_mestres = montar_publicacoes(df_secoes_mestres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos_mestres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_artigos_mestres.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos_mestres['CURRICULO'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unir os dois grupos de formação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'{len(df_secoes_mestres.index):4} linhas de dados de {len(lista_servidores_mestres)} mestres')\n",
    "# print(f'{len(df_secoes_doutores.index)} linhas de dados de {len(lista_servidores_doutores)} doutores')\n",
    "# df_secoes = pd.concat([df_secoes_mestres, df_secoes_doutores], ignore_index=True)\n",
    "# print(f'{len(df_secoes.index)} linhas de dados de {len(lista_servidores_mestres)+len(lista_servidores_doutores)} servidores no total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_secoes[:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_secoes.to_csv(pathout+'df_secoes_doutores_mestres.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_secoes[df_secoes['ROTULOS']=='Nome'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # pathout='C:/kgfioce/output/'\n",
    "# df_secoes_doutores_mestres = pd.read_csv(pathout+'df_secoes_doutores_mestres.csv', sep=\";\")\n",
    "# print(len(df_secoes_doutores_mestres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_servidores_doutorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_servidores_mestrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montar lista de Publicadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retirar os currículos que não tem artigos publicados, adicionar mestres com mais de 02 participações em publicações\n",
    "# lista_publicadores = []\n",
    "# retirar_doutores   = ['Dayane Alves Costa','Luciana Coelho Serafim']\n",
    "# adicionar_mestres  = ['Anna Carolina Machado Marinho', 'Claudia Stutz Zubieta','Luciana Silvério Alleluia Higino Da Silva','Marlos De Medeiros Chaves']\n",
    "\n",
    "# # Montar lista que será buscada no Lattes\n",
    "# for i in lista_servidores_doutorado:\n",
    "#     if i not in retirar_doutores:\n",
    "#         lista_publicadores.append(i)\n",
    "\n",
    "# for i in adicionar_mestres:\n",
    "#     lista_publicadores.append(i)\n",
    "\n",
    "# print(f'{len(lista_publicadores)} currículos de mestres/doutores associados à Fiocruz Ceará em 2023, com mais de 02 participações em artigos')\n",
    "# for n,i in enumerate(lista_publicadores):\n",
    "#     print(f'{n:2}: {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# t_ini=time.time()\n",
    "# df_secoes_publicadores, sucesso_publicadores, json_data = extrair_dados(lista_publicadores, mestres=True, assunto=False)\n",
    "\n",
    "# print('-'*50)\n",
    "# print(tempo(t_ini,time.time()), 'Tempo extração dados do currículo')\n",
    "# print(f'Extraídos dados de {len(sucesso_publicadores)}, {len(sucesso_publicadores)/len(lista_publicadores)*100:.2f}% de sucesso na extração dos servidores, com mestrado/doutorado e 02 ou mais participações em artigos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_secoes_publicadores.to_csv(pathout+'df_secoes_publicadores.csv', sep=\";\", index=False)\n",
    "# len(df_secoes_publicadores[df_secoes_publicadores['ROTULOS']=='Nome'].index)\n",
    "\n",
    "# for n,i in enumerate(df_secoes_publicadores['CURRICULO'].unique()):\n",
    "#     print(f'{n+1:2} {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testar extração e montagem da lista de artigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste = ['Fabio Miyajima']\n",
    "# teste = ['Jaime Ribeiro Filho']\n",
    "# teste = ['']\n",
    "# df_secoes_teste, sucesso_teste, json_data = extrair_dados(teste, mestres=True, assunto=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos_teste.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos_teste = montar_publicacoes(df_secoes_teste)\n",
    "# df_artigos_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrair dados de Servidores pesquisadores, ou com artigos no Lattes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # pathout='C:/kgfioce/output/'\n",
    "# df_secoes_publicadores = pd.read_csv(pathout+'df_secoes_publicadores.csv', sep=\";\")\n",
    "# print(len(df_secoes_publicadores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_secoes_publicadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos, curriculo_to_articles = montar_lista_pub(df_secoes_publicadores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar participações artigos publicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def montar_dfpub(df):\n",
    "    filtro  = 'Artigos completos publicados em periódicos'\n",
    "    artigos = df[(df.ROTULOS == filtro)]\n",
    "    print(f'Total de linhas de dados: {len(artigos)}')\n",
    "\n",
    "    nomes   = df[df.ROTULOS=='Nome'].values\n",
    "    print(f'Total de servidores: {len(nomes)}')  \n",
    "\n",
    "    # Initialize lists to populate DataFrame\n",
    "    curriculos = []\n",
    "    dados_publ = []\n",
    "    artigos_list = []\n",
    "    autores_list = []\n",
    "\n",
    "    remover = ['Ordenar por','Ordem Cronológica','Número de citações Web of science',\n",
    "               'Número de citações Scopus','Numero de citações Scielo','Primeiro autor',\n",
    "               'Impacto JCR','Ordem de Importância','Livros publicados/organizados ou edições']\n",
    "\n",
    "    for n, row in artigos.iterrows():\n",
    "        linha = row['CONTEUDOS']\n",
    "        curriculo = row['CURRICULO']\n",
    "\n",
    "        for i in eval(linha):\n",
    "            if i not in remover and len(i) > 15 and 'Citações:' not in i:\n",
    "                curriculos.append(curriculo)\n",
    "                dados_publ.append(i)\n",
    "                try:\n",
    "                    parts = i.split(' . ')\n",
    "                    if len(parts) == 2:\n",
    "                        autores_list = parts[0]\n",
    "                        autores_list = parts[1]\n",
    "                    else:\n",
    "                        autores_list = ''\n",
    "                        autores_list = ''\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "    # Create DataFrame with 'CURRICULO' as the index\n",
    "    df_publicacoes = pd.DataFrame({\n",
    "        'CURRICULO': curriculos,\n",
    "        'ARTIGOS': dados_publ,\n",
    "        'AUTORES': autores_list,\n",
    "        'ARTIGO': artigos_list,\n",
    "    }).set_index('CURRICULO')\n",
    "\n",
    "    return df_publicacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def montar_lista_pub(df):\n",
    "    filtro = 'Artigos completos publicados em periódicos'\n",
    "    artigos = df[(df.ROTULOS == filtro)]\n",
    "\n",
    "    # Initialize lists to hold DataFrame data\n",
    "    curriculos = []\n",
    "    artigos_list = []\n",
    "    anos_pub = []\n",
    "\n",
    "    # Initialize dictionary to hold curriculo to row mapping\n",
    "    curriculo_to_articles = {}\n",
    "\n",
    "    remover = ['Ordenar por', 'Ordem Cronológica', 'Número de citações Web of science',\n",
    "               'Número de citações Scopus', 'Numero de citações Scielo', 'Primeiro autor',\n",
    "               'Impacto JCR', 'Ordem de Importância', 'Livros publicados/organizados ou edições']\n",
    "\n",
    "    for n, row in artigos.iterrows():\n",
    "        linha = row['CONTEUDOS']\n",
    "        curriculo = row['CURRICULO']\n",
    "        artigos_temp = []  # Temporary list to hold articles for the current curriculum\n",
    "\n",
    "        for i in eval(linha):\n",
    "            if i not in remover and len(i) > 15 and 'Citações:' not in i:\n",
    "                # Extract year of publication using regex\n",
    "                match = re.search(r'\\d{4}\\.$', i)\n",
    "                if match:\n",
    "                    ano_pub = match.group().strip('.')\n",
    "                    anos_pub.append(int(ano_pub))\n",
    "                else:\n",
    "                    anos_pub.append(None)\n",
    "\n",
    "                curriculos.append(curriculo)\n",
    "                artigos_list.append(i)\n",
    "                artigos_temp.append(i)\n",
    "        \n",
    "        # Update the dictionary with the current row of articles\n",
    "        curriculo_to_articles[curriculo] = artigos_temp\n",
    "\n",
    "    # Create DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        'CURRICULO': curriculos,\n",
    "        'ARTIGO': artigos_list,\n",
    "        'ANO_PUB': anos_pub\n",
    "    })\n",
    "    \n",
    "    # Set CURRICULO as the index\n",
    "    output_df.set_index('CURRICULO', inplace=True)\n",
    "\n",
    "    return output_df, curriculo_to_articles\n",
    "\n",
    "# Example usage\n",
    "# df = pd.read_csv(\"your_dataframe.csv\")\n",
    "# output_df, curriculo_to_articles = montar_lista_pub(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_publicacoes = montar_dfpub(df_secoes_publicadores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos, curriculo_to_articles = montar_lista_pub(df_secoes_publicadores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos_doutores_mestres, curriculo_to_articles_doutores_mestres = montar_lista_pub(df_secoes_doutores_mestres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curriculo_to_articles_doutores_mestres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos_doutores_mestres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pathout=\"C:/kgfioce/output/\"\n",
    "df_secoes_servidores = pd.read_csv(pathout+'df_secoes_servidores.csv', sep=\";\")\n",
    "df_artigos_servidores, curriculo_to_articles_servidores = montar_lista_pub(df_secoes_servidores)\n",
    "print(len(df_artigos_servidores.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotbar_tudo(df_artigos):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Contagem do número de artigos para cada 'CURRICULO'\n",
    "    article_counts = df_artigos.index.value_counts()\n",
    "    \n",
    "    # Cálculo da soma total de artigos\n",
    "    total_articles = article_counts.sum()\n",
    "\n",
    "    # Criação do gráfico de barras\n",
    "    plt.figure(figsize=(19, 12))\n",
    "    ax = article_counts.plot(kind='bar', color='skyblue')\n",
    "\n",
    "    # Adição dos rótulos de colunas\n",
    "    for i, value in enumerate(article_counts):\n",
    "        plt.text(i, value + 0.5, str(value), ha='center', va='bottom')\n",
    "\n",
    "    # Adição do rótulo centralizado com a soma total de artigos\n",
    "    plt.annotate(f'Total de Artigos: {total_articles}', xy=(0.5, 0.95), xycoords='axes fraction',\n",
    "                 fontsize=24, ha='center', va='center')\n",
    "    \n",
    "    # Configurações adicionais\n",
    "    plt.xlabel('CURRICULO')\n",
    "    plt.ylabel('Quantidade de Artigos')\n",
    "    plt.title('Quantidade de participações em artigos por currículo de servidores, em qualquer tempo', fontsize=24)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotbar_tudo(df_artigos_servidores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrar por datas de ingresso na Fiocruz Ceará"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fioce_pessoal['INGRESSO_FIOCE'] = pd.to_datetime(fioce_pessoal['INGRESSO_FIOCE'])\n",
    "\n",
    "# Certificando-se de que 'INGRESSO_FIOCE' é do tipo int (se for data no formato yyyy, por exemplo)\n",
    "fioce_pessoal['ANO_INGRESSO_FIOCE'] = fioce_pessoal['INGRESSO_FIOCE'].dt.year\n",
    "\n",
    "# Merge entre df_artigos e fioce_pessoal usando 'AUTORES' e 'NOME' como chaves\n",
    "merged_df = df_artigos_servidores.merge(fioce_pessoal, left_on='CURRICULO', right_on='NOME', how='inner')\n",
    "\n",
    "# Filtrar as linhas de acordo com a condição do ano de publicação e da data de ingresso\n",
    "df_artigos_servidores_ingresso_fioce = merged_df[merged_df['ANO_PUB'] >= merged_df['ANO_INGRESSO_FIOCE']]\n",
    "\n",
    "# Opcional: Dropar colunas redundantes ou não necessárias, por exemplo, 'NOME' que é igual a 'AUTORES'\n",
    "# result_df = result_df.drop(columns=['NOME'])\n",
    "\n",
    "# Agora, result_df é o dataframe final desejado\n",
    "df_artigos_servidores_ingresso_fioce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artigos_servidores_ingresso_fioce.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_df = parse_dataframe(df_artigos_servidores_ingresso_fioce)\n",
    "teste_df.iloc[:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the list of columns you are interested in\n",
    "selected_columns = ['NOME','MATRÍCULA','ARTIGO', 'ÁREA', 'ANO_PUB', 'ANO_INGRESSO_FIOCE']\n",
    "\n",
    "# Create a new DataFrame containing only the selected columns\n",
    "df_servidores_ingresso_fioce = df_artigos_servidores_ingresso_fioce[selected_columns]\n",
    "df_servidores_ingresso_fioce.rename(columns={'ÁREA': 'SETOR_FIOCE'}, inplace=True)\n",
    "df_servidores_ingresso_fioce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the DataFrame to Excel\n",
    "df_artigos_servidores_ingresso_fioce.to_excel(pathout+\"df_artigos_servidores_ingresso_fioce.xlsx\", sheet_name='FiocruzCeara', index=False)\n",
    "df_artigos_servidores_ingresso_fioce.to_csv(pathout+\"df_artigos_servidores_ingresso_fioce.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artigos = montar_publicacoes(df_secoes_servidores)\n",
    "print(len(df_artigos.index))\n",
    "df_artigos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artigos = montar_publicacoes(df_secoes_servidores)\n",
    "\n",
    "# Converta strings vazias para NaN\n",
    "df_artigos['ANO_PUB'].replace('', pd.NA, inplace=True)\n",
    "\n",
    "# Preencha NaN com 0\n",
    "df_artigos['ANO_PUB'].fillna(0, inplace=True)\n",
    "\n",
    "# Agora converta a coluna para int\n",
    "df_artigos['ANO_PUB'] = df_artigos['ANO_PUB'].astype(int)\n",
    "\n",
    "# Salve o DataFrame\n",
    "df_artigos.to_csv(pathout+'df_artigos.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artigos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes das funções de separação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dicts(teste_dict, verbose=False):\n",
    "    \n",
    "    try:\n",
    "        dict2 = parse_string(teste_dict[\"input\"], verbose)\n",
    "    except Exception as e:\n",
    "        print('Nenhum separador funcionou bem para o caso:')\n",
    "        print(e)\n",
    "        print(teste_dict)\n",
    "        return -1.0  # Retorna -1.0 em caso de erro\n",
    "\n",
    "    dict1 = teste_dict[\"expected_output\"]\n",
    "    indices = len(dict1.keys())\n",
    "    sucesso = 0\n",
    "    desvios = 0\n",
    "    lenght = 75\n",
    "    for key in dict1.keys() & dict2.keys():  # Intersecção de chaves dos dois dicionários\n",
    "        if dict1[key] != dict2[key]:\n",
    "            desvios += 1\n",
    "            if verbose:\n",
    "                print('-' * lenght)\n",
    "                print('FALHOU na divisão de:')\n",
    "                print(f'Campo \"{key}\":')\n",
    "                print(f'   Esperado: {dict1[key]}')\n",
    "                print(f'     Obtido: {dict2[key]}')\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('-' * lenght)\n",
    "                print('SUCESSO na divisão de:')\n",
    "                print(f'Campo \"{key}\":')\n",
    "                print(f'   Esperado: {dict1[key]}')\n",
    "                print(f'     Obtido: {dict2[key]}')\n",
    "            sucesso += 1\n",
    "    \n",
    "    percentual_sucesso = f'{sucesso / indices * 100:.2f}'\n",
    "    \n",
    "    return percentual_sucesso\n",
    "\n",
    "\n",
    "def run_testes(test_dict, verbose=False):\n",
    "    resultados = {}\n",
    "    if not isinstance(test_dict, dict):\n",
    "        print(\"O parâmetro deve ser um dicionário\")\n",
    "        return resultados\n",
    "    \n",
    "    for name, value in test_dict.items():\n",
    "        result = compare_dicts(value, verbose)\n",
    "        if result is not None:  # Verifica se o resultado é None\n",
    "            print(f'Resultado do teste {name:3}: {result}% de conformidade entre obtido e esperado')\n",
    "            resultados[name] = float(result)\n",
    "        else:\n",
    "            print(f'Falha ao executar o teste {name}')\n",
    "            \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dictionary = {\n",
    "    \"t1\": {\n",
    "        'input': \"PEREIRA, F. O. ; ARRUA, J. M. M. ; RIBEIRO-FILHO, J. . In vitro and ex vivo antibiofilm activity of riparin 1, and its nor and dinor homologs, against dermatophytes. MYCOLOGIA, p. 1-10, 2023.\",\n",
    "        'expected_output': {\n",
    "            'authors': ['PEREIRA, F. O.', 'ARRUA, J. M. M.', 'RIBEIRO-FILHO, J.'],\n",
    "            'title': 'In vitro and ex vivo antibiofilm activity of riparin 1, and its nor and dinor homologs, against dermatophytes',\n",
    "            'journal': 'MYCOLOGIA',\n",
    "            'local': '',\n",
    "            'volume': '',\n",
    "            'page': '1-10',\n",
    "            'year': '2023'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"t2\": {\n",
    "        'input':\"VIEIRA-MEYER, Anya Pimentel Gomes Fernandes. RAIZES E PONTES NO FORTALECIMENTO DO SUS. Revista da ESP, v. 17, p. e1712, 2023.\",\n",
    "        'expected_output': {\n",
    "            'authors': ['VIEIRA-MEYER, Anya Pimentel Gomes Fernandes'],\n",
    "            'title': 'RAIZES E PONTES NO FORTALECIMENTO DO SUS',\n",
    "            'journal': 'Revista da ESP',\n",
    "            'local': '',\n",
    "            'volume': '17',\n",
    "            'page': 'e1712',\n",
    "            'year': '2023'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"t3\": {\n",
    "        'input':\"Nicolete, Roberto; Rius, Cristina ; Piqueras, Laura ; Jose, Peter J ; Sorgi, Carlos A ; Soares, Edson G ; Sanz, Maria J ; Faccioli, Lúcia H . Leukotriene B4-loaded microspheres: a new therapeutic strategy to modulate cell activation, v. 9, p. 36, 2008.\",\n",
    "        'expected_output': {\n",
    "            'authors': ['Nicolete, Roberto', 'Rius, Cristina', 'Piqueras, Laura','Jose, Peter J', 'Sorgi, Carlos A', 'Soares, Edson G', 'Sanz, Maria J', 'Faccioli, Lúcia H'],\n",
    "            'title': 'Leukotriene B4-loaded microspheres: a new therapeutic strategy to modulate cell activation',\n",
    "            'journal': '',\n",
    "            'local': '',\n",
    "            'volume': '9',\n",
    "            'page': '36',\n",
    "            'year': '2008'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"t4\": {\n",
    "        'input':\"TELES, Y. C. F. ; RIBEIRO-FILHO, J. ; BOZZA, Patrícia T. ; AGRA, M. F. ; SIHERI, W. ; IGOLI, J. O. ; GRAY, A. I. ; SOUZA, M. F. V. . Phenolic constituents from (L.) C. Presl. and anti-inflammatory activity of 7,4--di- -methylisoscutellarein. Natural Product Research (Print), p. 1-5, 2015.\",\n",
    "        'expected_output': {\n",
    "            'authors': ['TELES, Y. C. F.', 'RIBEIRO-FILHO, J.', 'BOZZA, Patrícia T.', 'AGRA, M. F.', 'SIHERI, W.', 'IGOLI, J. O.', 'GRAY, A. I.', 'SOUZA, M. F. V.'],\n",
    "            'title': 'Phenolic constituents from (L.) C Presl and anti-inflammatory activity of 7,4--di- -methylisoscutellarein',\n",
    "            'journal': 'Natural Product Research (Print)',\n",
    "            'local': '',\n",
    "            'volume': '',\n",
    "            'page': '1-5',\n",
    "            'year': '2015'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"t5\": {\n",
    "        'input':\"BILD, N. ; CHAPEAUROUGE, D. A. ; GFELLER, S. ; BIENZ, S. . The [M-1]+ quasi-molecular Ion in Chemical Ionization Mass Spectrometry, Fragmentation of Bis (benzyloxy) silanes by Intramolecular Reactions. Org. Mass Spectrom., v. 27, p. 896-900, 1992.\",\n",
    "        'expected_output': {\n",
    "            'authors': ['BILD, N.', 'CHAPEAUROUGE, D. A.', 'GFELLER, S.','BIENZ, S.'],\n",
    "            'title': 'The [M-1]+ quasi-molecular Ion in Chemical Ionization Mass Spectrometry, Fragmentation of Bis (benzyloxy) silanes by Intramolecular Reactions',\n",
    "            'journal': 'Mass Spectrom',\n",
    "            'local': '',\n",
    "            'volume': '27',\n",
    "            'page': '896-900',\n",
    "            'year': '1992'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"t6\": {\n",
    "        'input':\"DARUGE, E. ; MIYAJIMA, F. ; PARANHOS, L. R. ; DUZ, S. . Identificação Humana por meio de Superposição de Imagens: Caso Clínico. JBC. Jornal Brasileiro de Clínica & Estética em Odontologia, Curitiba - PR, v. 3, n.Mar/Abr, p. 90-96, 1999.\",\n",
    "        'expected_output': {\n",
    "            'authors': ['DARUGE, E.', 'MIYAJIMA, F.', 'PARANHOS, L. R.','DUZ, S.'],\n",
    "            'title': 'Identificação Humana por meio de Superposição de Imagens: Caso Clínico',\n",
    "            'journal': 'Jornal Brasileiro de Clínica & Estética em Odontologia',\n",
    "            'local': 'Curitiba - PR',\n",
    "            'volume': '3',\n",
    "            'page': '90-96',\n",
    "            'year': '1999'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"t7\": {\n",
    "        'input':\"SALOMON, TASSILA BUSS, LEWIS F WHITTAKER, CHARLES PRETE, CARLOS A OIKAWA, MARCIO K PEREIRA, RAFAEL HM MOURA, ISABEL CG DELERINO, LUCAS BARRAL-NETTO, MANOEL TAVARES, NATALIA M FRANCA, RAFAEL FO BOAVENTURA, VIVIANE S MIYAJIMA, FABIO MENDRONE-JUNIOR, ALFREDO DE ALMEIDA-NETO, CESAR SALLES, NANCI A FERREIRA, SUZETE C FLADZINSKI, KARINE A DE SOUZA, LUANA M SCHIER, LUCIANE K INOUE, PATRICIA M XABREGAS, LILYANE A CRISPIM, MYUKI AE FRAIJI, NELSON ARAUJO, FERNANDO LV , et al. ; SARS-CoV-2 antibody dynamics in blood donors and COVID-19 epidemiology in eight Brazilian state capitals: A serial cross-sectional study. eLife, v. 11, p. e78233, 2022.\",\n",
    "        'expected_output': {\n",
    "            'authors': ['SALOMON, TASSILA BUSS, LEWIS F WHITTAKER, CHARLES PRETE, CARLOS A OIKAWA, MARCIO K PEREIRA, RAFAEL HM MOURA, ISABEL CG DELERINO, LUCAS BARRAL-NETTO, MANOEL TAVARES, NATALIA M FRANCA, RAFAEL FO BOAVENTURA, VIVIANE S MIYAJIMA, FABIO MENDRONE-JUNIOR, ALFREDO DE ALMEIDA-NETO, CESAR SALLES, NANCI A FERREIRA, SUZETE C FLADZINSKI, KARINE A DE SOUZA, LUANA M SCHIER, LUCIANE K INOUE, PATRICIA M XABREGAS, LILYANE A CRISPIM, MYUKI AE FRAIJI, NELSON ARAUJO, FERNANDO LV , et al'],\n",
    "            'title': 'SARS-CoV-2 antibody dynamics in blood donors and COVID-19 epidemiology in eight Brazilian state capitals: A serial cross-sectional study',\n",
    "            'journal': 'eLife',\n",
    "            'local': '',\n",
    "            'volume': '11',\n",
    "            'page': 'e78233',\n",
    "            'year': '2022'\n",
    "        }\n",
    "    }, \n",
    "\n",
    "    \"t8\": {\n",
    "        'input':\"PEREIRA, F. O. ; ARRUA, J. M. M. ; RIBEIRO-FILHO, J. . In vitro and ex vivo antibiofilm activity of riparin 1, and its nor and dinor homologs, against dermatophytes. MYCOLOGIA, p. 1-10, 2023.\",\n",
    "        'expected_output': {\n",
    "            'authors': ['PEREIRA, F. O.', 'ARRUA, J. M. M.', 'RIBEIRO-FILHO, J.'],\n",
    "            'title': 'In vitro and ex vivo antibiofilm activity of riparin 1, and its nor and dinor homologs, against dermatophytes',\n",
    "            'journal': 'MYCOLOGIA',\n",
    "            'local': '',\n",
    "            'volume': '',\n",
    "            'page': '1-10',\n",
    "            'year': '2023'\n",
    "        }\n",
    "    },       \n",
    "\n",
    "    \"t9\": {\n",
    "        'input':\"MARTIN, A. L. A. R. ; PEREIRA, R. L. S. ; RIBEIRO-FILHO, J. ; MENEZES, I. R. A. ; COUTINHO, H. D. M. ; FONTELES, M. M. F. . In vitro and in silico evidences about the inhibition of MepA efflux pump by coumarin derivatives. MICROBIAL PATHOGENESIS, p. 106246, 2023.\",\n",
    "        'expected_output': {\n",
    "            'authors': ['MARTIN, A. L. A. R.', 'PEREIRA, R. L. S.', 'RIBEIRO-FILHO, J.', 'MENEZES, I. R. A.', 'COUTINHO, H. D. M.', 'FONTELES, M. M. F.'],\n",
    "            'title': 'In vitro and in silico evidences about the inhibition of MepA efflux pump by coumarin derivatives',\n",
    "            'journal': 'MICROBIAL PATHOGENESIS',\n",
    "            'local': '',\n",
    "            'volume': '',\n",
    "            'page': '106246',\n",
    "            'year': '2023'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"t10\": {\n",
    "        'input':\"TALKOWSKI, MICHAEL E. MCCANN, KATHLEEN L. CHEN, MICHAEL MCCLAIN, LORA BAMNE, MIKHIL WOOD, JOEL CHOWDARI, KODAVALI V. WATSON, ANNIE PRASAD, KONASALE M. KIROV, GEORGE GEORGIEVA, LYUDMILLA TONCHEVA, DRAGA MANSOUR, HADER LEWIS, DAVID A. OWEN, MICHAEL O'DONOVAN, MICHAEL PAPASAIKAS, PANAGIOTIS SULLIVAN, PATRICK RUDERFER, DOUGLAS YAO, JEFFREY K LEONARD, SHERRY THOMAS, PRAMOD MIYAJIMA, FABIO QUINN, JOHN LOPEZ, A. JAVIER , et al. ; Fine-mapping reveals novel alternative splicing of the dopamine transporter. American Journal of Medical Genetics. Part B, Neuropsychiatric Genetics, v. 153B, p. 1434-1447, 2010.\",\n",
    "        'expected_output': {\n",
    "            'authors': [\"TALKOWSKI, MICHAEL E. MCCANN, KATHLEEN L. CHEN, MICHAEL MCCLAIN, LORA BAMNE, MIKHIL WOOD, JOEL CHOWDARI, KODAVALI V. WATSON, ANNIE PRASAD, KONASALE M. KIROV, GEORGE GEORGIEVA, LYUDMILLA TONCHEVA, DRAGA MANSOUR, HADER LEWIS, DAVID A. OWEN, MICHAEL O'DONOVAN, MICHAEL PAPASAIKAS, PANAGIOTIS SULLIVAN, PATRICK RUDERFER, DOUGLAS YAO, JEFFREY K LEONARD, SHERRY THOMAS, PRAMOD MIYAJIMA, FABIO QUINN, JOHN LOPEZ, A. JAVIER , et al\"],\n",
    "            'title': 'Fine-mapping reveals novel alternative splicing of the dopamine transporter',\n",
    "            'journal': 'American Journal of Medical Genetics. Part B, Neuropsychiatric Genetics',\n",
    "            'local': '',\n",
    "            'volume': '153B',\n",
    "            'page': '1434-1447',\n",
    "            'year': '2010'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"t11\": {\n",
    "        'input':\"DA SILVA, LUCAS YURE SANTOS ; PAULO, CICERA LAURA ROQUE ; MOURA, TALYSSON FELISMINO ; ALVES, DANIEL SAMPAIO ; PESSOA, RENATA TORRES ; ARAÚJO, ISAAC MOURA ; DE MORAIS OLIVEIRA-TINTINO, CÍCERA DATIANE ; TINTINO, SAULO RELISON ; NONATO, CARLA DE FATIMA ALVES ; DA COSTA, JOSÉ GALBERTO MARTINS ; RIBEIRO-FILHO, JAIME ; COUTINHO, HENRIQUE DOUGLAS MELO ; KOWALSKA, GRA'YNA ; MITURA, PRZEMYS'AW ; BAR, MAREK ; KOWALSKI, RADOS'AW ; MENEZES, IRWIN ROSE ALENCAR DE . Antibacterial Activity of the Essential Oil of Piper tuberculatum Jacq. Fruits against Multidrug-Resistant Strains: Inhibition of Efflux Pumps and β-Lactamase. PLANTS, v. 12, p. 2377, 2023.\",\n",
    "        'expected_output': {\n",
    "            'authors': [\"DA SILVA, LUCAS YURE SANTOS ; PAULO, CICERA LAURA ROQUE ; MOURA, TALYSSON FELISMINO ; ALVES, DANIEL SAMPAIO ; PESSOA, RENATA TORRES ; ARAÚJO, ISAAC MOURA ; DE MORAIS OLIVEIRA-TINTINO, CÍCERA DATIANE ; TINTINO, SAULO RELISON ; NONATO, CARLA DE FATIMA ALVES ; DA COSTA, JOSÉ GALBERTO MARTINS ; RIBEIRO-FILHO, JAIME ; COUTINHO, HENRIQUE DOUGLAS MELO ; KOWALSKA, GRA'YNA ; MITURA, PRZEMYS'AW ; BAR, MAREK ; KOWALSKI, RADOS'AW ; MENEZES, IRWIN ROSE ALENCAR DE\"],\n",
    "            'title': 'Antibacterial Activity of the Essential Oil of Piper tuberculatum Jacq. Fruits against Multidrug-Resistant Strains: Inhibition of Efflux Pumps and β-Lactamase',\n",
    "            'journal': 'PLANTS',\n",
    "            'local': '',\n",
    "            'volume': '12',\n",
    "            'page': '2377',\n",
    "            'year': '2023'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"t12\": {\n",
    "        'input':\"MIYAJIMA, F.; OLLIER, W. ; MAYES, A. ; JACKSON, A. ; THACKER, N. ; RABBITT, P. ; Pendleton, N. ; HORAN, M. ; PAYTON, A. . Brain-derived neurotrophic factor polymorphism Val66Met influences cognitive abilities in the elderly. GENES, BRAIN AND BEHAVIOR (ONLINE), v. ON, p. 31/10/2007, 2007.\",\n",
    "        'expected_output': {\n",
    "            'authors': [\"MIYAJIMA, F.; OLLIER, W. ; MAYES, A. ; JACKSON, A. ; THACKER, N. ; RABBITT, P. ; Pendleton, N. ; HORAN, M. ; PAYTON, A\"],\n",
    "            'title': 'Brain-derived neurotrophic factor polymorphism Val66Met influences cognitive abilities in the elderly',\n",
    "            'journal': 'GENES, BRAIN AND BEHAVIOR (ONLINE)',\n",
    "            'local': '',\n",
    "            'volume': 'ON',\n",
    "            'page': '31/10/2007',\n",
    "            'year': '2007'\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"t13\": {\n",
    "        'input':\"MIYAJIMA, F.; LIMA, V. P. . Exames em DNA: a superestimação da inovação. Revista de Direito (Itatiba), Leme - SP, v. 1, n.2002, p. 63-65, 2002.\",\n",
    "        'expected_output': {\n",
    "            'authors': [\"MIYAJIMA, F.; LIMA, V. P.\"],\n",
    "            'title': 'Exames em DNA: a superestimação da inovação',\n",
    "            'journal': 'Revista de Direito (Itatiba)',\n",
    "            'local': 'Leme - SP',\n",
    "            'volume': '1',\n",
    "            'page': '63-65',\n",
    "            'year': '2002'\n",
    "        }\n",
    "    },                  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_testes(test_dictionary, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa todos os testes e armazena os resultados em 'resultados_todos_testes'\n",
    "resultados_todos_testes = run_testes(test_dictionary)\n",
    "\n",
    "# Filtra os testes que não atingiram 100% de conformidade\n",
    "testes_filtrados = {k: v for k, v in resultados_todos_testes.items() if v < 100.0}\n",
    "\n",
    "# Exibe os testes filtrados\n",
    "print(\"Testes com menos de 100% de conformidade:\", testes_filtrados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_testes(testes_filtrados, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_excecao = {\"t7\": \"SALOMON, TASSILA BUSS, LEWIS F WHITTAKER, CHARLES PRETE, CARLOS A OIKAWA, MARCIO K PEREIRA, RAFAEL HM MOURA, ISABEL CG DELERINO, LUCAS BARRAL-NETTO, MANOEL TAVARES, NATALIA M FRANCA, RAFAEL FO BOAVENTURA, VIVIANE S MIYAJIMA, FABIO MENDRONE-JUNIOR, ALFREDO DE ALMEIDA-NETO, CESAR SALLES, NANCI A FERREIRA, SUZETE C FLADZINSKI, KARINE A DE SOUZA, LUANA M SCHIER, LUCIANE K INOUE, PATRICIA M XABREGAS, LILYANE A CRISPIM, MYUKI AE FRAIJI, NELSON ARAUJO, FERNANDO LV , et al. ; SARS-CoV-2 antibody dynamics in blood donors and COVID-19 epidemiology in eight Brazilian state capitals: A serial cross-sectional study. eLife, v. 11, p. e78233, 2022.\"}\n",
    "\n",
    "run_testes(input_excecao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converta strings vazias para NaN\n",
    "df_artigos['ANO_PUB'].replace('', pd.NA, inplace=True)\n",
    "\n",
    "# Preencha NaN com 0\n",
    "df_artigos['ANO_PUB'].fillna(0, inplace=True)\n",
    "\n",
    "# Agora converta a coluna para int\n",
    "df_artigos['ANO_PUB'] = df_artigos['ANO_PUB'].astype(int)\n",
    "\n",
    "# Salve o DataFrame\n",
    "df_artigos.to_csv(pathout+'df_artigos.csv', sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_servidores_ingresso_fioce.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m,i in enumerate(df_secoes_publicadores['CURRICULO'].unique()):\n",
    "#     if i not in df_artigos['CURRICULO'].unique():\n",
    "#         print(f'Não encontrado nome de: \"{i}\" na lista e artigos montados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos[df_artigos['TITULO'] == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos[600:1200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrar por datas para recorte mestres/doutores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fioce_pessoal['INGRESSO_FIOCE'] = pd.to_datetime(fioce_pessoal['INGRESSO_FIOCE'])\n",
    "\n",
    "# # Certificando-se de que 'INGRESSO_FIOCE' é do tipo int (se for data no formato yyyy, por exemplo)\n",
    "# fioce_pessoal['ANO_INGRESSO_FIOCE'] = fioce_pessoal['INGRESSO_FIOCE'].dt.year\n",
    "\n",
    "# # Merge entre df_artigos e fioce_pessoal usando 'AUTORES' e 'NOME' como chaves\n",
    "# merged_df = df_artigos_doutores_mestres.merge(fioce_pessoal, left_on='CURRICULO', right_on='NOME', how='inner')\n",
    "\n",
    "# # Filtrar as linhas de acordo com a condição do ano de publicação e da data de ingresso\n",
    "# df_doutores_mestres_ingresso_fioce = merged_df[merged_df['ANO_PUB'] >= merged_df['ANO_INGRESSO_FIOCE']]\n",
    "\n",
    "# # Opcional: Dropar colunas redundantes ou não necessárias, por exemplo, 'NOME' que é igual a 'AUTORES'\n",
    "# # result_df = result_df.drop(columns=['NOME'])\n",
    "\n",
    "# # Agora, result_df é o dataframe final desejado\n",
    "# df_doutores_mestres_ingresso_fioce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_doutores_mestres_ingresso_fioce.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the list of columns you are interested in\n",
    "# selected_columns = ['NOME','MATRÍCULA','ARTIGO', 'ÁREA', 'ANO_PUB', 'ANO_INGRESSO_FIOCE']\n",
    "\n",
    "# # Create a new DataFrame containing only the selected columns\n",
    "# df_artigos_doutores_mestres = df_artigos_doutores_mestres[selected_columns]\n",
    "# df_artigos_doutores_mestres.rename(columns={'ÁREA': 'SETOR_FIOCE'}, inplace=True)\n",
    "# df_artigos_doutores_mestres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exporting the DataFrame to Excel\n",
    "# df_artigos_doutores_mestres.to_excel(pathout+\"df_artigos_doutores_mestres.xlsx\", sheet_name='FiocruzCeara', index=False)\n",
    "# df_artigos_doutores_mestres.to_csv(pathout+\"df_artigos_doutores_mestres.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montar recorte de Profissionais Publicadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the list of columns you are interested in\n",
    "# selected_columns = ['NOME','MATRÍCULA','ARTIGO', 'ÁREA', 'ANO_PUB', 'ANO_INGRESSO_FIOCE']\n",
    "\n",
    "# # Create a new DataFrame containing only the selected columns\n",
    "# filtered_df = result_df[selected_columns]\n",
    "# filtered_df.rename(columns={'ÁREA': 'SETOR_FIOCE'}, inplace=True)\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Exporting the DataFrame to Excel\n",
    "# filtered_df.to_excel(pathout+\"artigos_desde_ano_ingresso_fiocruz_ceara.xlsx\", sheet_name='FiocruzCeara', index=False)\n",
    "# filtered_df.to_csv(pathout+\"artigos_desde_ano_ingresso_fiocruz_ceara.csv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(result_df['ARTIGO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publicacoes = result_df['ARTIGO'].to_list()\n",
    "# len(publicacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montar lista específica de nomes para extração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista_busca=[]\n",
    "# for i in lista_servidores_doutores:\n",
    "#     if i != 'Raphael Trevizani Roque De Oliveira':\n",
    "#         lista_busca.append(i)\n",
    "#     else:\n",
    "#         lista_busca.append('Raphael Trevizani')\n",
    "\n",
    "# lista_busca.sort()\n",
    "# # Salvar lista de servidores em arquivo CSV\n",
    "# with open(pathcsv+'lista_servidores-fioce.csv', 'w', newline='') as arquivo:\n",
    "#     escritor = csv.writer(arquivo)\n",
    "#     for item in lista_busca:\n",
    "#         escritor.writerow([item])\n",
    "\n",
    "# # Criar lista de busca com interesse de pesquisa\n",
    "# retirar = ['Carlos Jose Araujo Pinheiro', 'Charles Cerqueira De Abreu', 'Dayane Alves Costa',\n",
    "#            'Ezequiel Valentim De Melo','João Baptista Estabile Neto','Luciano Pinto Zorzanelli',\n",
    "#            'Luciana Coelho Serafim', 'Nilton Luiz Costa Machado','Renato Caldeira De Souza',\n",
    "#            'Sergio Dos Santos Reis']\n",
    "\n",
    "# lista_busca = [item for item in lista_busca if item not in retirar]\n",
    "# with open(pathcsv+'lista_lattes-fioce.csv', 'w', newline='') as arquivo:\n",
    "#     escritor = csv.writer(arquivo)\n",
    "#     for item in lista_busca:\n",
    "#         escritor.writerow([item])\n",
    "\n",
    "# # Ler do arquivo CSV salvo para dataframe\n",
    "# df_busca = pd.read_csv(pathcsv+'lista_lattes-fioce.csv', header=None)\n",
    "# df_busca.columns = ['SERVIDORES_FIOCE']\n",
    "# print(f'{len(df_busca.index)} currículos a extrair')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrair dados visando avaliar edital FUNCAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# ## Arquivos fontes para orientadores FUNCAP\n",
    "# arquivo_qualis     = 'classificações_publicadas_todas_as_areas_avaliacao1672761192111.csv'\n",
    "# lista_orientadores = pd.read_csv(pathcsv+'lista_orientadores.csv')\n",
    "\n",
    "# lista_busca = lista_orientadores['ORIENTADOR'].unique()\n",
    "# lista_busca.sort()\n",
    "# print(f'Total de pesquisadores a extrair: {len(lista_orientadores[1:])}')\n",
    "# for i in lista_busca:\n",
    "#     print('    ',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_artigos(lista_nomes, mestres=True, assunto=False):\n",
    "    '''Extrai todas as informações brutas de publicações (artigos e livros) de cada currículo da Plataforma Lattes do CNPQ\n",
    "     Recebe: Um nome a ser buscado na base do currículo Lattes\n",
    "    Utiliza: Funções: definir_filtros(), montar_dfcolab_linhas()\n",
    "    Retorna: Três dataframes: df_identificacao com dados da identificação; df_dados com dados de todas produções; e df_colabartigos com dados das colaborações em artigos\n",
    "    Autor: Marcos Aires (Jan 2022)\n",
    "    '''\n",
    "    import time\n",
    "    from datetime import date\n",
    "    \n",
    "    # print(f'Iniciada extração de {len(lista_nomes)} currículos')\n",
    "    t0=time.time()\n",
    "    \n",
    "    ## INÍCIO DO SCRIPT DE RASPAGEM DA PÁGINA HTML DO CURRÍCULO LATTES\n",
    "    ## https://www.selenium.dev/documentation/pt-br/webdriver/browser_manipulation/\n",
    "    options   = Options()\n",
    "    # options.add_argument(\"--headless\")\n",
    "    browser   = webdriver.Chrome(options=options)\n",
    "    url_buscaespecialista = 'http://buscatextual.cnpq.br/buscatextual/busca.do?buscarDoutores=true&buscarDemais=false&textoBusca='\n",
    "    browser.get(url_buscaespecialista) # acessa a url de busca do CNPQ   \n",
    "    # browser.set_window_position(2100, 0)\n",
    "    # browser.set_window_size(1096, 1896)\n",
    "    # browser.maximize_window()\n",
    "    \n",
    "    browser.set_window_position(-20, -10)\n",
    "    size          = browser.get_window_size()\n",
    "    width1        = size.get(\"width\")\n",
    "    height1       = size.get(\"height\")\n",
    "    browser.set_window_size(170, 1896)\n",
    "    browser.mouse = webdriver.ActionChains(browser)\n",
    "    \n",
    "    delay   = 10  # seconds \n",
    "    buscas        = []\n",
    "    resultados    = []\n",
    "    \n",
    "    df_dados          = pd.DataFrame()   \n",
    "    rotulos           = []\n",
    "    conteudos         = []\n",
    "    parcial_rotulos   = []\n",
    "    parcial_conteudos = []\n",
    "    sucesso           = []\n",
    "    falhas            = []\n",
    "    impactos = []\n",
    "    linhas_dados = []\n",
    "    artigos = []\n",
    "\n",
    "    df_parcial = pd.DataFrame({     \n",
    "            'NOMES': pd.Series(sucesso),\n",
    "            'ROTULOS': pd.Series(rotulos),\n",
    "            'CONTEUDOS': pd.Series(conteudos),                    \n",
    "        })\n",
    "\n",
    "    t1=time.time()\n",
    "    print(tempo(t0,t1), 'Tempo de conexão ao servidor do CNPq')\n",
    "    time.sleep(0.00001)\n",
    "\n",
    "    count=0\n",
    "    for NOME in lista_nomes:\n",
    "        print('-'*100)\n",
    "        count+=1\n",
    "        t2       = time.time()\n",
    "        tdec     = np.round(t2-t0,2)\n",
    "        restante = len(lista_nomes)-count\n",
    "        print(f'Extraindo currículo {count}/{len(lista_nomes)}. Resta {restante}. Decorrido:{horas(tdec)}. Previsão de término em {horas(np.round(tdec/count,0)*(restante+1))}')\n",
    "        \n",
    "        # Definir filtros para busca de nomes\n",
    "        definir_filtros(browser, mestres, assunto)\n",
    "        preencher_busca(browser, delay, NOME)      \n",
    "        window_before  = browser.current_window_handle\n",
    "        limite=5\n",
    "        ## Clicar no botão abrir currículo e mudar de aba\n",
    "        try:\n",
    "            ## Aguarda, encontra, clica em buscar nome\n",
    "            link_nome    = achar_busca(browser, delay)\n",
    "            nome_buscado = []\n",
    "            nome_achado  = []\n",
    "            nome_buscado.append(NOME)\n",
    "            \n",
    "            if link_nome.text == None:\n",
    "                xpath_nome = '/html/body/form/div/div[4]/div/div/div/div[3]/div/div[3]/ol/li'\n",
    "                # 'Stale file handle'\n",
    "                print('Ainda sem resposta do servidor, tentando novamente...')\n",
    "                retry(WebDriverWait(browser, delay).until(\n",
    "                    EC.element_to_be_clickable((By.XPATH, xpath_nome))),\n",
    "                #    expected_ex_type=ZeroDivisionError, \n",
    "                   wait_ms=200,\n",
    "                   limit=limite, \n",
    "                #    logger=logger, \n",
    "                   on_exhaust=(f'Problema ao acessar ao servidor do CNpQ função definir_filtros(). {limite} tentativas sem sucesso.'))\n",
    "            try:\n",
    "                ActionChains(browser).click(link_nome).perform()\n",
    "                nome_achado.append(link_nome.text)\n",
    "            except:\n",
    "                print(f'Currículo não encontrado para: {NOME}.')\n",
    "                return\n",
    "            \n",
    "            retry(WebDriverWait(browser, delay).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"#idbtnabrircurriculo\"))),\n",
    "                #    expected_ex_type=ZeroDivisionError, \n",
    "                   wait_ms=200,\n",
    "                   limit=limite, \n",
    "                #    logger=logger, \n",
    "                   on_exhaust=(f'Problema ao acessar ao servidor do CNpQ função definir_filtros(). {limite} tentativas sem sucesso.'))   \n",
    "            \n",
    "            btn_abrir_curriculo = WebDriverWait(browser, delay).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"#idbtnabrircurriculo\")))\n",
    "            time.sleep(0.2)\n",
    "            ActionChains(browser).click(btn_abrir_curriculo).perform()\n",
    "\n",
    "            ## Gerenciamento das janelas abertas no browser\n",
    "            WebDriverWait(browser, delay).until(EC.number_of_windows_to_be(2))\n",
    "            window_after = browser.window_handles\n",
    "            new_window   = [x for x in window_after if x != window_before][0]\n",
    "            browser.switch_to.window(new_window)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('Erro',e)\n",
    "            print('Tentando nova requisição ao servidor')\n",
    "            time.sleep(1)\n",
    "            btn_abrir_curriculo = WebDriverWait(browser, delay).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"#idbtnabrircurriculo\")))\n",
    "            ActionChains(browser).click(btn_abrir_curriculo).perform()\n",
    "            WebDriverWait(browser, delay).until(EC.number_of_windows_to_be(2))\n",
    "\n",
    "            ## Gerenciamento das janelas abertas no browser\n",
    "            window_after = browser.window_handles\n",
    "            new_window   = [x for x in window_after if x != window_before][0]\n",
    "            browser.switch_to.window(new_window)\n",
    "            time.sleep(1)\n",
    "\n",
    "        t3=time.time()\n",
    "\n",
    "        ## O objeto elementos_id abaixo é uma lista de elementos onde as informações de identificação estão contidas\n",
    "        # acessado através do marcador xpath='//div[@class=\"infpessoa\"]' no HTML para extrair de cada pesquisador\n",
    "        time.sleep(1)\n",
    "        xpath='//div[@class=\"infpessoa\"]'\n",
    "        WebDriverWait(browser, delay).until(\n",
    "                EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "        elementos_id = browser.find_elements(By.XPATH, xpath)\n",
    "\n",
    "        # Fazer com que a primeira informação para cada pesquisador seja o caminho para sua foto e dados de identificação\n",
    "        try:\n",
    "            css_selector='.foto'\n",
    "            link_foto=WebDriverWait(browser, delay).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, \".foto\"))).get_attribute(\"src\")\n",
    "            rotulos.append('Link Foto:')\n",
    "            conteudos.append(link_foto)            \n",
    "\n",
    "        except Exception as e:\n",
    "            traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "            print('  !!Erro ao extrair imagem do currículo:',e,'\\n', traceback_str)\n",
    "\n",
    "        for i in range(len(elementos_id)):\n",
    "            dados = elementos_id[i].text.split('\\n')\n",
    "            for i in range(len(dados)):\n",
    "                if i==0:\n",
    "                    rotulos.append('Nome completo:')\n",
    "                    conteudos.append(dados[i])\n",
    "                elif 'Bolsista' in dados[i]:\n",
    "                    rotulos.append('Bolsista CNPq:')\n",
    "                    conteudos.append(dados[i])\n",
    "                elif 'Endereço para acessar este CV: ' in dados[i]:\n",
    "                    rotulos.append('Link Currículo:')\n",
    "                    conteudos.append(dados[i].strip('Endereço para acessar este CV: '))\n",
    "                elif 'ID Lattes: ' in dados[i]:\n",
    "                    rotulos.append('ID Lattes:')\n",
    "                    conteudos.append(dados[i].strip('ID Lattes: '))\n",
    "                elif 'Última atualização do currículo em ' in dados[i]:\n",
    "                    rotulos.append('Data atualização:')\n",
    "                    conteudos.append(dados[i].strip('Última atualização do currículo em '))\n",
    "                    dt_atualizacao = dados[i].strip('Última atualização do currículo em ')\n",
    "                    dtt = datetime.strptime(dt_atualizacao, '%d/%m/%Y').date()\n",
    "                    defasagem = (date.today()-dtt).days        \n",
    "\n",
    "        try: \n",
    "            df_temp =pd.DataFrame({\n",
    "                'ROTULOS': pd.Series(rotulos),\n",
    "                'CONTEUDOS': pd.Series(conteudos),\n",
    "                    })\n",
    "            filtro    = 'Link Foto:'\n",
    "            fotos     = df_temp[(df_temp.ROTULOS == filtro)]['CONTEUDOS']\n",
    "            x         = fotos[-1:].index[0]\n",
    "            df_temp.drop(columns=['ROTULOS'], inplace=True)\n",
    "\n",
    "            try:\n",
    "                foto = HTML(df_temp[x:x+1].to_html(escape=False, formatters=dict(CONTEUDOS=path_to_image_html)))\n",
    "                display(foto)\n",
    "                print(f'Atualizado em {dt_atualizacao} há {defasagem:>2} dias | {NOME}')    \n",
    "                \n",
    "\n",
    "            except TimeoutException as t:\n",
    "                print('Demora na conexão com servidor, carregamento da foto cancelado')\n",
    "                traceback_str = ''.join(traceback.format_tb(t.__traceback__))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('Erro ao extrair a foto do pesquisador')\n",
    "            traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "            print(e,traceback_str)\n",
    "        \n",
    "        t4=time.time() \n",
    "\n",
    "        ## TRECHO PARA EXTRAIR DADOS DOS ARTIGOS\n",
    "        try:    \n",
    "            page_source = browser.page_source\n",
    "            soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            print(len(soup.text))\n",
    "            info_spans = soup.find_all('span', class_='informacao-artigo')\n",
    "            for span in info_spans:\n",
    "                linhas_dados.append(span.text)\n",
    "            artigos.append(linhas_dados)\n",
    "\n",
    "            ## Fechar janela do currículo\n",
    "            browser.close()            \n",
    "            \n",
    "            ## Gerenciamento das janelas abertas no browser\n",
    "            todas_janelas = browser.window_handles\n",
    "            browser.switch_to.window(todas_janelas[0])\n",
    "\n",
    "            ## Fechar a janela pop-up\n",
    "            close_popup = WebDriverWait(browser, delay).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, \"//*[@id='idbtnfechar']\")))\n",
    "            close_popup.click()\n",
    "            \n",
    "            # ## Nova Consulta\n",
    "            # try:\n",
    "            #     nova_consulta = WebDriverWait(browser, delay).until(\n",
    "            #         EC.element_to_be_clickable((By.XPATH, \"//*[@id='botaoBuscaFiltros']\")))\n",
    "            #     nova_consulta.click()\n",
    "            #     time.sleep(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Erro ao reiniciar consulta')\n",
    "                traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "                print(e,traceback_str) \n",
    "            \n",
    "            t5=time.time()                       \n",
    "\n",
    "            # print(f' {tempo(t0,t5)} | Tempo de Acesso |  Identificação |   Dados Brutos | Subtotal Tempo | Acumulado')\n",
    "            # print(f'  Decorrido  |   {tempo(t2,t3)}   |  {tempo(t3,t4)}   |  {tempo(t4,t5)}   |  {tempo(t2,t5)}   | {len(conteudos)} seções')\n",
    "            \n",
    "            sucesso.append(NOME)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print('Erro ao montar dataframe dados de artigos')\n",
    "            traceback_str = ''.join(traceback.format_tb(e.__traceback__))\n",
    "            print(e,traceback_str)    \n",
    "            browser.quit()\n",
    "            \n",
    "            return df_dados\n",
    "    \n",
    "    # df_dados =pd.DataFrame({\n",
    "    #     'ROTULOS': pd.Series(rotulos),\n",
    "    #     'CONTEUDOS': pd.Series(conteudos),\n",
    "    #         })\n",
    "    \n",
    "    t6=time.time()\n",
    "    print('='*95)\n",
    "    # print(f' {len(sucesso)} currículos extraídos com sucesso')\n",
    "    print(f' Tempo total para extrair {len(artigos)} artigos dos currículos: {tempo(t0,t6)}')\n",
    "    # print('='*95)\n",
    "    browser.quit()\n",
    "    \n",
    "    # return df_dados, sucesso, parcial_rotulos, parcial_conteudos\n",
    "    return pd.DataFrame(artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arquivos fontes para orientadores FUNCAP:\n",
    "# arquivo_qualis     = 'classificações_publicadas_todas_as_areas_avaliacao1672761192111.csv'\n",
    "# lista_orientadores = pd.read_csv(pathcsv+'lista_orientadores.csv')\n",
    "\n",
    "# lista_busca = lista_orientadores['ORIENTADOR'].unique()\n",
    "# lista_busca.sort()\n",
    "# print(f'Total de pesquisadores a extrair: {len(lista_orientadores[1:])}')\n",
    "# for i in lista_busca:\n",
    "#     print('    ',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados_artigos = extrair_artigos(lista_busca[0:1])\n",
    "# for i in dados_artigos.values:\n",
    "#     print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in dados_artigos.values:\n",
    "#     c=0\n",
    "#     for n,j in enumerate(i):\n",
    "#         c+=1\n",
    "#         if c==1:\n",
    "#             print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados_artigos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Funções padronização de strings e remoção de variantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PADRONIZAÇÃO DE NOMES DE AUTOR E ANÁLISE DE SIMILARIDADES\n",
    "def padronizar_nome(linha_texto):\n",
    "    '''Procura sobrenomes e abreviaturas e monta nome completo\n",
    "     Recebe: String com todos os sobrenomes e nomes, abreviados ou não\n",
    "    Retorna: Nome completo no formato padronizado em SOBRENOME AGNOME, Prenomes\n",
    "      Autor: Marcos Aires (Mar.2022)\n",
    "    '''\n",
    "    import unicodedata\n",
    "    import re\n",
    "    # print('               Analisando:',linha_texto)\n",
    "    string = ''.join(ch for ch in unicodedata.normalize('NFKD', linha_texto) if not unicodedata.combining(ch))\n",
    "    string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.','').replace('\\'','')\n",
    "    string = string.replace(',,,',',').replace(',,',',')\n",
    "    string = re.sub(r'[0-9]+', '', string)\n",
    "        \n",
    "    # Expressões regulares para encontrar padrões de divisão de nomes de autores\n",
    "    sobrenome_inicio   = re.compile(r'^[A-ZÀ-ú-a-z]+,')                  # Sequência de letras maiúsculas no início da string\n",
    "    sobrenome_composto = re.compile(r'^[A-ZÀ-ú-a-z]+[ ][A-ZÀ-ú-a-z]+,')  # Duas sequências de letras no início da string, separadas por espaço, seguidas por vírgula\n",
    "    letra_abrevponto   = re.compile(r'^[A-Z][.]')                        # Uma letra maiúscula no início da string, seguida por ponto\n",
    "    letra_abrevespaco  = re.compile(r'^[A-Z][ ]')                        # Uma letra maiúscula no início da string, seguida por espaço\n",
    "    letras_dobradas    = re.compile(r'[A-Z]{2}')                         # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "    letras_dobradasini = re.compile(r'[A-Z]{2}[ ]')                      # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "    letras_dobradasfim = re.compile(r'[ ][A-Z]{2}')                      # Duas letras maiúsculas juntas no final da string, precedida por espaço\n",
    "    letras_duasconsnts = re.compile(r'[B-DF-HJ-NP-TV-XZ]{2}')            # Duas Letras maiúsculas e consoantes juntas\n",
    "    letras_tresconsnts = re.compile(r'[B-DF-HJ-NP-TV-XZ]{3}')            # Três Letras maiúsculas e consoantes juntas\n",
    "    \n",
    "    # Agnomes e preprosições a tratar, agnomes vão maiúsculas para sobrenome e preposições vão para minúsculas nos nomes\n",
    "    nomes=[]\n",
    "    agnomes       = ['NETO','JUNIOR','FILHO','SEGUNDO','TERCEIRO']\n",
    "    preposicoes   = ['da','de','do','das','dos']\n",
    "    nome_completo = ''\n",
    "    \n",
    "    # Ajustar lista de termos, identificar sobrenomes compostos e ajustar sobrenome com ou sem presença de vírgula\n",
    "    div_sobrenome      = sobrenome_inicio.findall(string)\n",
    "    div_sbrcomposto    = sobrenome_composto.findall(string)\n",
    "    \n",
    "    # print('-'*100)\n",
    "    # print('                 Recebido:',string)\n",
    "    \n",
    "    # Caso haja vírgulas na string, tratar sobrenomes e sobrenomes compostos\n",
    "    if div_sobrenome != [] or div_sbrcomposto != []:\n",
    "        # print('CASO_01: Há víruglas na string')\n",
    "        div = string.split(', ')\n",
    "        sobrenome     = div[0].strip().upper()\n",
    "        try:\n",
    "            div_espaco    = div[1].split(' ')\n",
    "        except:\n",
    "            div_espaco    = ['']\n",
    "        primeiro      = div_espaco[0].strip('.')\n",
    "        \n",
    "        # print('     Dividir por vírgulas:',div)\n",
    "        # print('      Primeira DivVirgula:',sobrenome)\n",
    "        # print('Segunda DivVrg/DivEspaços:',div_espaco)\n",
    "        # print('      Primeira DivEspaços:',primeiro)\n",
    "               \n",
    "        # Caso primeiro nome sejam somente duas letras maiúsculas juntas, trata-se de duas iniciais\n",
    "        if len(primeiro)==2 or letras_tresconsnts.findall(primeiro):\n",
    "            # print('CASO_01.a: Há duas letras ou três letras consoantes juntas, são iniciais')\n",
    "            primeiro_nome=primeiro[0].strip()\n",
    "            # print('          C01.a1_PrimNome:',primeiro_nome)\n",
    "            nomes.append(primeiro[1].strip().upper())\n",
    "            try:\n",
    "                nomes.append(primeiro[2].strip().upper())\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            # print('CASO_01.b: Primeiro nome maior que 2 caracteres')\n",
    "            primeiro_nome = div_espaco[0].strip().title()\n",
    "            # print('          C01.a2_PrimNome:',primeiro_nome)\n",
    "        \n",
    "        # Montagem da lista de nomes do meio\n",
    "        for nome in div_espaco:\n",
    "            # print('CASO_01.c: Para cada nome da divisão por espaços após divisão por vírgula')\n",
    "            if nome not in nomes and nome.lower()!=primeiro_nome.lower() and nome.lower() not in primeiro_nome.lower() and nome!=sobrenome:   \n",
    "                # print('CASO_01.c1: Se o nome não está nem como primeiro nome, nem sobrenomes')\n",
    "                # print(nome, len(nome))\n",
    "                \n",
    "                # Avaliar se é abreviatura seguida de ponto e remover o ponto\n",
    "                if len(nome)<=2 and nome.lower() not in preposicoes:\n",
    "                    # print('    C01.c1.1_Nome<=02:',nome)\n",
    "                    for inicial in nome:\n",
    "                        # print(inicial)\n",
    "                        if inicial not in nomes and inicial not in primeiro_nome:\n",
    "                            nomes.append(inicial.replace('.','').strip().title())\n",
    "                elif len(nome)==3 and nome.lower() not in preposicoes:\n",
    "                        # print('    C01.c1.2_Nome==03:',nome)\n",
    "                        for inicial in nome:\n",
    "                            if inicial not in nomes and inicial not in primeiro_nome:\n",
    "                                nomes.append(inicial.replace('.','').strip().title())\n",
    "                else:\n",
    "                    if nome not in nomes and nome!=primeiro_nome and nome!=sobrenome and nome!='':\n",
    "                        if nome.lower() in preposicoes:\n",
    "                            nomes.append(nome.replace('.','').strip().lower())\n",
    "                        else:\n",
    "                            nomes.append(nome.replace('.','').strip().title())\n",
    "                        # print(nome,'|',primeiro_nome)\n",
    "                        \n",
    "        #caso haja sobrenome composto que não esteja nos agnomes considerar somente primeiro como sobrenome\n",
    "        if div_sbrcomposto !=[] and sobrenome.split(' ')[1] not in agnomes and sobrenome.split(' ')[0].lower() not in preposicoes:\n",
    "            # print('CASO_01.d: Sobrenome composto sem agnomes')\n",
    "            # print(div_sbrcomposto)\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            \n",
    "            nomes.append(sobrenome.split(' ')[1].title())\n",
    "            sobrenome = sobrenome.split(' ')[0].upper()\n",
    "            # print('Sobrenome:',sobrenome)\n",
    "            \n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('    Nomes:',nomes)\n",
    "        \n",
    "        #caso haja preposição como agnome desconsiderar e passar para final dos nomes\n",
    "        if div_sbrcomposto !=[] and sobrenome.split(' ')[0].lower() in preposicoes:\n",
    "            # print('CASO_01.e: Preposição no Sobrenome passar para o final dos nomes')\n",
    "            # print('   div_sbrcomposto:', div_sbrcomposto)\n",
    "            # print('Sobrenome composto:',div_sbrcomposto)\n",
    "            \n",
    "            nomes.append(div_sbrcomposto[0].split(' ')[0].lower())\n",
    "            # print('    Nomes:',nomes)\n",
    "            sobrenome = div_sbrcomposto[0].split(' ')[1].upper().strip(',')\n",
    "            # print('Sobrenome:',sobrenome)\n",
    "            \n",
    "            for i in nomes:\n",
    "                # print('CASO_01.e1: Para cada nome avaliar se o sobrenome está na lista')\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('  Nomes:',nomes)\n",
    "        \n",
    "        # print('Ao final do Caso 01')\n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('           Lista de nomes:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "    # Caso não haja vírgulas na string considera sobrenome o último nome da string dividida com espaço vazio\n",
    "    else:\n",
    "        # print('CASO_02: Não há víruglas na string')\n",
    "        try:\n",
    "            div = string.split(' ')\n",
    "            # print('      Divisões por espaço:',div)\n",
    "            \n",
    "            if div[-1] in agnomes: # nome final é um agnome\n",
    "                sobrenome     = div[-2].upper().strip()+' '+div[-1].upper().strip()\n",
    "                for i in div[1:-2]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.title().strip())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.lower().strip())\n",
    "            else:\n",
    "                if len(div[-1]) > 2:\n",
    "                    sobrenome     = div[-1].upper().strip()\n",
    "                    primeiro_nome = div[1].title().strip()\n",
    "                    for i in div[1:-1]:\n",
    "                        if i != sobrenome and i not in preposicoes:\n",
    "                            nomes.append(i.title().strip())\n",
    "                        if i in preposicoes:\n",
    "                            nomes.append(i.lower().strip())\n",
    "                else:\n",
    "                    sobrenome     = div[-2].upper().strip()\n",
    "                    for i in div[-1]:\n",
    "                        nomes.append(i.title())\n",
    "                    primeiro_nome = nomes[0].title().strip()\n",
    "                    for i in div[1:-1]:\n",
    "                        if i != sobrenome and i not in preposicoes:\n",
    "                            nomes.append(i.title().strip())\n",
    "                        if i in preposicoes:\n",
    "                            nomes.append(i.lower().strip())\n",
    "        except:\n",
    "            sobrenome = div[-1].upper().strip()\n",
    "            for i in div[1:-1]:\n",
    "                    if i != sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.title().strip())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.lower().strip())\n",
    "            \n",
    "        if sobrenome.lower() != div[0].lower().strip():\n",
    "            primeiro_nome=div[0].title().strip()\n",
    "        else:\n",
    "            primeiro_nome=''\n",
    "        \n",
    "        # print('Ao final do Caso 02')\n",
    "        # print('    Sobrenome sem vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome sem vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio sem vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "    # Encontrar e tratar como abreviaturas termos com apenas uma ou duas letras iniciais juntas, com ou sem ponto\n",
    "    for j in nomes:\n",
    "        # print('CASO_03: Avaliar cada nome armazenado na variável nomes')\n",
    "        # Procura padrões com expressões regulares na string\n",
    "        div_sobrenome      = sobrenome_inicio.findall(j)\n",
    "        div_sbrcomposto    = sobrenome_composto.findall(j)\n",
    "        div_abrevponto     = letra_abrevponto.findall(j)\n",
    "        div_abrevespaco    = letra_abrevespaco.findall(j)\n",
    "        div_ltrdobradasini = letras_dobradasini.findall(j)\n",
    "        div_ltrdobradasfim = letras_dobradasfim.findall(j)\n",
    "        div_ltrdobradas    = letras_dobradas.findall(j)\n",
    "        tamanho=len(j)\n",
    "        # print('\\n', div_ltrdobradasini, div_ltrdobradasfim, tamanho, 'em:',j,len(j))\n",
    "        \n",
    "        #caso houver abreviatura com uma letra em maiúscula nos nomes\n",
    "        if div_abrevponto !=[] or tamanho==1:\n",
    "            # print('CASO_03.1: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "            nome = j.replace('.','').strip()\n",
    "            if nome not in nomes and nome != sobrenome and nome != primeiro_nome:\n",
    "                # print('CASO_03.1a: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "                nomes.append(nome.upper())\n",
    "        \n",
    "        #caso houver duas inicias juntas em maiúsculas\n",
    "        elif div_ltrdobradasini !=[] or div_ltrdobradasfim !=[] or div_ltrdobradas !=[] :\n",
    "            # print('CASO_03.2: Há abreviaturas uma letra maiúscula nos nomes')\n",
    "            for letra in j:\n",
    "                # print('CASO_03.2a: Avaliar cada inicial do nome')\n",
    "                if letra not in nomes and letra != sobrenome and letra != primeiro_nome:\n",
    "                    # print('CASO_03.2a.1: Se não estiver adicionar inicial aos nomes')\n",
    "                    nomes.append(letra.upper())\n",
    "        \n",
    "        #caso haja agnomes ao sobrenome\n",
    "        elif sobrenome in agnomes:\n",
    "            # print('CASO_03.3: Há agnomes nos sobrenomes')\n",
    "            sobrenome = nomes[-1].upper()+' '+sobrenome\n",
    "            # print(sobrenome.split(' '))\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('Nomes do meio:',nomes)\n",
    "            \n",
    "        else:\n",
    "            # print('CASO_03.4: Não há agnomes nos sobrenomes')\n",
    "            if j not in nomes and j not in sobrenome and j != primeiro_nome:\n",
    "                if len(nomes) == 1:\n",
    "                    nomes.append(j.upper())\n",
    "                elif 1 < len(nomes) <= 3:\n",
    "                    nomes.append(j.lower())\n",
    "                else:\n",
    "                    nomes.append(j.title())\n",
    "         \n",
    "        # print('Ao final do Caso 03')\n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "    nomes_meio=' '.join([str for str in nomes]).strip()\n",
    "    # print('        Qte nomes do meio:',nomes,len(nomes))\n",
    "    \n",
    "    if primeiro_nome.lower() == sobrenome.lower():\n",
    "        # print('CASO_04: Primeiro nome é igual ao sobrenome')\n",
    "        try:\n",
    "            primeiro_nome=nomes_meio.split(' ')[0]\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            nomes_meio.remove(sobrenome)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        # print('Ao final do caso 04')\n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "    # Caso sobrenome seja só de 1 letra passá-lo para nomes e considerar o próximo nome como sobrenome\n",
    "    for i in range(len(div)):\n",
    "        if len(sobrenome)==1 or sobrenome.lower() in preposicoes:\n",
    "            # print('CASO_05: Mudar sobrenomes até o adequado')\n",
    "            div    = string.split(', ')\n",
    "            # print('Divisão por vírgulas:',div)\n",
    "            avaliar0       = div[0].split(' ')[0].strip()\n",
    "            if 1< len(avaliar0) < 3:\n",
    "                # print('CASO_05.1: 1 < Sobrenome < 3 fica em minúsculas')\n",
    "                sbrn0          = avaliar0.lower()\n",
    "            else:\n",
    "                # print('CASO_05.2: Sobrenome de tamanho 1 ou maior que 3 fica em maiúsculas')\n",
    "                sbrn0          = avaliar0.title()\n",
    "            # print('sbrn0:',sbrn0, len(sbrn0))\n",
    "            \n",
    "            try:\n",
    "                avaliar1=div[0].split(' ')[1].strip()\n",
    "                # print('avaliar0',avaliar0)\n",
    "                # print('avaliar1',avaliar1)\n",
    "                if 1 < len(avaliar1) <=3:\n",
    "                    sbrn1     = avaliar1.lower()\n",
    "                else:\n",
    "                    sbrn1     = avaliar1.title()\n",
    "                # print('sbrn1:',sbrn1, len(sbrn1))\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if div != []:\n",
    "                # print('CASO_05.3: Caso haja divisão por vírgulas na string')\n",
    "                try:\n",
    "                    div_espaco     = div[1].split(' ')\n",
    "                except:\n",
    "                    div_espaco     = div[0].split(' ')\n",
    "                sobrenome      = div_espaco[0].strip().upper()\n",
    "                try:\n",
    "                    primeiro_nome  = div_espaco[1].title().strip()\n",
    "                except:\n",
    "                    primeiro_nome  = div_espaco[0].title().strip()\n",
    "                if len(sbrn0) == 1:\n",
    "                    # print('CASO_05.3a: Avalia primeiro sobrenome de tamanho 1')\n",
    "                    # print('Vai pros nomes:',str(sbrn0).title())\n",
    "                    nomes_meio = nomes_meio+str(' '+sbrn0.title())\n",
    "                    # print('   NomesMeio:',nomes_meio)\n",
    "\n",
    "                elif 1 < len(sbrn0) <= 3:\n",
    "                    # print('CASO_05.3b: Avalia primeiro sobrenome 1< tamanho <=3')\n",
    "                    # print('Vão pros nomes sbrn0:',sbrn0, 'e sbrn1:',sbrn1)\n",
    "\n",
    "                    div_tresconsoantes = letras_tresconsnts.findall(sobrenome)\n",
    "                    if div_tresconsoantes != []:\n",
    "                        # print('CASO_05.4: Três consoantes como sobrenome')\n",
    "                        for letra in sobrenome:\n",
    "                            nomes.append(letra)\n",
    "\n",
    "                        if len(sobrenome) >2:\n",
    "                            sobrenome=nomes[0]\n",
    "                        else:\n",
    "                            sobrenome=nomes[1]\n",
    "                        nomes.remove(sobrenome)\n",
    "                        primeiro_nome=nomes[0]\n",
    "                        nomes_meio=' '.join([str for str in nomes[1:]]).strip()\n",
    "                        nome_completo=sobrenome.upper()+', '+nomes_meio                \n",
    "                    \n",
    "                    try:                       \n",
    "                        # print(' 05.3b    Lista de Nomes:',nomes_meio)\n",
    "                        nomes_meio=nomes_meio.replace(sbrn0,'')\n",
    "                        # print(' 05.3b ReplaceSobrenome0:',nomes_meio)\n",
    "                        nomes_meio=nomes_meio.replace(sbrn1,'')\n",
    "                        # print(' 05.3b ReplaceSobrenome1:',nomes_meio)\n",
    "                    except Exception as e:\n",
    "                        # print('   Erro ReplaceSobrenome:',e)\n",
    "                        pass\n",
    "                    try:\n",
    "                        nomes_meio.replace(primeiro_nome.title(),'')\n",
    "                        nomes_meio.replace(primeiro_nome.lower(),'')\n",
    "                        nomes_meio.replace(primeiro_nome,'')\n",
    "                        # print(' 05.3b Replace PrimNome:',nomes_meio)\n",
    "                    except Exception as e:\n",
    "                        print('Erro no try PrimeiroNome:',e)\n",
    "                        pass\n",
    "                    nomes_meio = nomes_meio.replace(sobrenome,'')\n",
    "                    try:\n",
    "                        for n,i in enumerate(avaliar1):\n",
    "                            nomes.append(i.upper())\n",
    "                            sbrn1     = avaliar1[0]\n",
    "                        else:\n",
    "                            sbrn1     = avaliar1.title()\n",
    "                        # print('sbrn1:',sbrn1, len(sbrn1))\n",
    "                        nomes_meio = nomes_meio+str(' '+sbrn0)+str(' '+sbrn1)\n",
    "                    except:\n",
    "                        nomes_meio = nomes_meio+str(' '+sbrn0)\n",
    "                    nomes      = nomes_meio.strip().strip(',').split(' ')\n",
    "                    # print(' 05.3b NomesMeio:',nomes_meio)\n",
    "                    # print(' 05.3b     Nomes:',nome)\n",
    "\n",
    "                else:\n",
    "                    # print('CASO_05.3c: Avalia primeiro sobrenome >3')\n",
    "                    nomes_meio = nomes_meio+str(' '+div[0].strip().title())\n",
    "                    nomes      = nomes_meio.strip().split(' ')\n",
    "                    # print(' 05.3c NomesMeio:',nomes_meio)\n",
    "                    # print(' 05.3c     Nomes:',nomes)\n",
    "\n",
    "                nomes_meio=nomes_meio.replace(sobrenome,'').replace(',','').strip()\n",
    "                nomes_meio=nomes_meio.replace(primeiro_nome,'').strip()\n",
    "\n",
    "            # print('Ao final do caso 05')\n",
    "            # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "            # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "            # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "    \n",
    "    if sobrenome != '' and primeiro_nome !='':\n",
    "        nome_completo=sobrenome.upper().replace(',','')+', '+primeiro_nome.replace(',','')+' '+nomes_meio.replace(sobrenome,'').replace(',','')\n",
    "    elif sobrenome != '':\n",
    "        nome_completo=sobrenome.upper().replace(',','')+', '+nomes_meio.replace(sobrenome,'').replace(',','')\n",
    "    else:\n",
    "        nome_completo=sobrenome.upper()\n",
    "    \n",
    "#     print('Após ajustes finais')\n",
    "#     print('     Sobrenome:',sobrenome)\n",
    "#     print(' Primeiro Nome:',primeiro_nome)\n",
    "#     print('         Nomes:',nomes)\n",
    "#     print('     NomesMeio:',nomes_meio)        \n",
    "        \n",
    "#     print('                Resultado:',nome_completo)\n",
    "    \n",
    "    return nome_completo.strip()\n",
    "\n",
    "\n",
    "def iniciais_nome(linha_texto):\n",
    "    '''Função para retornar sobrenome+iniciais dos nomes, na forma: SOBRENOME, X Y Z\n",
    "     Recebe: String com nome\n",
    "    Retorna: Tupla com nome e sua versão padronizada em sobrenome+agnomes em maiúsculas, seguida de vírgula e iniciais dos nomes \n",
    "      Autor: Marcos Aires (Mar.2022)\n",
    "    '''\n",
    "    import unicodedata\n",
    "    import re\n",
    "    # print('               Analisando:',linha_texto)\n",
    "    string = ''.join(ch for ch in unicodedata.normalize('NFKD', linha_texto) if not unicodedata.combining(ch))\n",
    "    string = string.replace('(Org)','').replace('(Org.)','').replace('(Org).','').replace('.','')\n",
    "        \n",
    "    # Expressões regulares para encontrar padrões de divisão de nomes de autores\n",
    "    sobrenome_inicio   = re.compile(r'^[A-ZÀ-ú-a-z]+,')                 # Sequência de letras maiúsculas no início da string\n",
    "    sobrenome_composto = re.compile(r'^[A-ZÀ-ú-a-z]+[ ][A-ZÀ-ú-a-z]+,') # Duas sequências de letras no início da string, separadas por espaço, seguidas por vírgula\n",
    "    letra_abrevponto   = re.compile(r'^[A-Z][.]')                       # Uma letra maiúscula no início da string, seguida por ponto\n",
    "    letra_abrevespaco  = re.compile(r'^[A-Z][ ]')                       # Uma letra maiúscula no início da string, seguida por espaço\n",
    "    letras_dobradas    = re.compile(r'[A-Z]{2}')                        # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "    letras_dobradasini = re.compile(r'[A-Z]{2}[ ]')                     # Duas letras maiúsculas juntas no início da string, seguida por espaço\n",
    "    letras_dobradasfim = re.compile(r'[ ][A-Z]{2}')                     # Duas letras maiúsculas juntas no final da string, precedida por espaço\n",
    "        \n",
    "    nomes=[]\n",
    "    agnomes       = ['NETO','JUNIOR','FILHO','SEGUNDO','TERCEIRO']\n",
    "    preposicoes   = ['da','de','do','das','dos','DA','DE','DOS','DAS','DOS','De']\n",
    "    nome_completo = ''\n",
    "    \n",
    "    # Ajustar lista de termos, identificar sobrenomes compostos e ajustar sobrenome com ou sem presença de vírgula\n",
    "    div_sobrenome      = sobrenome_inicio.findall(string)\n",
    "    div_sbrcomposto    = sobrenome_composto.findall(string)\n",
    "    \n",
    "    # Caso haja vírgulas na string, tratar sobrenomes e sobrenomes compostos\n",
    "    if div_sobrenome != [] or div_sbrcomposto != []:\n",
    "        div   = string.split(', ')\n",
    "        sobrenome     = div[0].strip().upper()\n",
    "        try:\n",
    "            div_espaco    = div[1].split(' ')\n",
    "        except:\n",
    "            div_espaco  = ['']\n",
    "        primeiro      = div_espaco[0].strip('.')\n",
    "        \n",
    "        # Caso primeiro nome sejam somente duas letras maiúsculas juntas, trata-se de duas iniciais\n",
    "        if len(primeiro)==2:\n",
    "            primeiro_nome=primeiro[0].strip()\n",
    "            nomes.append(primeiro[1].strip())\n",
    "        else:\n",
    "            primeiro_nome = div_espaco[0].strip().title()\n",
    "        \n",
    "        # Montagem da lista de nomes do meio\n",
    "        for nome in div_espaco:\n",
    "            if nome not in nomes and nome.lower()!=primeiro_nome.lower() and nome.lower() not in primeiro_nome.lower() and nome!=sobrenome:   \n",
    "                # print(nome, len(nome))\n",
    "                \n",
    "                # Avaliar se é abreviatura seguida de ponto e remover o ponto\n",
    "                if len(nome)<=2 and nome.lower() not in preposicoes:\n",
    "                    for inicial in nome:\n",
    "                        # print(inicial)\n",
    "                        if inicial not in nomes and inicial not in primeiro_nome:\n",
    "                            nomes.append(inicial.replace('.','').strip().title())\n",
    "                else:\n",
    "                    if nome not in nomes and nome!=primeiro_nome and nome!=sobrenome and nome!='':\n",
    "                        if nome.lower() in preposicoes:\n",
    "                            nomes.append(nome.replace('.','').strip().lower())\n",
    "                        else:\n",
    "                            nomes.append(nome.replace('.','').strip().title())\n",
    "                        # print(nome,'|',primeiro_nome)\n",
    "                        \n",
    "        #caso haja sobrenome composto que não esteja nos agnomes considerar somente primeiro como sobrenome\n",
    "        if div_sbrcomposto !=[] and sobrenome.split(' ')[1] not in agnomes:\n",
    "            # print(div_sbrcomposto)\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            nomes.append(sobrenome.split(' ')[1].title())\n",
    "            sobrenome = sobrenome.split(' ')[0].upper()\n",
    "            # print('Sobrenome:',sobrenome.split(' '))\n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('Nomes do meio:',nomes)\n",
    "        \n",
    "        # print('    Sobrenome com vírgula:',sobrenome, len(sobrenome),'letras')\n",
    "        # print('Primeiro nome com vírgula:',primeiro_nome, len(primeiro_nome),'letras')\n",
    "        # print('Nomes do meio com vírgula:',nomes, len(nomes),'nomes')\n",
    "        \n",
    "    # Caso não haja vírgulas na string considera sobrenome o último nome da string dividida com espaço vazio\n",
    "    else:\n",
    "        try:\n",
    "            div       = string.split(' ')\n",
    "            if div[-2] in agnomes:\n",
    "                sobrenome = div[-2].upper()+' '+div[-1].strip().upper()\n",
    "                for i in nomes[1:-2]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.strip().title())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.strip().lower())\n",
    "            else:\n",
    "                sobrenome = div[-1].strip().upper()\n",
    "                for i in div[1:-1]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.strip().title())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.strip().lower())\n",
    "        except:\n",
    "            sobrenome = div[-1].strip().upper()\n",
    "            for i in div[1:-1]:\n",
    "                    if i not in sobrenome and i not in preposicoes:\n",
    "                        nomes.append(i.strip().title())\n",
    "                    if i in preposicoes:\n",
    "                        nomes.append(i.strip().lower())\n",
    "            \n",
    "        if sobrenome.lower() != div[0].strip().lower():\n",
    "            primeiro_nome=div[0].strip().title()\n",
    "        else:\n",
    "            primeiro_nome=''\n",
    "        \n",
    "        # print('    Sobrenome sem vírgula:',sobrenome)\n",
    "        # print('Primeiro nome sem vírgula:',primeiro_nome)\n",
    "        # print('Nomes do meio sem vírgula:',nomes)\n",
    "    \n",
    "    # Encontrar e tratar como abreviaturas termos com apenas uma ou duas letras iniciais juntas, com ou sem ponto\n",
    "    for j in nomes:\n",
    "        # Procura padrões com expressões regulares na string\n",
    "        div_sobrenome      = sobrenome_inicio.findall(j)\n",
    "        div_sbrcomposto    = sobrenome_composto.findall(j)\n",
    "        div_abrevponto     = letra_abrevponto.findall(j)\n",
    "        div_abrevespaco    = letra_abrevespaco.findall(j)\n",
    "        div_ltrdobradasini = letras_dobradasini.findall(j)\n",
    "        div_ltrdobradasfim = letras_dobradasfim.findall(j)\n",
    "        div_ltrdobradas    = letras_dobradas.findall(j)\n",
    "        tamanho=len(j)\n",
    "        # print('\\n', div_ltrdobradasini, div_ltrdobradasfim, tamanho, 'em:',j,len(j))\n",
    "        \n",
    "        #caso houver abreviatura com uma letra em maiúscula nos nomes\n",
    "        if div_abrevponto !=[] or tamanho==1:\n",
    "            cada_nome = j.replace('.','').strip()\n",
    "            if cada_nome not in nomes and cada_nome != sobrenome and nome != primeiro_nome:\n",
    "                nomes.append(cada_nome)\n",
    "        \n",
    "        #caso houver duas inicias juntas em maiúsculas\n",
    "        elif div_ltrdobradasini !=[] or div_ltrdobradasfim !=[] or div_ltrdobradas !=[] :\n",
    "            for letra in j:\n",
    "                if letra not in nomes and letra != sobrenome and letra != primeiro_nome:\n",
    "                    nomes.append(letra)\n",
    "        \n",
    "        #caso haja agnomes ao sobrenome\n",
    "        elif sobrenome in agnomes:\n",
    "            sobrenome = nomes[-1].upper()+' '+sobrenome\n",
    "            # print(sobrenome.split(' '))\n",
    "            # print('Sobrenome composto:',sobrenome)\n",
    "            for i in nomes:\n",
    "                if i.lower() in sobrenome.lower():\n",
    "                    nomes.remove(i)\n",
    "            # print('Nomes do meio:',nomes)\n",
    "            \n",
    "        else:\n",
    "            if j not in nomes and j not in sobrenome and j != primeiro_nome:\n",
    "                nomes.append(j)\n",
    "    \n",
    "    nomes_meio=' '.join([str[0] for str in nomes]).strip()\n",
    "    # print('Qte nomes do meio',len(nomes),nomes)\n",
    "    if sobrenome != '' and primeiro_nome !='':\n",
    "        sobrenome_iniciais = sobrenome+', '+primeiro_nome[0]+' '+nomes_meio\n",
    "    elif sobrenome != '':\n",
    "        sobrenome_iniciais = sobrenome\n",
    "    \n",
    "    return sobrenome_iniciais.strip()\n",
    "\n",
    "\n",
    "def similares(lista_autores, lista_grupo, limite_jarowinkler, distancia_levenshtein):\n",
    "    \"\"\"Função para aplicar padronização no nome de autor da lista de pesquisadores e buscar similaridade na lista de coautores\n",
    "     Recebe: Lista de pesquisadores do grupo em análise gerada pela lista de nomes dos coautores das publicações em análise\n",
    "    Utiliza: get_jaro_distance(), editdistance()\n",
    "    Retorna: Lista de autores com fusão de nomes cuja similaridade esteja dentro dos limites definidos nesta função\n",
    "      Autor: Marcos Aires (Fev.2022)\n",
    "      \n",
    "    Refazer: Inserir crítica de, mantendo sequência ordem alfabética, retornar no final nome mais extenso em caso de similaridade;\n",
    "    \"\"\"\n",
    "    from pyjarowinkler.distance import get_jaro_distance\n",
    "    from IPython.display import clear_output\n",
    "    import editdistance\n",
    "    import numpy as np\n",
    "    import time\n",
    "    \n",
    "    t0=time.time()\n",
    "    \n",
    "    # limite_jarowinkler=0.85\n",
    "    # distancia_levenshtein=6\n",
    "    similares_jwl=[]\n",
    "    similares_regras=[]\n",
    "    similares=[]\n",
    "    tempos=[]\n",
    "    \n",
    "    count=0\n",
    "    t1=time.time()\n",
    "    for i in lista_autores:\n",
    "        count+=1\n",
    "        if count > 0:\n",
    "            tp=time.time()-t1\n",
    "            tmed=tp/count*2\n",
    "            tempos.append(tp)\n",
    "    #     print(\"Analisar similaridades com: \", nome_padronizado)\n",
    "        \n",
    "        count1=0\n",
    "        for nome in lista_autores:\n",
    "            if count1 > 0:\n",
    "                resta=len(lista_autores)-count\n",
    "                print(f'Analisando {count1:3}/{len(lista_autores)} resta analisar {resta:3} nomes. Previsão de término em {np.round(tmed*resta/60,1)} minutos')\n",
    "            else:\n",
    "                print(f'Analisando {count1:3}/{len(lista_autores)} resta analisar {len(lista_autores)-count1} nomes.')\n",
    "            \n",
    "            t2=time.time()\n",
    "            count1+=1            \n",
    "\n",
    "            try:\n",
    "                similaridade_jarowinkler = get_jaro_distance(i, nome)\n",
    "                print(f'{i:40} | {nome:40} | Jaro-Winkler: {np.round(similaridade_jarowinkler,2):4} Levenshtein: {editdistance.eval(i, nome)}')\n",
    "                similaridade_levenshtein = editdistance.eval(i, nome)\n",
    "\n",
    "                # inferir similaridade para nomes que estejam acima do limite ponderado definido, mas não idênticos e não muito distantes em edição\n",
    "                if  similaridade_jarowinkler > limite_jarowinkler and similaridade_jarowinkler!=1 and similaridade_levenshtein < distancia_levenshtein:\n",
    "                    # Crítica no nome mais extenso como destino no par (origem, destino)\n",
    "                    \n",
    "                    similares_jwl.append((i,nome))\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            clear_output(wait=True)\n",
    "    \n",
    "    # Conjunto de regras de validação de similaridade\n",
    "    # Monta uma lista de nomes a serem retirados antes de montar a lista de troca\n",
    "    trocar=[]\n",
    "    retirar=[]\n",
    "    for i in similares_jwl:\n",
    "        sobrenome_i = i[0].split(',')[0]\n",
    "        sobrenome_j = i[1].split(',')[0]\n",
    "\n",
    "        try:\n",
    "            iniciais_i  = iniciais_nome(i[0]).split(',')[1].strip()\n",
    "        except:\n",
    "            iniciais_i  = ''\n",
    "\n",
    "        try:\n",
    "            iniciais_j  = iniciais_nome(i[1]).split(',')[1].strip()\n",
    "        except:\n",
    "            iniciais_j  = ''\n",
    "\n",
    "        try:\n",
    "            primnome_i = i[0].split(',')[1].strip().split(' ')[0].strip()\n",
    "        except:\n",
    "            primnome_i = ''\n",
    "\n",
    "        try:\n",
    "            primnome_j = i[1].split(',')[1].strip().split(' ')[0].strip()\n",
    "        except:\n",
    "            primnome_j = ''    \n",
    "\n",
    "        try:\n",
    "            inicial_i = i[0].split(',')[1].strip()[0]\n",
    "        except:\n",
    "            inicial_i = ''\n",
    "\n",
    "        try:\n",
    "            resto_i   = i[0].split(',')[1].strip().split(' ')[0][1:]\n",
    "        except:\n",
    "            resto_i   = ''\n",
    "\n",
    "        try:\n",
    "            inicial_j = i[1].split(',')[1].strip()[0]\n",
    "        except:\n",
    "            inicial_j = ''\n",
    "\n",
    "        try:\n",
    "            resto_j   = i[1].split(',')[1].strip().split(' ')[0][1:]\n",
    "        except:\n",
    "            resto_j = ''\n",
    "\n",
    "        # Se a distância de edição entre os sobrenomes\n",
    "        if editdistance.eval(sobrenome_i, sobrenome_j) > 2 or inicial_i!=inicial_j:\n",
    "            retirar.append(i)\n",
    "        else:\n",
    "            if primnome_i!=primnome_j and len(primnome_i)>1:\n",
    "                retirar.append(i)\n",
    "            if primnome_i!=primnome_j and len(primnome_i)>1 and len(primnome_j)>1:\n",
    "                retirar.append(i)\n",
    "            if resto_i!=resto_j and resto_i!='':\n",
    "                retirar.append(i)\n",
    "            if len(i[1]) < len(i[0]):\n",
    "                retirar.append(i)\n",
    "            if len(iniciais_i) != len(iniciais_j):\n",
    "                retirar.append(i)\n",
    "\n",
    "    for i in similares_jwl:\n",
    "        if i not in retirar:\n",
    "            trocar.append(i)\n",
    "\n",
    "        if iniciais_nome(i[0]) in iniciais_nome(i[1]) and len(i[0]) < len(i[1]):\n",
    "            trocar.append(i)\n",
    "\n",
    "        if iniciais_nome(i[0]) == iniciais_nome(i[1]) and len(i[0]) < len(i[1]):\n",
    "             trocar.append(i)\n",
    "\n",
    "    # Exemplo de inserção de conhecimentos extra Lattes para melhor resolução de entidades\n",
    "    lista_extra = [\n",
    "                    # ('ALBUQUERQUE, Adriano B', 'ALBUQUERQUE, Adriano Bessa'),\n",
    "                    # ('ALBUQUERQUE, Adriano', 'ALBUQUERQUE, Adriano Bessa'),\n",
    "                    # ('COELHO, Andre L V', 'COELHO, Andre Luis Vasconcelos'),\n",
    "                    # ('DUARTE, Joao B F', 'DUARTE, Joao Batista Furlan'),\n",
    "                    # ('FILHO, Raimir H','HOLANDA FILHO, Raimir'),\n",
    "                    # ('FILHO, Raimir','HOLANDA FILHO, Raimir'),\n",
    "                    # ('FORMIGO, A','FORMICO, Maria Andreia Rodrigues'),\n",
    "                    # ('FORMICO, A','FORMICO, Maria Andreia Rodrigues'),\n",
    "                    # ('FURLAN, J B D', 'FURLAN, Joao Batista Duarte'),\n",
    "                    # ('FURTADO, Elizabeth', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "                    # ('FURTADO, Elizabeth S', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "                    # ('FURTADO, Elizabeth Sucupira','FURTADO, Maria Elizabeth Sucupira'),\n",
    "                    # ('FURTADO, M E S', 'FURTADO, Maria Elizabeth Sucupira'),\n",
    "                    # ('FURTADO, Vasco', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                    # ('FURTADO, J P', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                    # ('FURTADO, J V P', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                    # ('FURTADO, Vasco', 'FURTADO, Joao Jose Vasco Peixoto'),\n",
    "                    # ('FURTADO, Elizabeth','FURTADO, Maria Elizabeth Sucupira'),\n",
    "                    # ('HOLANDA, Raimir', 'HOLANDA FILHO, Raimir'),\n",
    "                    # ('LEITE, G S', 'LEITE, Gleidson Sobreira'),\n",
    "                    # ('PEQUENO, T H C', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                    # ('PEQUENO, Tarcisio','PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                    # ('PEQUENO, Tarcisio Cavalcante', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                    # ('PINHEIRO, Placido R', 'PINHEIRO, Placido Rogerio'),\n",
    "                    # ('PINHEIRO, Vladia', 'PINHEIRO, Vladia Celia Monteiro'),\n",
    "                    # ('RODRIGUES, M A F', 'RODRIGUES, Maria Andreia Formico'),\n",
    "                    # ('RODRIGUES, Andreia', 'RODRIGUES, Maria Andreia Formico'),\n",
    "                    # ('JOAO, Batista F Duarte,', 'FURLAN, Joao Batista Duarte'),\n",
    "                    # ('MACEDO, Antonio Roberto M de', 'MACEDO, Antonio Roberto Menescal de'),\n",
    "                    # ('MACEDO, D V', 'MACEDO, Daniel Valente'),\n",
    "                    # ('MENDONCA, Nabor C', 'MENDONCA, Nabor das Chagas'),\n",
    "                    # ('PEQUENO, Tarcisio', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                    # ('PEQUENO, Tarcisio H', 'PEQUENO, Tarcisio Haroldo Cavalcante'),\n",
    "                    # ('PINHEIRO, Mirian C D', 'PINHEIRO, Miriam Caliope Dantas'),\n",
    "                    # ('PINHEIRO, Mirian Caliope Dantas', 'PINHEIRO, Miriam Caliope Dantas'),\n",
    "                    # ('PINHEIRO, P G C D', 'PINHEIRO, Pedro Gabriel Caliope Dantas'),\n",
    "                    # ('PINHEIRO, Pedro G C', 'PINHEIRO, Pedro Gabriel Caliope Dantas'),\n",
    "                    # ('PINHEIRO, Placido R', 'PINHEIRO, Placido Rogerio'),\n",
    "                    # ('PINHEIRO, Vladia', 'PINHEIRO, Vladia Celia Monteiro'),\n",
    "                    # ('ROGERIO, Placido Pinheiro', 'PINHEIRO, Placido Rogerio'),\n",
    "                    # ('REBOUCRAS FILHO, Pedro', 'REBOUCAS FILHO, Pedro Pedrosa'),\n",
    "                    # ('SAMPAIO, A', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "                    # ('SAMPAIO, Americo', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "                    # ('SAMPAIO, Americo Falcone', 'SAMPAIO, Americo Tadeu Falcone'),\n",
    "                    # ('SUCUPIRA, Elizabeth Furtado','FURTADO, Maria Elizabeth Sucupira'),\n",
    "                  ]\n",
    "    \n",
    "    trocar=trocar+lista_extra\n",
    "    trocar.sort()\n",
    "    \n",
    "    return trocar\n",
    "\n",
    "\n",
    "def extrair_variantes(df_dadosgrupo):\n",
    "    ''' Utiliza campo de Nome em Citações do currículo como filtro para obter variantes do nome de cada membro\n",
    "     Recebe: Dataframe com os dados brutos do grupo de pesquisa agrupados; lista de nomes de pesquisadores de interesse\n",
    "    Retorna: Lista de tuplas com pares a serem trocados da variante pelo nome padronizado na forma (origem, destino)\n",
    "    '''\n",
    "    filtro1   = 'Nome'\n",
    "    lista_nomes = df_dadosgrupo[(df_dadosgrupo.ROTULOS == filtro1)]['CONTEUDOS'].values\n",
    "\n",
    "    variantes=[]\n",
    "    filtro='Nome em citações bibliográficas'\n",
    "    variantes=df_dadosgrupo[(df_dadosgrupo.ROTULOS == filtro)]['CONTEUDOS'].to_list()\n",
    "\n",
    "    trocar=[]\n",
    "    for j in range(len(variantes)):\n",
    "        padrao_destino = padronizar_nome(lista_nomes[j])\n",
    "        trocar.append((lista_nomes[j], padrao_destino))\n",
    "        for k in variantes[j]:\n",
    "            padrao_origem = padronizar_nome(k)\n",
    "            trocar.append((k, padrao_destino))\n",
    "            trocar.append((padrao_origem, padrao_destino))\n",
    "    \n",
    "    return trocar\n",
    "\n",
    "\n",
    "def inferir_variantes(nome):\n",
    "    ''' Quebra um nome inicialmente por vírgula para achar sobrenomes, e depois por ' ' para achar nomes\n",
    "     Recebe: Par de nomes a comparar, nome1 é nome padronizado na função padronizar_nome(), nome2 é o que será analisado\n",
    "    Utiliza: Função padronizar_nome(nome)\n",
    "    Retorna: Lista de tuplas, no formato (origem, destino), com variantes de nome a serem trocadas pela forma padronizada\n",
    "      Autor: Marco Aires (Fev.2022)\n",
    "    '''\n",
    "    trocar = []\n",
    "    nomes  = []\n",
    "    try:\n",
    "        div0  = nome.split(',').strip()\n",
    "        sobrenome=div0[0]\n",
    "        try:\n",
    "            div1 = div0[1].split(' ').strip()\n",
    "            for i in div1:\n",
    "                nomes.append(i)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    trocar.append(nome, iniciais_nome(nome))\n",
    "    \n",
    "    return trocar\n",
    "\n",
    "\n",
    "def comparar_nomes(nome1,nome2):\n",
    "    ''' Compara dois nomes por seus sobrenomes e iniciais do primeiro nome\n",
    "     Recebe: Par de nomes a comparar, nome1 é nome padronizado na função padronizar_nome(), nome2 é o que será analisado\n",
    "    Utiliza: Função padronizar_nome(nome)\n",
    "    Retorna: Lista de tuplas, no formato (origem, destino), com variantes de nome a serem trocadas pela forma padronizada\n",
    "      Autor: Marco Aires (Fev.2022)\n",
    "    '''\n",
    "    trocar=[]\n",
    "    qte_nomes1=0\n",
    "    nome_padronizado1 = padronizar_nome(nome1)\n",
    "    sobrenome1        = nome_padronizado1.split(',')[0]\n",
    "    if sobrenome1!='':\n",
    "        qte_nomes1+=1\n",
    "    primeiro_nome1    = nome_padronizado1.split(',')[1].split(' ')[0]\n",
    "    if primeiro_nome1!='':\n",
    "        qte_nomes1+=1\n",
    "    inicial_primnome1 = primeiro_nome1[0]\n",
    "    demais_nomes1     = nome_padronizado1.split(',')[1].split(' ')[1:]\n",
    "    qte_nomes1=qte_nomes1+len(demais_nomes1)\n",
    "    \n",
    "    qte_nomes2=0\n",
    "    nome_padronizado2 = padronizar_nome(nome2)\n",
    "    sobrenome2        = nome_padronizado2.split(',')[0]\n",
    "    if sobrenome2!='':\n",
    "        qte_nomes2+=1    \n",
    "    primeiro_nome2    = nome_padronizado2.split(',')[1].split(' ')[0]\n",
    "    if primeiro_nome2!='':\n",
    "        qte_nomes2+=1\n",
    "    inicial_primnome2 = primeiro_nome2[0]\n",
    "    demais_nomes2     = nome_padronizado2.split(',')[1].split(' ')[1:]\n",
    "    qte_nomes2=qte_nomes2+len(demais_nomes2)\n",
    "    \n",
    "    if sobrenome1==sobrenome2 and primeiro_nome1==primeiro_nome2:\n",
    "        trocar.append((nome1,nome_padronizado2))\n",
    "\n",
    "    if sobrenome1==sobrenome2 and primeiro_nome1==primeiro_nome2:\n",
    "        trocar.append((nome1,nome_padronizado2))\n",
    "        \n",
    "    return trocar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = \"Vasconcelos, GS ; Fernandes, MCR ; Matsui, TC ; Luciano, MCS ; Costa, CL ; Ferraz, CPM ; Dias, FBS ; MIYAJIMA, FABIO ; Araújo, FMC ; Fonseca, MHG . Persistent SARS-COV-2 infection in vaccinated individual with three doses of COVID-19 vaccine. VACCINE, v. 41, p. 1778-1782, 2023.\"\n",
    "# extrair_detalhes(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtro='Artigos completos publicados em periódicos'\n",
    "# artigos = df_secoes[df_secoes.ROTULOS == filtro]\n",
    "\n",
    "# nome = lista_busca[1]\n",
    "# artigos_individual = artigos[artigos.CURRICULO==nome]\n",
    "# lista_individual = artigos_individual['CONTEUDOS']\n",
    "# lista_individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><b>FILTRAR PERÍODO DE TEMPO UNIFICADO</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artigos = pd.read_csv(pathout+'df_artigos_servidores_ingresso_fioce.csv', sep='\\t')\n",
    "print(len(df_artigos.index))\n",
    "# df_artigos[601:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artigos.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_inico = 2008\n",
    "ano_final = 2023\n",
    "df_artigosperiodo = df_artigos[(df_artigos.ANO_PUB >=ano_inico)&(df_artigos.ANO_PUB <=ano_final)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artigosperiodo[df_artigosperiodo.ANO_PUB==np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_artigosperiodo[:600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><b>FILTRAR PERÍODO DE TEMPO INDIVIDUALIZADO</b></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_artigos = df_artigos_servidores\n",
    "\n",
    "# fioce_pessoal['INGRESSO_FIOCE'] = pd.to_datetime(fioce_pessoal['INGRESSO_FIOCE'])\n",
    "\n",
    "# # Certificando-se de que 'INGRESSO_FIOCE' é do tipo int (se for data no formato yyyy, por exemplo)\n",
    "# fioce_pessoal['ANO_INGRESSO_FIOCE'] = fioce_pessoal['INGRESSO_FIOCE'].dt.year\n",
    "\n",
    "# # Merge entre df_artigos e fioce_pessoal usando 'AUTORES' e 'NOME' como chaves\n",
    "# merged_df = df_artigos.merge(fioce_pessoal, left_on='CURRICULO', right_on='NOME', how='inner')\n",
    "\n",
    "# # Filtrar as linhas de acordo com a condição do ano de publicação e da data de ingresso\n",
    "# result_df = merged_df[merged_df['ANO_PUB'] >= merged_df['ANO_INGRESSO_FIOCE']]\n",
    "\n",
    "# # Opcional: Dropar colunas redundantes ou não necessárias, por exemplo, 'NOME' que é igual a 'AUTORES'\n",
    "# result_df = result_df.drop(columns=['NOME'])\n",
    "\n",
    "# # Agora, result_df é o dataframe final desejado\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df[result_df.ANO_PUB==2030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_result_df = merged_df[merged_df['ANO_PUB'] < merged_df['ANO_INGRESSO_FIOCE']]\n",
    "# print(len(result_df))\n",
    "# print(len(out_result_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exibir informações extratídas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artigosperiodo.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolucao_artigos(df_artigosperiodo, fioce_pessoal, threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artigosperiodo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_artigosperiodo.NOME.value_counts()))\n",
    "df_artigosperiodo.NOME.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fioce_pessoal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_media_artigos(df_artigosperiodo, fioce_pessoal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolucao_anual(df_artigosperiodo, fioce_pessoal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolucao_sem_duplicatas(df_artigosperiodo, fioce_pessoal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotar_artigos_ano(df_artigosperiodo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparativo_curriculos(df_artigosperiodo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotar_barras_estaqueadas(df_artigosperiodo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artigosperiodo[df_artigosperiodo.NOME=='Anya Pimentel Gomes Fernandes Vieira Meyer'].sort_values(by='ANO_PUB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df[result_df.NOME=='Raphael Trevizani']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qualitatives = px.colors.qualitative.swatches()\n",
    "# sequentials = px.colors.sequential.swatches()\n",
    "\n",
    "# qualitatives.show()\n",
    "# sequentials.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def try_folders(drives_win, drives_lin,pastas,pastasraiz):\n",
    "#     sistema_operacional =sys.platform\n",
    "#     for r in pastasraiz:\n",
    "#         for p in pastas:\n",
    "#             if 'linux' in sistema_operacional:\n",
    "#                 so = 'Linux'\n",
    "#                 for d in drives_lin:\n",
    "#                     caminho = d+p+r\n",
    "#             elif 'win32' in sistema_operacional:\n",
    "#                 so = 'Windows'\n",
    "#                 for d in drives_win:\n",
    "#                     pastaraiz = d+p+r\n",
    "#             else: \n",
    "#                 print('MacOS não contemplado ainda')\n",
    "#             try:\n",
    "#                 print(f'Procurar em: {pastaraiz}')\n",
    "#                 caminho = pastaraiz+'/chromedriver'\n",
    "#                 if 'chromedriver' in os.listdir(caminho):\n",
    "#                     print(f'Folder Chromedriver encontrado em: {pastaraiz}')\n",
    "#                     print(f'Sistema Operacional: {so}')\n",
    "#                     print(f'  Pasta de trabalho: {caminho}')\n",
    "#                     return pastaraiz\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "#                 caminho = None\n",
    "#                 pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_chromedriver(drives_win, drives_lin, drives_mac, users, root_folders):\n",
    "#     \"\"\"\n",
    "#     This function aims to locate the directory containing Chromedriver.\n",
    "#     \"\"\"\n",
    "#     os_type = sys.platform\n",
    "\n",
    "#     # Determine the OS and relevant drives\n",
    "#     if 'linux' in os_type:\n",
    "#         os_name = 'Linux'\n",
    "#         drives = drives_lin\n",
    "#     elif 'win32' in os_type:\n",
    "#         os_name = 'Windows'\n",
    "#         drives = drives_win\n",
    "#     elif 'darwin' in os_type:\n",
    "#         os_name = 'macOS'\n",
    "#         drives = drives_mac\n",
    "#     else:\n",
    "#         print(\"Unsupported operating system.\")\n",
    "#         return None\n",
    "\n",
    "#     # Iterate over potential paths to find Chromedriver\n",
    "#     for root in root_folders:\n",
    "#         for user in users:\n",
    "#             for drive_path in drives:\n",
    "#                 search_path = os.path.join(drive_path, user, root)\n",
    "#                 print(f'Buscando em {search_path}')\n",
    "#                 try:\n",
    "#                     if 'chromedriver' in os.listdir(search_path):\n",
    "#                         chromedriver_path = os.path.join(search_path, 'chromedriver')\n",
    "#                         print(f'Chromedriver found at: {chromedriver_path}')\n",
    "#                         print(f'Operating System: {os_name}')\n",
    "#                         return search_path\n",
    "#                 except FileNotFoundError as e:\n",
    "#                     continue\n",
    "\n",
    "#     print(\"Chromedriver not found.\")\n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drives_win   = ['C:/Users']\n",
    "# drives_lin   = ['/home']\n",
    "# drives_mac   = []\n",
    "# users        = ['/marcos.aires', '/marcos', '/marco']\n",
    "# root_folders = ['/kgfioce']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.path.join(drives_win[0], users[0], root_folders[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_chromedriver(drives_win, drives_lin, drives_mac, users, root_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "\n",
    "# def find_chromedriver(drives_win, drives_lin, drives_mac, users, root_folders):\n",
    "#     \"\"\"\n",
    "#     This function aims to locate the directory containing Chromedriver.\n",
    "#     \"\"\"\n",
    "#     os_type = sys.platform\n",
    "\n",
    "#     # Determine the OS and relevant drives\n",
    "#     if 'linux' in os_type:\n",
    "#         os_name = 'Linux'\n",
    "#         drives = drives_lin\n",
    "#     elif 'win32' in os_type:\n",
    "#         os_name = 'Windows'\n",
    "#         drives = drives_win\n",
    "#     elif 'darwin' in os_type:\n",
    "#         os_name = 'macOS'\n",
    "#         drives = drives_mac\n",
    "#     else:\n",
    "#         print(\"Unsupported operating system.\")\n",
    "#         return None\n",
    "\n",
    "#     # Iterate over potential paths to find Chromedriver\n",
    "#     for root in root_folders:\n",
    "#         for user in users:\n",
    "#             for drive in drives:\n",
    "#                 search_path = f\"{drive}{os.sep}{user}{os.sep}{root}\"\n",
    "#                 print(f'Searching in: {search_path}')\n",
    "                \n",
    "#                 try:\n",
    "#                     if 'chromedriver' in os.listdir(search_path):\n",
    "#                         chromedriver_path = f\"{search_path}{os.sep}chromedriver\"\n",
    "#                         print(f'Chromedriver found at: {chromedriver_path}')\n",
    "#                         print(f'Operating System: {os_name}')\n",
    "#                         return search_path\n",
    "#                 except FileNotFoundError as e:\n",
    "#                     continue\n",
    "\n",
    "#     print(\"Chromedriver not found.\")\n",
    "#     return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find_chromedriver(drives_win, drives_lin, drives_mac, users, root_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade python-docx\n",
    "\n",
    "# import pandas as pd\n",
    "# from docx import Document\n",
    "\n",
    "# def read_table_from_docx(docx_path, table_index=0):\n",
    "#     # Abrir o arquivo Word\n",
    "#     doc = Document(docx_path)\n",
    "    \n",
    "#     # Verificar se o documento contém tabelas\n",
    "#     if len(doc.tables) == 0:\n",
    "#         return \"O documento não contém tabelas.\"\n",
    "    \n",
    "#     # Escolher a tabela pelo índice (começando por 0)\n",
    "#     table = doc.tables[table_index]\n",
    "    \n",
    "#     # Ler as linhas da tabela e armazená-las em uma lista de listas\n",
    "#     data = []\n",
    "#     for row in table.rows:\n",
    "#         row_data = []\n",
    "#         for cell in row.cells:\n",
    "#             row_data.append(cell.text)\n",
    "#         data.append(row_data)\n",
    "    \n",
    "#     # Converter a lista de listas em um dataframe do pandas\n",
    "#     df = pd.DataFrame(data)\n",
    "    \n",
    "#     # Utilizar a primeira linha como cabeçalho\n",
    "#     df.columns = df.iloc[0]\n",
    "#     df = df[1:]\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Caminho para o arquivo Word\n",
    "# docx_path = \"24102022_Tabela_1844948_TabelaAreasConhecimento_atualizada_2022.docx\"\n",
    "\n",
    "# # Ler a primeira tabela no arquivo para um dataframe\n",
    "# df = read_table_from_docx(pathcsv+docx_path)\n",
    "\n",
    "# # Exibir o dataframe\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beakerx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
